[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладний статистичний аналіз",
    "section": "",
    "text": "Передмова",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "binom.html",
    "href": "binom.html",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "1.1 Генеральна сукупність та вибірка\nВи вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.\nПроте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.\nЩоб це перевірити, ви проводите експеримент: залучаєте 30 нових студентів. 20 із них проходять курс й оплачують доступ, а 11 відмовляються. 20 — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?\nРозв’язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають генеральною сукупністю. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як \\(\\mu\\). Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та досліджувати результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо вибірку з генеральної сукупності та аналізуємо частку успішних випадків.\nЗгідно з результатами нашого експерименту, спостережувана ймовірність оплати становить \\(\\hat{\\mu} = 20/30 = 0.67\\)1. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?\nРозгляньмо, чому отримане значення може не бути переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює \\(\\mu = 0.5\\), і змоделюємо можливі результати для 30 студентів.\nДавайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для 30 спроб:\nМи бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.\nТому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення \\(\\mu\\) у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#генеральна-сукупність-та-вибірка",
    "href": "binom.html#генеральна-сукупність-та-вибірка",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "Якщо монетка випаде орлом, студент оплачує доступ.\nЯкщо монетка випаде решкою, студент відмовляється від курсу.\nВикористаємо метод integers() до класу Generator, яка генерує випадкові цілі числа в заданому діапазоні.\nПідкинемо монетку 30 разів та порахуємо кількість успішних випадків.\n\n\n\n\nЛістинг 1.1: Підкидання монетки\n\n\n\n1rng = np.random.default_rng(seed=18)\n\n2n = 30\n3results = rng.integers(0, 1, size = 30, endpoint = True)\n4success = np.sum(results) / n\n\n5print(f\"Кількість успішних випадків: {round(success, 3) * 100}%\")\n\n\n1\n\nІніціалізуємо генератор випадкових чисел з фіксованим seed.\n\n2\n\nКількість студентів.\n\n3\n\nГенеруємо випадкові числа2 для кожного студента.\n\n4\n\nОбчислюємо частку успішних випадків.\n\n5\n\nВиводимо результат.\n\n\n\n\nКількість успішних випадків: 70.0%",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-гіпотези",
    "href": "binom.html#статистичні-гіпотези",
    "title": "1  Біноміальний критерій",
    "section": "1.2 Статистичні гіпотези",
    "text": "1.2 Статистичні гіпотези\n\n1.2.1 Постановка задачі\nМи з’ясували, що навіть за ймовірності \\(\\mu = 0.5\\) можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали seed для отримання такого результату. Якщо повторити цей експеримент з іншим значенням seed або збільшити кількість спостережень, результат може виявитися іншим.\n\n\n\n\n\n\nПорада\n\n\n\nСпробуйте змінити seed (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.\n\n\nТож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту статистично значущими необхідно отримати відповідь на питання:\n\n\nЧи можна вважати, що спостережуване значення \\(\\hat{\\mu}\\) є більшим від \\(\\mu = 0.5\\)?\n\n\nЗвернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину \\(\\xi\\), яка підпорядковується розподілу Бернуллі3. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.\n\\[\n\\xi \\sim \\text{Bernoulli}(\\mu)\n\\]\nде \\(\\mu\\) — ймовірність успіху.\nНас цікавить підтвердження того, що \\(\\mu &gt; 0.5\\). У статистиці для перевірки гіпотез розглядають дві можливості:\n\nНульова гіпотеза (\\(H_0\\)) формулюється як твердження, яке ми прагнемо спростувати.\nАльтернативна гіпотеза (\\(H_1\\)) висловлює припущення, яке ми хочемо довести.\n\nСкорочено це записують як:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 0.5 \\\\\nH_1 &: \\mu &gt; 0.5\n\\end{aligned}\n\\]\nЗауважимо, що якщо в нашому експерименті з 30 студентами можна дивитися не на частку успіхів, а на їх кількість.\nТоді питання можна переформулювати так:\n\n\nЗа умови вірності \\(H_0\\) наскільки ймовірно отримати 20 або більше успішних випадків з 30?\n\n\nЯкщо ми проводимо \\(n\\) незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу4.\n\\[\nS_n = \\sum_{i=1}^{n} \\xi_i \\sim \\text{Binomial}(n, \\mu)\n\\]\nде \\(\\xi_i\\) — випадкова величина, яка показує успіх у \\(i\\)-му спостереженні, \\(S_n\\) — кількість успішних випадків у \\(n\\) спостереженнях, \\(n\\) — кількість спостережень, \\(\\mu\\) — ймовірність успіху.\nДавайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\).\n\n\n\nЛістинг 1.2: Функція щільності ймовірностей для біноміального розподілу\n\n\n\n1n = 30\n2mu = 0.5\n\n3x = np.arange(0, n + 1)\n4y = binom.pmf(x, n, mu)\n\n5plt.bar(x, y, color=turquoise)\n6plt.bar(x[x &gt;= 20], y[x &gt;= 20], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nКількість студентів.\n\n2\n\nЙмовірність успіху.\n\n3\n\nСтворюємо масив з усіма можливими значеннями кількості успішних випадків.\n\n4\n\nОбчислюємо ймовірності для кожної кількості успішних випадків.\n\n5\n\nСтворюємо гістограму з ймовірностями.\n\n6\n\nВиділяємо ймовірності для кількості успішних випадків, які є більшими або рівними 20.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 1.1: Візуалізація функції щільності ймовірностей для біноміального розподілу\n\n\n\n\n\nЦіановим5 кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює 20.\n\n\n1.2.2 Критерій\nЩойно ми розробили алгоритм, який на основі вибірки \\(\\xi\\) або визнає наявність доказів на користь \\(H_1\\), або повідомляє, що таких доказів немає. Відповідно, він або відхиляє \\(H_0\\), або не відхиляє її.\nТакий алгоритм називається критерієм. Його можна подати у вигляді функції \\(S\\), яка приймає реалізацію вибірки та повертає \\(1\\), якщо слід відхилити \\(H_0\\), та \\(0\\) в іншому випадку.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо відхиляємо } H_0 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nДавайте припустимо, що ми вирішили відхилити \\(H_0\\), якщо кількість успішних випадків перевищує або дорівнює 21. Тоді критерій набуде вигляду:\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо } \\sum \\xi_i \\geqslant 21 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nЗазвичай скорочують запис і пишуть просто правило, за яким відхиляємо \\(H_0\\)\n\\[\nS = \\{\\sum \\xi_i \\geqslant 21\\}\n\\]\nПозначимо \\(Q = \\sum \\xi_i\\), \\(C = 21\\), тоді критерій набуває вигляду:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}\n\\]\nТак влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. \\(Q\\) називається статистикою критерію, \\(C\\) — критичним значенням.\n\\(Q\\) може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх \\(\\xi_i\\). Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.\n\n\n1.2.3 Критична область\nЗнову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію \\(S\\):\n\n\nНаскільки часто може бути таке, що за справедливості \\(H_0\\) критерій \\(S\\) відхиляє гіпотезу?\n\n\nВідповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним 21, побачивши на картинці, що великі відхилення відбуваються при \\(H_0\\) рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення \\(C\\), виходячи з частоти помилок нашого критерію.\nВибираючи \\(C\\), ми можемо або часто відхиляти нульову гіпотезу, коли \\(C\\) мале, або можемо робити це рідше, коли \\(C\\) велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.\n\n\\(C = 16\\). Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із 30, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає \\(1\\), тобто це помилка хибно позитивна (false positive, FP).\n\\(C = 29\\). У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб’ємося цього. Не відхилити гіпотезу \\(H_0\\), коли вона неправильна — це теж помилка. Вона називається хибно негативна (false negative, FN), оскільки критерій повернув 0 помилково.\n\n\n\\[\n\\text{FP} - H_0 \\text{відхиляється, коли вона вірна}\n\\]\n\\[\n\\text{FN} - H_0 \\text{не відхиляється, коли вона не вірна}\n\\]\nУ нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.\nТому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж частота хибнопозитивних спрацьовувань (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності \\(H_0\\).\nТепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.\n\n\nЯкий FPR у критерію \\(S\\) для перевірки гіпотези \\(H_0\\) проти \\(H_1\\)?\n\n\nКоли \\(H_0\\) є вірною, щоб порахувати кількість успіхів ми проводили 30 разів підкидання монетки з ймовірністю орла \\(0.5\\). Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при \\(\\mu = 0.5\\) наша статистика має біноміальний розподіл \\(Q \\sim Binom(0.5, 30)\\).\nОбчислимо FPR для \\(C = 21\\)\n\\[\n\\begin{aligned}\nFPR &= P(S(\\xi) = 1\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ \\mu = 0.5) = \\\\\n&= P(Q \\geqslant 21\\ |\\ Q \\sim Binom(0.5, 30))\n\\end{aligned}\n\\]\nЦе вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.\n\n\n1.2.4 Обчислення FPR\nДавайте порахуємо суму ймовірностей для кількостей успіхів від 21 до 30 включно. Покажемо графічно, як це виглядає на Рисунку 1.2.\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, 0.5)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink)\nfor i in range(crit_subs - 2, crit_subs + 4):\n    plt.text(i + 0.5, y[i] + 0.001, f\"{round(y[i] * 100, 1)}%\",\n    ha='center', va='bottom', size=8, rotation = 30)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.2: Ймовірність хибно відхилити \\(H_0\\) за умови її вірності\n\n\n\n\n\nЗалишається лише обчислити суму ймовірностей для кількостей успіхів від 21 до 30 включно. Це і буде нашим FPR.\n\\[\nFPR_{21} = \\sum_{i = 21}^{30} P(Q = i) \\approx 0.021\n\\]\nУ нашому випадку це буде 2.1%. Якщо FPR не перевищує деякої константи \\(\\alpha\\), то критерій називається критерієм рівня значущості \\(\\alpha\\). Статистичний критерій з \\(\\alpha\\) = 100% створити тривіально — достатньо завжди відхиляти \\(H_0\\) — тому така постановка не має сенсу.\nРівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть \\(\\alpha = 0.05\\), але якщо потрібне більш точне ухвалення рішення, можуть вибрати \\(0.01\\), \\(0.005\\), \\(0.001\\). Якщо ж рішення не таке критичне, можуть вибрати \\(0.1\\).\nПрипустимо, вибрали значення \\(\\alpha = 0.05\\), скористаємося критерієм \\(S\\): тобто якщо кількість успішних випадків перевищує або дорівнює 21, то відхиляємо \\(H_0\\).\nЯкщо уважно подивитись на Рисунок 1.2, то можна помітити, що ми можемо відхиляти \\(H_0\\) при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати \\(\\alpha = 0.05\\):\n\\[\nFPR_{20} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.049\n\\]\nЯкщо ж обрати 19, то FPR буде більше \\(\\alpha\\): \\[\nFPR_{19} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.1002\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-функції-в-python",
    "href": "binom.html#статистичні-функції-в-python",
    "title": "1  Біноміальний критерій",
    "section": "1.3 Статистичні функції в Python",
    "text": "1.3 Статистичні функції в Python\nУ цій частині подивимося, як вивести те, що ми отримали в частині 2, за допомогою Python. А також зрозуміємо, як знайти відповідне \\(C\\) за допомогою Python.\n\n1.3.1 Біноміальний розподіл\nМи з’ясували, що статистика \\(Q\\) має біноміальний розподіл.\nБіноміальний розподіл \\(Binom(n, \\mu)\\) — розподіл кількості успіхів у послідовності з \\(n\\) незалежних випадкових експериментів, ймовірність успіху в кожному з яких дорівнює \\(\\mu\\).\nЩоб працювати з розподілом, можна створити об’єкт-розподіл за допомогою бібліотеки scipy.stats.\n\n\n\n\nЛістинг 1.3: Створення біноміального розподілу\n\n\nfrom scipy.stats import binom\n\nn = 30\nmu = 0.5\n\nbinom_dist = binom(n, mu)\n\n\n\n\n\nКількість спостережень.\nЙмовірність успіху.\n\n\n\n1.3.2 Функція ймовірностей\nФункція ймовірності дискретного розподілу \\(p_\\xi(x)\\) — ймовірність, з якою \\(\\xi\\) приймає значення \\(x\\).\nУ Python це функція pmf (probability mass function).\n\n\n\n\nЛістинг 1.4: Обчислення ймовірностей біноміального розподілу для кількості успіхів\n\n\nbinom_dist.pmf(20)\n\n\n\n\n0.027981600724160654\n\n\nЗобразимо розподіл статистики \\(Q\\) за справедливості \\(H_0\\) на графіку. Для цього можна передати відразу масив точок, для яких треба розрахувати ймовірність.\n\n1x = np.arange(0, n + 1)\n2y = binom_dist.pmf(x)\n\n3crit_subs = 21\n\n4plt.bar(x, y, color=turquoise, label=\"Ймовірність успіхів\")\n5plt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink, label=\"Критичне значення\")\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nМасив точок.\n\n2\n\nРозрахунок ймовірностей.\n\n3\n\nКритичне значення.\n\n4\n\nЙмовірність успіхів.\n\n5\n\nКритичне значення.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.3: Функція щільності ймовірностей біноміального розподілу\n\n\n\n\n\n\nНасправді вже зараз ми можемо порахувати ймовірність потрапляння в критичну область. Потрібно просто підсумувати ймовірності для кількостей успіхів від 21 до 30.\n\n\n\n\nЛістинг 1.5: Обчислення ймовірностей для критичної області\n\n\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.0214\n\n\nОтже, ми дійсно побудували критерій рівня значущості \\(\\alpha = 0.05\\). Ба більше, це критерій рівня значущості 0.021.\nА що якби ми взяли \\(C = 19\\)?\n\n\n\n\nЛістинг 1.6: Обчислення ймовірностей для критичної області при \\(C = 19\\)\n\n\ncrit_subs = 19\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.1002\n\n\nТоді ймовірність помилки вже навіть більше \\(10\\%\\), що зовсім нам не підходить.\nА якщо \\(C = 20\\)?\n\n\n\n\nЛістинг 1.7: Обчислення ймовірностей для критичної області при \\(C = 20\\)\n\n\ncrit_subs = 20\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.0494\n\n\nВидно, що немає такого \\(C\\), щоб FPR був рівно \\(5\\%\\).\n\n\n1.3.3 Кумулятивна функція розподілу\nКумулятивна функція розподілу \\(F_\\xi(x) = P(\\xi \\leqslant x)\\)\nУ Python це функція cdf (Cumulative Distribution Function).\n\n\n\n\nЛістинг 1.8: Обчислення кумулятивної функції розподілу біноміального розподілу\n\n\nbinom_dist.cdf(19)\n\n\n\n\n0.9506314266473055\n\n\nЙмовірність отримати \\(19\\) або менше успіхів у нашому завданні \\(\\geqslant 0.95\\). А оскільки \\(P(\\xi \\leqslant 19) + P(\\xi \\geqslant 20) = 1\\), можемо обчислити рівень значущості нашого критерію.\n\n\n\n\nЛістинг 1.9: Обчислення рівня значущості критерію\n\n\n1 - binom_dist.cdf(19)\n\n\n\n\n0.04936857335269451\n\n\n\n\n1.3.4 Квантиль\nЩоб вибрати критичну область для критерію, ми хотіли б знайти точку, площа стовпців праворуч від якої була б \\(5\\%\\). Тобто площа стовпців зліва — \\(95\\%\\). Така точка називається квантилью.\n\\[\nu_p(\\xi) = \\{x\\ | F_\\xi(x) = p\\}\n\\]\nАле при \\(p = 0.95\\) й нашому біноміальному розподілі, такої точки немає. Ми з’ясували, що є точка, праворуч від якої площа \\(0.494\\), а в наступної вже \\(0.1\\). Щоб визначити квантиль у цьому випадку, модифікуємо визначення. Квантиль \\(u_p(\\xi)\\) — величина, яку \\(\\xi\\) не перевищує з імовірністю хоча б \\(p\\). Тобто \\(F_\\xi(u_p) \\geqslant p\\).\n\\[\nu_p(\\xi) = min\\ \\{x\\ |\\ F_\\xi(x) \\geqslant p \\}\n\\]\n\nПриклад 1.1 Для величини \\(\\xi \\sim Bin(30, 0.5)\\) порахуємо 0.95-квантиль. Вирішимо задачу просто підбором.\n\\[\nP(\\xi \\leqslant 18) \\approx 0.90\n\\]\n\\[\nP(\\xi \\leqslant 19) \\approx 0.951\n\\]\n\\[\nP(\\xi \\leqslant 20) \\approx 0.97\n\\]\nБачимо, що 18 нам ще не підходить, а 19 й більші значення вже підійдуть. У них функція розподілу буде більшою за \\(p\\). Відповідь — найменше відповідне значення, тобто 19. При цьому немає точки, де функція розподілу дорівнювала б \\(p\\) в точності.\nЯкби розподіл був неперервним, можна було б сказати, що квантиль — це таке \\(x\\), на якому функція розподілу дорівнює \\(p\\). Але для дискретного розподілу такого може не бути.\n\nУ Python квантиль можна порахувати через функцію ppf (Percent Point Function).\n\n\n\n\nЛістинг 1.10: Обчислення квантилю біноміального розподілу\n\n\nbinom_dist.ppf(0.95)\n\n\n\n\n19.0\n\n\nЯк тепер підібрати \\(C\\) для будь-яких \\(n, \\mu\\) й для будь-якого рівня значущості \\(\\alpha\\)?\n\nПотрібно знайти \\(C\\), таке що \\(P(Q \\geqslant C) \\leqslant \\alpha\\)\nТобто потрібно \\(P(Q &lt; C) \\geqslant 1 - \\alpha\\)\n\\(Q\\) приймає тільки цілі значення: \\(P(Q \\leqslant C - 1) \\geqslant 1 - \\alpha\\), або \\(F(C - 1) \\geqslant 1 - \\alpha\\)\nОтже, з визначення квантилі, \\(C - 1 = u_{1 - \\alpha}\\)\nЗначить \\(C = u_{1 - \\alpha} + 1\\)\n\n\n\n\n\nЛістинг 1.11: Знаходження критичного значення для критерію\n\n\ndef find_crit_subs(n, mu, alpha):\n    binom_dist = binom(n, mu)\n    return binom_dist.ppf(1 - alpha) + 1\n\n\nfind_crit_subs(30, 0.5, 0.05)\n\n\n\n\n20.0\n\n\nКритичне значення \\(20\\), отже підсумковий критерій має такий вигляд\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\n\\(Q = 19\\), значить гіпотезу ми не відкидаємо.\nПри цьому нам вдалося побудувати процес, за яким ми ухвалюємо рішення для будь-якого рівня значущості та значення статистики критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#p-значення",
    "href": "binom.html#p-значення",
    "title": "1  Біноміальний критерій",
    "section": "1.4 \\(p\\)-значення",
    "text": "1.4 \\(p\\)-значення\nЗауважимо, що зараз, якщо нам зададуть іншу \\(\\alpha\\), нам доведеться перебудовувати критерій заново. Це не зовсім зручно. У статистиці є механізм \\(p\\)-значення, який дає змогу прийняти рішення для всіх \\(\\alpha\\) відразу.\n\n1.4.1 Більш екстремальні значення\nПрипустимо, ми провели експеримент й порахували для критерію його статистику \\(Q(\\xi)\\). Позначимо отримане значення \\(q\\), у поточній задачі це \\(q = 19\\). Якби кількість успішних підписок була більшою, це б сильніше свідчило на користь альтернативної гіпотези \\(H_1\\). Тобто в разі значення \\(25\\) ми були б ще сильніше впевнені в тому, що наш бізнес буде окупатися. Тоді значення \\(25\\) називається більш екстремальним, ніж значення \\(19\\). У нашій задачі більш екстремальним із двох значень є те, яке більше.\nВизначимо поняття екстремальності формально:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}:\\ t\\ \\text{екстремальніше}\\ q \\Leftrightarrow t &gt; q\n\\]\nНайчастіше критерії інших видів можна привести до цього, тоді для них теж визначено поняття екстремальності.\n\n\n1.4.2 \\(p\\)-значення\np-value — це ймовірність отримати таке або більш екстремальне значення статистики \\(q\\) за умови вірності \\(H_0\\).\n\\[\nP_{H_0}(Q \\geqslant q)\n\\]\n\n\n\n\n\n\n\n\nРисунок 1.4: \\(p\\)-значення для критерію \\(Q = 15\\)\n\n\n\n\n\nТепер виведемо формулу через функції Python:\n\\[\nP_{H_0}(Q \\geqslant q) = 1 - P_{H_0}(Q &lt; q) = 1 - F(q)\n\\]\nЗобразимо на графіку область більш екстремальних значень й p-value для різних значень статистики.\n\n\n\n\n\n\n\n\nРисунок 1.5: \\(p\\)-значення для критерію \\(Q = 10, 19, 20, 25\\)\n\n\n\n\n\nМожна побачити, що в критичній області \\(p\\)-значення \\(\\leqslant \\alpha\\), а поза нею \\(p\\)-значення \\(&gt; \\alpha\\). Саме таке правило й використовується для прийняття рішення.\n\\[\nH_0 \\text{ відкидається } \\Leftrightarrow p-значення \\leqslant \\alpha\n\\]\nПричому за \\(p\\)-значення одразу видно, що якби в нашу критичну область включили значення \\(19\\), наш критерій допускав би FPR у \\(10\\%\\) випадків, що вже неприпустимо. Тому й гіпотезу ми не відкидаємо.\nЗауважимо, що для обчислення \\(p\\)-значення не знадобилося знання \\(\\alpha\\), а потрібна була тільки статистика й форма критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#двосторонні-критерії",
    "href": "binom.html#двосторонні-критерії",
    "title": "1  Біноміальний критерій",
    "section": "1.5 Двосторонні критерії",
    "text": "1.5 Двосторонні критерії\nДо цього моменту нас цікавили відхилення від ймовірності в \\(50\\%\\) тільки в один бік. І логічно, адже це продиктовано бізнесом. Тільки велика частка успішних підписок призведе до успіху. І зазвичай при прийнятті рішень так й буває. При тестуванні нового рішення або продукту розглядають альтернативну гіпотезу тільки в бік поліпшення, тому що в іншому разі немає сенсу впроваджувати рішення на всіх користувачів.\nОднак іноді може знадобитися доводити відхилення в обидва боки, якщо ви перевіряєте якесь припущення. Нехай вам дали монетку й просять перевірити, чесна вона чи ні. Монетка чесна, якщо під час підкидання ймовірність випадання орла дорівнює \\(0.5\\). Ви підкидаєте монетку \\(30\\) разів, кожен кидок — бернуллівська величина, аналогічно завданню з сервісом освітніх послуг. Нульова гіпотеза та ж сама: \\(\\mu = 0.5\\). Але тепер ми хочемо відкидати цю гіпотезу як у разі великої ймовірності орла, так і в разі маленької, відповідно перевіряємо двосторонню гіпотезу.\n\\[\nH_0: \\mu = 0.5\n\\]\n\\[\nH_1: \\mu \\neq 0.5\n\\]\nВиберемо критичну область для критерію за такої альтернативи. Скористаємося тією ж статистикою \\(Q(\\xi) = \\sum \\xi_i\\). Тільки тепер відхилення в кожну сторону однаково важливі. Відкидати гіпотезу будемо не тільки на досить великих значеннях, а й на досить маленьких. Наприклад, якщо у нас було всього \\(2\\) орла з \\(30\\) — це свідчення на користь того, що \\(\\mu \\neq 0.5\\), але не на користь \\(\\mu &gt; 0.5\\).\nОскільки відхилення в різні боки однаково важливі, а розподіл симетричний, шукати критерій можна в такому вигляді:\n\\[\nS = \\{Q \\geqslant C\\} \\cup \\{Q \\leqslant n - C\\}\n\\]\n\n1.5.1 Як вибрати критичну область\nПодивимося, який вигляд матиме критична область у такому разі.\n\n\n\n\n\n\n\n\nРисунок 1.6: Двостороння критична область для критерію \\(С = 6\\)\n\n\n\n\n\nЗ картинки видно, що якщо тепер відкидати відхилення за \\(Q \\geqslant 20\\), то необхідно відкидати й \\(Q \\leqslant 10\\), а отже, загальна площа стовпців буде вже приблизно \\(0.1\\). Тому за рівня значущості \\(0.05\\) й \\(20\\) успіхів гіпотеза вже не відкинеться.\nЯкщо ж виставити \\(C = 6\\), то така область уже підходить, площа стовпців \\(\\approx 0.043 &lt; 0.05\\).\nЩоб вибрати порогову константу за формулою, можна помітити, що критична область симетрична, а значить праворуч площа не повинна бути більшою, ніж \\(\\frac{\\alpha}{2}\\). А таку задачу ми вже вміємо розв’язувати.\nРеалізуємо функцію на Python.\n\n\n\n\nЛістинг 1.12: Знаходження критичного значення для двостороннього критерію\n\n\ndef find_crit_subs_two_sided(n, mu, alpha):\n    binom_dist = binom(n, mu)\n    return n / 2 - binom_dist.ppf(alpha / 2) + 1\n\nfind_crit_subs_two_sided(30, 0.5, 0.05)\n\n\n\n\n6.0\n\n\n\n\n1.5.2 Як знайти \\(p\\)-значення\nКритерій має вигляд\n\\[\nS = \\{|Q(\\xi) - 15| \\geqslant C\\}\n\\]\nПозначимо відхилення суми від 15 як \\(\\Delta(\\xi) = |Q(\\xi) - 15|\\), тоді ми маємо критерій\n\\[\nS = \\{\\Delta(\\xi) \\geqslant C\\}\n\\]\nТобто більш екстремальними вважатимуться ті значення суми, що знаходяться далі від 15. Щоб обчислити \\(p\\)-значення, доведеться порахувати суму площ із двох сторін окремо.\n\n\n\n\nЛістинг 1.13: Обчислення \\(p\\)-значення для двостороннього критерію\n\n\ndef pvalue_two_sided_sym(n, q):\n    binom_h0 = binom(n=n, p=0.5)\n    diff = np.abs(q - 15)\n    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n    left_sq = binom_h0.cdf(15 - diff)\n    return left_sq + right_sq\n\npvalue_two_sided_sym(30, 21)\n\n\n\n\n0.04277394525706769\n\n\nНасправді через симетричність розподілу ліва і права площа виходять однаковими, тому можна порахувати площу з одного боку і помножити на 2.\n\n\n\n\nЛістинг 1.14: Обчислення \\(p\\)-значення для двостороннього критерію (спрощено)\n\n\ndef pvalue_two_sided_sym_simple(n, q):\n    binom_h0 = binom(n=n, p=0.5)\n    diff = np.abs(q - 15)\n    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n    return 2 * right_sq\n\npvalue_two_sided_sym_simple(30, 21)\n\n\n\n\n0.04277394525706768\n\n\nТепер навіть у разі \\(20\\) орлів \\(p\\)-значення \\(&gt; 0.05\\), тому відкидати будемо значення, починаючи з \\(21\\) й менші або такі, що дорівнюють \\(9\\).\n\n\n1.5.3 Випадок із несиметричним розподілом\nКоли розподіл за справедливості \\(H_0\\) несиметричний, відхилення від очікуваного значення в різні боки можуть бути по-різному критичними. Як приклад розглянемо також біноміальний розподіл, але з імовірністю успіху \\(0.8\\).\nТоді можна ліву і праву критичні області побудувати окремо, виділивши на них по \\(\\frac{\\alpha}{2}\\) площі. Праву область ми вже вміємо шукати, знайдемо ліву.\n\nbinom_h0_nonsym = binom(n=30, p=0.8)\n\nprobs = binom_h0_nonsym.pmf(np.arange(31))\n\nplt.bar(np.arange(31), probs, color=turquoise, label=\"Binom(30, 0.8)\")\nplt.legend(fontsize=8)\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.7: Біноміальний розподіл з імовірністю успіху \\(0.8\\)\n\n\n\n\n\nДля того, щоб побудувати двосторонній критерій, потрібно знайти ліворуч і праворуч області, площа яких становить не більше, ніж \\(\\frac{\\alpha}{2}\\). Для правого боку ми вже розв’язували таку задачу, розв’яжемо для лівого.\nШукаємо \\(C\\), таке що\n\\[\nP(Q(\\xi) \\leqslant C) \\leqslant \\frac{\\alpha}{2}\n\\]\nСпочатку знайдемо перше число, де ймовірність \\(\\geqslant \\frac{\\alpha}{2}\\). А це за визначенням \\(\\frac{\\alpha}{2}\\)-квантиль. Достатньо взяти попереднє число, і воно буде задовольняти нашій умові.\n\n\n\n\nЛістинг 1.15: Знаходження критичного значення для двостороннього критерію\n\n\ndef two_sided_criterion_nonsym(n, mu, alpha):\n    binom_h0 = binom(n=n, p=mu)\n    c2 = binom_h0.ppf(1 - alpha/2) + 1\n    c1 = binom_h0.ppf(alpha/2) - 1\n    return c1, c2\n\ntwo_sided_criterion_nonsym(30, 0.8, 0.05)\n\n\n\n\n(18.0, 29.0)\n\n\nОтже, наш критерій для перевірки гіпотези\n\\[\nH_0: \\mu = 0.8\n\\]\n\\[\nH_1: \\mu \\neq 0.8\n\\]\nмає вигляд\n\\[\nS = \\{Q(\\xi) \\leqslant 18\\} \\cup \\{Q(\\xi) \\geqslant 29\\}\n\\]\nТут межа \\(29\\) уже має логічний вигляд, бо треба спростувати 80% орлів/успіхів, а для цього потрібна велика їхня кількість.\nЗобразимо критичну область на графіку.\n\nC1, C2 = two_sided_criterion_nonsym(30, 0.8, 0.05)\n\nplt.figure(figsize=(6, 4))\nplt.bar(np.arange(31), probs, color=turquoise, label=\"Binom(30, 0.8)\")\nplt.bar(np.arange(31)[np.arange(31) &lt;= C1], probs[np.arange(31) &lt;= C1], color=red_pink, label=\"Критичне значення\")\nplt.bar(np.arange(31)[np.arange(31) &gt;= C2], probs[np.arange(31) &gt;= C2], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.legend(fontsize = '8', loc = 'upper left')\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.8: Двостороння критична область для критерію \\(C_1 = 18, C_2 = 29\\)\n\n\n\n\n\n\n\n1.5.4 \\(p\\)-значення для несиметричного розподілу\nЦей критерій — об’єднання двох критеріїв рівня значущості \\(\\frac{\\alpha}{2}\\), для кожного з яких можна порахувати \\(p\\)-значення. Позначимо їх як \\(p_1, p_2\\). Перший критерій відкидається при \\(p_1 \\leqslant \\frac{\\alpha}{2}\\), другий при \\(p_2 \\leqslant \\frac{\\alpha}{2}\\). А наш об’єднаний, коли виконано одну з цих умов, тобто\n\\[\n2p_1 \\leqslant \\alpha \\vee 2p_2 \\leqslant \\alpha \\Leftrightarrow 2 \\cdot \\min(p_1, p_2) \\leqslant \\alpha\n\\]\nОтже, можна рахувати \\(p\\)-значення як \\(2 \\min(p_1, p_2)\\) й порівнювати з \\(\\alpha\\).\nПроведемо аналогію із симетричним випадком: якщо сума опинилася в лівій частині, то потрібно порахувати \\(p\\)-значення лівого критерію і помножити на 2. Якщо сума опинилася в правій частині, то потрібно порахувати \\(p\\)-значення правого критерію і помножити на 2.\n\n\n\n\nЛістинг 1.16: Обчислення \\(p\\)-значення для двостороннього критерію з несиметричним розподілом\n\n\ndef pvalue_two_sided(n, q, mu=0.5):\n    binom_h0 = binom(n=n, p=mu)\n    pvalue_left = binom_h0.cdf(q)\n    pvalue_right = 1 - binom_h0.cdf(q - 1)\n    return 2 * min(pvalue_left, pvalue_right)\n\npvalue_two_sided(30, 28, 0.8)\n\n\n\n\n0.08835797030399428\n\n\nВидно, що \\(p\\)-значення \\(&gt; 0.05\\), отже, на рівні значущості \\(0.05\\) навіть \\(28\\) успіхів недостатньо, щоб відкинути ймовірність успіху в \\(80\\%\\).\nЗауважимо, що ця ж функція працює і для симетричного випадку, повертаючи той самий результат.\n\n\n\n\nЛістинг 1.17: Обчислення \\(p\\)-значення для двостороннього критерію з симетричним розподілом\n\n\npvalue_two_sided(n=30, q=20, mu=0.5)\n\n\n\n\n0.09873714670538902\n\n\n\n\n\n\nЛістинг 1.18: Знаходження \\(p\\)-значення для двостороннього критерію\n\n\npvalue_two_sided_sym(n=30, q=20)\n\n\n\n\n0.09873714670538904",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#готові-функції",
    "href": "binom.html#готові-функції",
    "title": "1  Біноміальний критерій",
    "section": "1.6 Готові функції",
    "text": "1.6 Готові функції\nЗвісно, можна використати готові функції з бібліотеки scipy. Для цього використаємо функцію binomtest, котра має параметри:\n\nk — кількість успіхів\nn — кількість спостережень\np — ймовірність успіху\nalternative — тип гіпотези:\n\ntwo-sided: двостороння\ngreater: правостороння\nless: лівостороння\n\n\n\n\n\nЛістинг 1.19\n\n\nfrom scipy.stats import binomtest\n\nresult = binomtest(19, 30, 0.5, alternative='two-sided')\n\nprint(f\"Статистика: {result.statistic:.2f}\")\nprint(f\"p-значення: {result.pvalue:.4f}\")\n\nСтатистика: 0.63\np-значення: 0.2005",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#висновки",
    "href": "binom.html#висновки",
    "title": "1  Біноміальний критерій",
    "section": "1.7 Висновки",
    "text": "1.7 Висновки\nМи розглянули, як можна використовувати біноміальний розподіл для перевірки гіпотези про ймовірність успіху. Для цього ми визначили критерій, критичну область, \\(p\\)-значення. Показали, як можна використовувати ці поняття для різних видів гіпотез: односторонніх, двосторонніх, симетричних та несиметричних.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#питання-для-самоперевірки",
    "href": "binom.html#питання-для-самоперевірки",
    "title": "1  Біноміальний критерій",
    "section": "1.8 Питання для самоперевірки",
    "text": "1.8 Питання для самоперевірки\n\nЯкі гіпотези можна перевірити за допомогою біноміального розподілу?\nЯк визначити критичну область для критерію?\nЯк визначити \\(p\\)-значення для критерію?\nЯк визначити критичну область для двостороннього критерію?\nЯк визначити \\(p\\)-значення для двостороннього критерію?\nЯк визначити критичну область для несиметричного розподілу?\nЯк визначити \\(p\\)-значення для несиметричного розподілу?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#footnotes",
    "href": "binom.html#footnotes",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "У статистиці \\(\\hat{\\mu}\\) позначається як оцінка параметра \\(\\mu\\).↩︎\nМетод integers() генерує випадкові цілі числа в заданому діапазоні. Аргумент endpoint вказує, що верхня межа включається у діапазон.↩︎\nРозподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.↩︎\nБіноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума \\(n\\) незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.↩︎\nАнгл. cyan, від грец. κυανouς — “блакитний”, “лазуровий”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "power.html",
    "href": "power.html",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1 Статистична потужність",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#статистична-потужність",
    "href": "power.html#статистична-потужність",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1.1 Хибно негативні помилки\nРаніше під час побудови критеріїв ми звертали увагу тільки на \\(\\alpha\\), рівень значущості критерію. Але цей параметр контролює лише хибнопозитивну помилку (False Positive), а саме ймовірність, що критерій прийме \\(H_1\\) за умови вірності \\(H_0\\).\nАле є ще один вид помилок, які може допустити критерій — хибно негативні помилки (False Negative). Це випадки, коли критерій приймає \\(H_0\\) за умови вірності \\(H_1\\). Це важливо, оскільки вони можуть вказувати на те, що критерій не чутливий до змін, які відбуваються в даних.\nВипадок, коли ймовірність FPR \\(&lt; \\alpha\\), але при цьому ймовірність хибно негативні помилки (False Negative Rate, FNR) величезна, можна навести легко. Для цього достатньо ніколи не відкидати гіпотезу, взявши критерій \\(S \\equiv 0\\).\nНаведемо приклад, коли помилки False Negative відбуваються не завжди, але критерії є все одно нечутливими.\n\n\n2.1.2 Критерій пори року\nПоставимо гіпотезу про те, що зараз на вулиці літо. Для перевірки можна було б, звісно, подивитися в календар, але ми зробимо інакше.\n\\[\nH_0: \\text{ на вулиці літо}\n\\]\n\\[\nH_1: \\text{ на вулиці не літо}\n\\]\nПодивимося у вікно і визначимо, чи йде там сніг. Якщо він йде, то це непоганий доказ того, що зараз не літо, а отже можна відкинути \\(H_0\\).\nПорахуємо FPR та FNR для цього критерію. Ми знаємо, що влітку сніг іде дуже рідко (ймовірність помилки нижча за \\(0.1\\%\\)), тож це точно критерій рівня значущості \\(0.001\\), чого зазвичай достатньо для критеріїв.\n\\[\nFPR(S) = P(\\text{йде сніг}\\ |\\ \\text{сьогодні літо}) &lt; 0.001\n\\]\nАле що з FNR? Розглянемо конкретний випадок: зараз вересень. Оскільки у вересні майже завжди немає снігу, можна сказати, що FNR більша за \\(90\\%\\), отже, цей критерій насправді мало дієвий.\n\\[\nFNR(S) = P(\\text{не йде сніг}\\ |\\ \\text{зараз вересень}) &gt; 0.9\n\\]\nСформулюємо інший критерій рівня значущості \\(\\alpha\\), причому в цьому разі рівень значущості можна вибрати довільним.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо монетка з імовірністю орла } \\alpha \\text{ випала орлом} \\\\\n    0, \\text{ інакше}\n\\end{cases}\n\\]\nВиходить, цей критерій випадковий, і він не використовує взагалі жодної інформації про погоду. Однак вимогам до рівня значущості він задовольняє.\n\\[\nFPR = P(\\text{випав орел}\\ |\\ \\text{сьогодні літо}) = P(\\text{випав орел}) = \\alpha\n\\]\nОбчислимо FNR.\n\\[\nFNR = P(\\text{не випав орел}\\ |\\ \\text{сьогодні не літо}) = P(\\text{не випав орел}) = 1 - \\alpha\n\\]\nЗа \\(\\alpha = 0.001\\), як у першому випадку, отримуємо ймовірність FNR \\(0.999 &gt; 0.9\\), тобто за однакового рівня значущості з першим критерієм, другий критерій частіше припускається хибно негативної помилки.\n\n\n2.1.3 Потужність\nУ статистиці заведено позитивним результатом вважати відкидання нульової гіпотези, бо зазвичай підтвердження альтернативи означає наявність бізнес-результату. Тому вважається хорошим критерій, який частіше дає змогу виявити бізнес-результат. І рахують тоді не ймовірність хибно негативної помилки, а потужність, що дорівнює ймовірності відкинути нульову гіпотезу за вірності \\(H_1\\), тобто ймовірність істинно позитивного результату (True Positive Rate, TPR).\n\\[\n\\text{Power}_S = 1 - FNR\n\\tag{2.1}\\]\nКоли альтернатива \\(H_1\\) складається з множини результатів, потужність розглядають як функцію від результату. Наприклад, можна порахувати потужність першого та другого критеріїв взимку й восени.\n\\[\n\\text{Power}_S(\\mu) = 1 - FNR(\\mu)\n\\]\nПерший критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{їде сніг } | \\text{ травень}) \\approx 0.00001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{їде сніг } | \\text{ жовтень}) \\approx 0.1\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{їде сніг } | \\text{ січень}) \\approx 0.5\n\\]\nДругий критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{випав орел } | \\text{ травень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{випав орел } | \\text{ жовтень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{випав орел } | \\text{ січень}) = \\alpha = 0.001\n\\]\nЗазвичай завдання пошуку найкращого критерію формулюється як пошук якомога потужнішого критерію за заданого рівня значущості \\(FPR \\leqslant \\alpha\\). Але ми сказали, що потужність — функція від параметра, у нашому випадку від місяця.\nЯкщо ми застосовуватимемо критерій у січні, то потужнішим буде перший критерій, а якщо в травні, то потужнішим буде другий критерій. Тому потрібно розуміти, коли буде застосовуватися критерій, а отже, ми шукаємо найпотужніший критерій у галузі, яка нас цікавить.\nХоча в реальності в травні потужність обох критеріїв настільки низька, що вони просто не приносять користі, й використовувати їх не має сенсу.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#потужність-для-біноміального-розподілу",
    "href": "power.html#потужність-для-біноміального-розподілу",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.2 Потужність для біноміального розподілу",
    "text": "2.2 Потужність для біноміального розподілу\nЗастосуємо нові знання про потужність для нашої задачі з освітнім сервісом. З бізнес-міркувань ми вже вибрали \\(\\alpha = 0.05\\), а отже, знаємо, що ми неправильно відкидаємо гіпотезу \\(H_0:\\ \\mu = 0.5\\) з ймовірністю не більше, ніж \\(5\\%\\). Тобто цим обмежена ймовірність хибно позитивної помилки.\nА з якою ймовірністю ми будемо правильно відкидати гіпотезу? І яка в нас буде ймовірність хибно негативної помилки? На це запитання якраз відповість формула потужності.\nЗгадаймо критерій, за яким ми приймаємо рішення:\n\\[\nQ(\\xi) = \\sum\\limits_{i=1}^n \\xi_i - \\text{кількість підписок}\n\\]\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\nТобто якщо отримуємо хоча б \\(20\\) успішних підписок, то відкидаємо \\({H}_0\\).\nЗауважимо, що потужність залежить від того, яке значення \\(\\mu\\) у нашій генеральній сукупності. Зафіксуємо спочатку параметр \\(\\mu = 0.6\\) й порахуємо потужність для нього. Якщо істинний параметр такий, то статистика \\(Q\\) має розподіл \\(Binom(30, 0.6)\\).\n\nbinom_h0 = binom(n=30, p=0.5)\nbinom_alternative = binom(n=30, p=0.6)\n\nx_grid = np.arange(1, 31)\ncrit_reg = x_grid &gt;= 20\n\nprobs_h0 = binom_h0.pmf(x_grid)\nplt.bar(x_grid, probs_h0, color=turquoise, label='PMF, $Binom(0.5, 30)$')\n\nprobs_alternative = binom_alternative.pmf(x_grid)\nplt.bar(x_grid, probs_alternative, color=slate, label='PMF, $Binom(0.6, 30)$')\nplt.bar(x_grid[crit_reg], probs_alternative[crit_reg], color=red_pink, label='Критична область')\n\nplt.legend(fontsize=8)\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.1: Потужність критерію для \\(\\mu = 0.6\\)\n\n\n\n\n\nЯк і раніше, нас цікавить імовірність отримати \\(20\\) або більше успіхів. Але якщо раніше ми дивилися на неї для розподілу з \\(\\mu=0.5\\) й хотіли, щоб вона була меншою за \\(5\\%\\), то тепер ми дивимося за \\(\\mu = 0.6\\) та прагнемо зробити цю величину якомога більшою. Порівняно з обчисленням FPR формула не зміниться, змінюється тільки \\(\\mu\\)\n\n\n\n\nЛістинг 2.1: Обчислення потужності критерію\n\n\ncritical_value = 20\npower = 1 - binom(n=30, p=0.6).cdf(critical_value - 1)\nfpr   = 1 - binom(n=30, p=0.5).cdf(critical_value - 1)\n\nprint(f\"Хибно позитивна помилка: {fpr:.1%}\")\nprint(f\"Потужність: {power:.1%}\")\n\n\n\n\nХибно позитивна помилка: 4.9%\nПотужність: 29.1%\n\n\nВидно, що потужність близько \\(30\\%\\). Це досить маленьке значення, адже якщо наш продукт прибутковий, то ми побачимо це за допомогою нашого тесту тільки з імовірністю в \\(30\\) відсотків. Ми легко можемо пропустити ефект.\nЩо ж можна зробити, щоб зробити потужність вищою? Щоб розібратися, реалізуємо функцію потужності в загальному вигляді.\n\n\n\n\nЛістинг 2.2: Обчислення потужності критерію для загального випадку\n\n\ndef get_stat_power(N, mu_h0, mu_alternative, alpha):\n    '''Обчислює статистичну потужність критерію для біноміального розподілу\n    \n    Параметри:\n        N - кількість бернуллієвських експериментів (розмір вибірки)\n        mu_h0 - імовірність успіху в нульовій гіпотезі\n        mu_alternative - передбачувана ймовірність успіху в експерименті\n        alpha - рівень значущості критерію\n    '''\n    binom_h0 = binom(n=N, p=mu_h0)\n    binom_alternative = binom(n=N, p=mu_alternative)\n    critical_value = binom_h0.ppf(1 - alpha) + 1\n    return 1 - binom_alternative.cdf(critical_value - 1) \n\nget_stat_power(30, 0.5, 0.6, alpha=0.05)\n\n\n\n\n0.2914718612234968\n\n\nКоли в житті ми спостерігаємо якесь явище і бачимо його лише кілька разів, ми не впевнені в тому, що воно не випадкове. Якщо ж бачимо його досить часто, то вже складаємо закономірності. Так і в статистиці. Коли ми подивилися на 30 потенційних підписок, ми помічаємо, що частка доставок більше половини. Але ми все ще не впевнені. Щоб отримати більше впевненості, потрібно провести більше спостережень, тобто знайти більше пробних клієнтів.\nПодивимося, що буде, якщо ми проведемо експеримент на 300 клієнтах.\n\n\n\n\nЛістинг 2.3: Обчислення потужності критерію для 300 клієнтів\n\n\nget_stat_power(300, 0.5, 0.6, alpha=0.05)\n\n\n\n\n0.9655326717180749\n\n\nБачимо, що потужність уже дуже близька до \\(100\\%\\). Але провести 300 пробних занять набагато затратніше, ніж 30. І за ресурсами, і за часом. Тому зазвичай балансують між потужністю і тривалістю/витратами експерименту.\nПрийнято вважати, що прийнятною для роботи потужністю вважається \\(80\\%\\). Подивимося, як змінюється потужність при зростанні розміру вибірки, і скільки потрібно провести експериментів, щоб детектувати ефект при \\(\\mu = 0.6\\) у \\(80\\%\\) випадків.\n\nn_grid = np.arange(10, 600, 10)\npower = get_stat_power(n_grid, 0.5, 0.6, alpha=0.05)\n\nplt.xlabel('Кількість пробних занять')\nplt.ylabel('Потжність')\n\nplt.plot(n_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_n = n_grid[power &gt;= 0.8].min()\nplt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.2: Залежність потужності від розміру вибірки для \\(\\mu = 0.6\\)\n\n\n\n\n\nБачимо, що для потужності в \\(80\\%\\) достатньо набрати 160 пробних занять.\nА що, якщо ми хочемо детектувати ще менший ефект? Наприклад, якщо хочемо відкидати гіпотезу за \\(\\mu = 0.51\\). Часто поліпшення ймовірності успіху на \\(1\\%\\) може бути значущим для продукту, тому це питання не позбавлене сенсу.\n\nn_grid = np.arange(10, 30000, 59)\npower = get_stat_power(n_grid, 0.5, 0.51, alpha=0.05)\n\nplt.xlabel('Кількість пробних занять', fontsize=8)\nplt.ylabel('Потжність', fontsize=8)\n\nplt.plot(n_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_n = n_grid[power &gt;= 0.8].min()\nplt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.3: Залежність потужності від розміру вибірки для \\(\\mu = 0.51\\)\n\n\n\n\n\nБачимо, що потрібно понад 15 тисяч клієнтів, щоб детектувати такий ефект! Дуже складно знайти стільки пробних клієнтів. Але потрібно замислитися над питанням, а чи варто це робити? У нашому випадку, якщо ймовірність успіху \\(51\\%\\), то прибуток із замовлень буде невеликий, і вкладення інвесторів, звісно, окупатимуться, але дуже довго. Тому збільшення на \\(1%\\) для нашого завдання не значуще практично, а отже, не потрібно намагатися набирати 15 тисяч людей, а можна зупинитися і на 160.\nПеред кожним експериментом аналітику варто замислюватися над питанням тривалості тесту і кількості учасників. Для цього потрібно зрозуміти:\n\nЯкий ефект є для завдання практично значущим?\nСкільки знадобиться випробовуваних, щоб детектувати цей ефект частіше, ніж у \\(80\\%\\) випадків?\n\n\nЗ графіків видно, що для детектування меншого ефекту потрібен більший розмір вибірки. Подивимося, як для фіксованого \\(N=30\\) змінюється потужність для різних параметрів \\(\\mu\\).\n\nmu_grid = np.linspace(0.5, 0.9, 100)\npower = get_stat_power(30, 0.5, mu_grid, alpha=0.05)\n\nplt.xlabel('Ймовірність успіху')\nplt.ylabel('Потужність')\n\nplt.plot(mu_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_mu = mu_grid[power &gt;= 0.8].min()\nplt.axvline(min_mu, ls='--', color=slate, label=f'$\\mu = {min_mu:.2f}$')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.4: Залежність потужності від параметра \\(\\mu\\)\n\n\n\n\n\nУ нашому експерименті ми добре детектуємо ефект, тільки якщо ймовірність успіху в генеральній сукупності хоча б \\(72\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#мінімальна-величина-ефекту",
    "href": "power.html#мінімальна-величина-ефекту",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.3 Мінімальна величина ефекту",
    "text": "2.3 Мінімальна величина ефекту\nВище на Рисунок 2.4 ми побачили, що з хорошою потужністю понад \\(80\\%\\) ми можемо помітити ефект у \\(22\\) процентних пункти. Причому це можна порахувати навіть до проведення експерименту. У нашому випадку таке збільшення успішності щодо \\(0.5\\) цілком можливо, і з ним можна працювати. Але коли аналітики перевіряють зміни, найчастіше очікуваний ефект коливається в районі одного, максимум двох відсотків! Для подібних змін не підійде обрана постановка експерименту, а значить і проводити його не має сенсу.\nТому перед запуском експериментів аналітики повідомляють мінімальну величину ефекту, яку можна задетектувати (Minimal Detectable Effect, MDE). У нашому випадку \\(MDE = +22\\) процентних пункти.\nБільш формально, MDE для гіпотези \\(H_0: \\mu = \\mu_0\\) — це мінімальний ефект \\(\\delta\\), за якого критерій рівня значущості \\(\\alpha\\) для перевірки цієї гіпотези за істинного параметра \\(\\mu = \\mu_0 + \\delta\\) та розміру вибірки \\(N\\) відкидатиме \\({H}_0\\) з потужністю більшою, ніж \\(1 - \\beta\\).\nНайчастіше беруть \\(1 - \\beta = 80\\%\\). Напишемо функцію, яка обчислюватиме MDE підбором.\n\n\n\n\nЛістинг 2.4: Обчислення MDE\n\n\ndef binom_test_mde_one_sided(N, mu0, alpha=0.05, min_power=0.8):\n    delta_grid = np.linspace(0, 1 - mu0, 500) \n    power = get_stat_power(N, mu0, mu0 + delta_grid, alpha=alpha)\n    fit_delta = delta_grid[power &gt;= min_power]\n    return fit_delta[0]\n\nbinom_test_mde_one_sided(30, 0.5)\n\n\n\n\n0.21843687374749496\n\n\nРезультат збігається з обчисленнями за графіком Рисунок 2.4. Тобто ми можемо детектувати ефект у \\(22\\) процентних пункти.\nЗазвичай MDE розраховують не просто так, а нерозривно з ним іде питання про визначення розміру вибірки.\nУ нашому завданні ми знайшли \\(30\\) клієнтів, не обчислюючи спочатку, скільки їх знадобиться. Але що якщо отриманий MDE занадто великий й потрібно зробити його меншим, оскільки очікувані зміни набагато менші? Тоді вирішується зворотне завдання, За необхідним MDE визначити обсяг вибірки. Якщо ми говоримо, що хочемо детектувати +10 в.п., тобто 60% успішних підписок, то потрібно знайти 160 тестових клієнтів, це видно з попередніх графіків. Якщо 30 осіб нам, наприклад, шукати місяць, такий тест може затягнутися майже на півроку. Тому варто подумати про те, щоб виділити додаткові ресурси на пошук клієнтів, наприклад, залучити маркетологів.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#довірчі-інтервали",
    "href": "power.html#довірчі-інтервали",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.4 Довірчі інтервали",
    "text": "2.4 Довірчі інтервали\nРаніше ми навчилися перевіряти гіпотезу \\({H}_0: \\mu = 0.5\\). Як відповідь ми отримуємо лише вердикт “відкидаємо \\({H}_0\\)” або “не відкидаємо \\({H}_0\\)”. Однак у вибірці міститься набагато більше інформації, й ми можемо більше зрозуміти про параметр, ніж порівняння з числом \\(0.5\\).\nЯкщо гіпотеза \\({H}_0\\) не відкидається, це означає, що значення \\(\\mu = 0.5\\) припустиме для нашої вибірки. Отримані значення можна пояснити значенням \\(\\mu = 0.5\\). Але якщо у нас є механізм перевірки для будь-якого \\(\\mu\\), ми можемо для всіх значень дізнатися, які з них допустимі, і отримати множину можливих значень \\(\\mu\\). Така множина називається довірчим інтервалом.\nДовірчий інтервал рівня \\(1 - \\alpha\\) — множина значень параметра \\(\\mu_0\\), для яких гіпотеза \\(\\mu = \\mu_0\\) не відкидається критерієм рівня значущості \\(\\alpha\\).\nЗ визначення випливає, що різні критерії можуть породжувати різні довірчі інтервали. У цій частині розглянемо, які інтервали породжуються двостороннім критерієм. Для цього з кроком \\(0.001\\) переберемо значення \\(\\mu \\in [0, 1]\\) і перевіримо гіпотези.\n\n\n\n\nЛістинг 2.5: Довірчі інтервали для біноміального розподілу\n\n\ndef two_sided_criterion_nonsym(n, mu, alpha):\n    binom_h0 = binom(n=n, p=mu)\n    c2 = binom_h0.ppf(1 - alpha/2) + 1\n    c1 = binom_h0.ppf(alpha/2) - 1\n    return c1, c2\n\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n\n\n95% довірчий інтервал: [0.439 - 0.8]\n\n\n\nФункція, що обчислює критичні значення для двостороннього критерію.\nКількість успішних підписок.\nСітка значень \\(\\mu\\).\nСписок значень \\(\\mu\\), для яких гіпотеза не відкидається.\nПеребір значень \\(\\mu\\).\n\n\nОтримавши такий інтервал, ми відразу можемо зробити висновок, що гіпотеза \\({H}_0: \\mu = 0.5\\) не відкидається, оскільки \\(0.5\\) лежить у довірчому інтервалі. Але при цьому відразу зрозуміло, що \\(\\mu \\neq 0.4\\) на рівні значущості \\(\\alpha\\).\nЗвичайно ж, у довірчому інтервалі лежить значення \\(\\mu = \\frac{19}{30}\\), для якого \\(19\\) успіхів — це найбільш правдоподібний результат. При цьому інтервал несиметричний щодо точки \\(\\frac{19}{30}\\).\nПодивимося, як можна візуально знайти межу інтервалу. Ми отримали \\(19\\) успіхів. Для кожного \\(\\mu_0\\) статистика \\(Q\\) має розподіл \\(Binom(30, \\mu_0)\\). Будемо малювати цей розподіл і дивитися, чи потрапляє \\(19\\) у критичну область.\n\n\n\n\nЛістинг 2.6: Довірчі інтервали для біноміального розподілу\n\n\nmus_h0 = [0.2, 0.438, 0.439, 0.8, 0.81, 0.9]\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\nfor mu_h0, ax in zip(mus_h0, axes.flatten()):\n    binom_h0 = binom(n=30, p=mu_h0)\n    probs = binom_h0.pmf(x_grid)\n\n    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    crit_reg = (x_grid &lt;= c1) | (x_grid &gt;= c2)\n    ax.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\n\n    is_rejection = success_cnt &lt;= c1 or success_cnt &gt;= c2\n    ax.axvline(success_cnt, ls='--', label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не видхилено'), color='gray', alpha=0.4)\n\n    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Довірчі інтервали для біноміального розподілу\n\n\n\n\n\nВидно, що зі зростанням \\(\\mu_0\\) гістограма зсувається вправо. І спочатку \\(19\\) потрапляє в праву критичну область. Потім, починаючи з точки \\(0.439\\), значення \\(19\\) вже опиняється поза критичною областю, і тільки з \\(\\mu_0 = 0.81\\) починає потрапляти в ліву критичну область.\nТаким чином, ліва межа довірчого інтервалу — це перша точка, коли значення статистики перестало потрапляти до критичної області, а права межа - остання точка, коли значення не потрапляє до правої критичної області.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#односторонні-довірчі-інтервали",
    "href": "power.html#односторонні-довірчі-інтервали",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.5 Односторонні довірчі інтервали",
    "text": "2.5 Односторонні довірчі інтервали\nНасправді, двосторонній критерій потрібен вкрай рідко. Контролювати хибно похитивну помилку нам потрібно тільки для відхилень у бік, корисний для бізнесу. У випадку завдання з освітнім сервісом це отримання більшої конверсії в успіх.\nСпробуємо скористатися одностороннім критерієм для побудови довірчого інтервалу.\n\n\n\n\nЛістинг 2.7: Односторонні довірчі інтервали для біноміального розподілу\n\n\ndef make_binom_criterion(n, mu=0.5, alpha=0.05):\n    binom_h0 = binom(n=n, p=mu)\n    q = binom_h0.ppf(1 - alpha)\n    return q + 1\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1.001, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n\n\n95% довірчий інтервал: [0.467 - 1.0]\n\n\nКоли ми використовували двосторонній інтервал, ми отримали ліву межу \\(0.439 &lt; 0.467\\). Виходить, що односторонній інтервал з точки зору лівої межі дає нам більше інформації. При цьому з точки зору правої межі ми втрачаємо інформацію зовсім. Вона дорівнює 1 просто тому, що ймовірність не може бути більшою.\nНасправді зазвичай на праву межу не дивляться під час аналізу, коли ми шукаємо позитивний ефект.\nПрипустимо, ми отримали не \\(19\\) успіхів, а \\(22\\). Побудуємо 2 види інтервалів.\n\n\n\n\nЛістинг 2.8: Двосторонній довірчий інтервал для \\(22\\) успіхів\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Двосторонній 95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\nДвосторонній 95% довірчий інтервал: [0.542 - 0.877]\n\n\n\n\n\n\nЛістинг 2.9: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1.001, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Односторонній 95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\nОдносторонній 95% довірчий інтервал: [0.571 - 1.000]\n\n\nЗа обома довірчими інтервалами ми робимо висновок, що конверсія значимо відрізняється від \\(50\\%\\). Але односторонній інтервал дає кращу нижню оцінку на ймовірність успіху. Ми можемо зрозуміти, що наша конверсія більша за \\(57\\%\\). А інформація з двостороннього інтервалу про те, що ймовірність менша за \\(88\\%\\) не додає нам користі.\nНавіщо ж ми тоді взагалі використовуємо двосторонній інтервал? Щоб це зрозуміти, подивимося, як виглядають візуально межі для одностороннього інтервалу.\n\n\n\n\nЛістинг 2.10: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\nfor mu_h0, ax in zip(mus_h0, axes.flatten()):\n    binom_h0 = binom(n=30, p=mu_h0)\n    probs = binom_h0.pmf(x_grid)\n\n    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n    c = make_binom_criterion(30, mu_h0, alpha=0.05)\n    crit_reg = (x_grid &gt;= c)\n    ax.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\n\n    is_rejection = success_cnt &gt;= c\n    ax.axvline(success_cnt, ls='--', label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не відхилено'), color='gray', alpha=0.4)\n\n    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\n\n\n\nПорівняно з Рисунок 2.5 ми бачимо, що права критична область стала більшою через те, що там тепер знаходиться не \\(2.5\\%\\), а \\(5\\%\\) від усіх значень. При цьому лівої критичної області просто не існує, тому за великих \\(\\mu\\) не відбувається потрапляння \\(19\\) до неї, а значить ми не відкидаємо гіпотезу.\nЗауважимо, що якби ми будували двосторонній інтервал, але з удвічі більшою \\(\\alpha\\), потрапляння в праву критичну область траплялися б за тих самих \\(\\mu\\), що й в односторонньому критерії. Тому часто для пошуку односторонньої межі будують двосторонній довірчий інтервал із більшою \\(\\alpha\\), ігноруючи при цьому праву межу. Це зручно, оскільки можна користуватися тільки однією функцією для критерію.\nПеревіримо, що вийде за \\(\\alpha = 0.1\\).\n\n\n\n\nЛістинг 2.11: Двосторонній довірчий інтервал для \\(22\\) успіхів з \\(\\alpha = 0.1\\)\n\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.1)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\n95% довірчий інтервал: [0.467 - 0.778]\n\n\nБачимо, що отримали таку саму ліву межу, як і в односторонньому інтервалі.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#властивості-довірчих-інтервалів",
    "href": "power.html#властивості-довірчих-інтервалів",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.6 Властивості довірчих інтервалів",
    "text": "2.6 Властивості довірчих інтервалів\nЗгадаймо визначення довірчого інтервалу.\nНехай є критерій \\(S = \\{Q(\\xi) \\leqslant C\\}\\) рівня значущості \\(\\alpha\\) для перевірки гіпотези \\({H}_0: \\mu = \\mu_0\\), \\(Q\\) — статистика критерію, а \\(q\\) — її реалізація на конкретній вибірці \\(\\xi = \\xi_1, \\dots, \\xi_n\\). Тоді довірчим інтервалом називається множина таких \\(\\mu_0\\), на яких критерій \\(S\\) не відкидає гіпотезу \\({H}_0: \\mu = \\mu_0\\).\nПроцедура підрахунку інтервалу — це довгий перебір значень із деяким кроком. Але це все ще залишається деякою функцією від вибірки, тобто статистикою й випадковою величиною, причому її розподіл залежить від статистики \\(Q\\), а отже, і від початкової вибірки, та від параметра \\(\\mu\\) у генеральній сукупності.\nПозначимо межі інтервалу за \\(\\mathcal{L}(Q), \\mathcal{R}(Q)\\) — статистики критерію, які відповідають лівій та правій межі інтервалу.\n\n2.6.1 Ймовірність попадання в інтервал\nЯким би не було істинне значення \\(\\mu = \\mu_0\\), ймовірність того, що воно перебуває між \\(\\mathcal{L}(Q)\\) та \\(\\mathcal{R}(Q)\\), не нижча, ніж \\(1 - \\alpha\\). Значення \\(1 - \\alpha\\) називається рівнем довіри довірчого інтервалу.\n\\[\nP(\\mathcal{L}(Q) &lt; \\mu_0 &lt; \\mathcal{R}(Q)) \\geqslant 1 - \\alpha\n\\tag{2.2}\\]\nВажливо, що випадковість тут прихована саме в \\(\\mathcal{L}\\) і \\(\\mathcal{R}\\), а не в \\(\\mu_0\\). Параметр \\(\\mu_0\\) невідомий, але ми припускаємо його константним і не випадковим.\nПеревіримо справедливість цієї властивості. Для цього зафіксуємо \\(\\mu_0\\) й проведемо множину експериментів:\n\nГенеруємо вибірку з розподілу з параметром \\(\\mu_0\\).\nОбчислюємо статистику \\(q\\).\nРахуємо довірчий інтервал для \\(\\alpha = 0.05\\).\n\n\nПеревіряємо, що частка випадків, коли параметр \\(\\mu_0\\) опинився всередині інтервалу, хоча б \\(95\\%\\)\n\n\n\nЛістинг 2.12: Перевірка властивості довірчого інтервалу.\n\n\n\nimport time\n\nstart_time = time.time()\n\ndef my_binomial_confint(n, alpha, q):\n    mu_grid = np.arange(0, 1.1, 0.1) # np.arange(0, 1.001, 0.001)\n    mu_no_rejection = []\n\n    for mu_h0 in mu_grid:\n        c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n        if q &gt; c1 and q &lt; c2:\n            mu_no_rejection.append(mu_h0)\n\n    return min(mu_no_rejection), max(mu_no_rejection)\n\nN_EXPERIMENTS = 1000\nSAMPLE_SIZE = 30\nlatent_mu = 0.5\nbinom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\nconfint_fail_cases = 0\n\nfor i in range(N_EXPERIMENTS):\n    q = binom_true.rvs()\n    L, R = my_binomial_confint(n=SAMPLE_SIZE, alpha=0.05, q=q)\n    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\nsuccess_cases = round(100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS, 2)\n\nprint(f\"Відсоток успішних випадків: {success_cases}%\")\n\nend_time = time.time()\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\nВідсоток успішних випадків: 61.4%\nЧас виконання: 3.7664 секунди\n\n\n\n\n\nЗазначимо, що цей код працював понад 5 хвилин. Це через те, що під час кожного експерименту потрібно побудувати довірчий інтервал, а значить перевірити 1000 можливих параметрів \\(\\mu_0\\).\nБачимо, що властивість виконалася. Ми очікували хоча б \\(95\\%\\) влучень, отримали навіть \\(61.4\\%\\). Насправді це значно більше, ніж ми очікували. Це відбувається через дискретність розподілу. З тієї ж причини під час пошуку критичної області ми не могли вибрати стовпці із сумарною висотою рівно \\(\\alpha\\).\n\n2.6.1.1 Доведення\nПід час формулювання властивості ми припускаємо, що є деяка \\(\\mu_0\\) — ймовірність успіху в генеральній сукупності. Коли ми проводимо штучний експеримент, ми фіксуємо її й можемо вважати істинною \\(\\mu\\).\nЩоразу ми генеруємо \\(Q \\sim Binom(\\mu_0, 30)\\) й перевіряємо, чи потрапила \\(\\mu_0\\) у довірчий інтервал. Намалюємо розподіл статистики \\(Q\\), який уже нам знайомий. Намалюємо й область ймовірності \\(\\leqslant \\alpha\\), як ми робили це раніше.\n\n\n\n\nЛістинг 2.13: Розподіл статистики при істинній ймовірності успіху\n\n\nmu0 = 0.5\nbinom_mu0 = binom(n=30, p=mu0)\nprobs = binom_mu0.pmf(x_grid)\n\nplt.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu0}, 30)$')\nc1, c2 = two_sided_criterion_nonsym(30, mu0, alpha=0.05)\ncrit_reg = (x_grid &gt;= c2) | (x_grid &lt;= c1)\nplt.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Розподіл статистики при істинній ймовірності успіху\n\n\n\n\n\nНехай реалізувалося значення статистики \\(q\\). За такою вибіркою можна побудувати довірчий інтервал на \\(\\mu\\). Він буде якось розташований, але зараз нас цікавить, чи потрапить у нього \\(\\mu_0\\). За визначенням потрапляння в інтервал відбудеться, якщо не відкидається гіпотеза \\({H}_0:\\ \\mu = \\mu_0\\). Але тоді за справедливості \\({H}_0\\) статистика має той розподіл, що і на малюнку. І гіпотеза відкидається тільки в разі потрапляння в критичну область, а це трапляється з ймовірністю \\(\\leqslant \\alpha\\).\nОтже, з ймовірністю хоча б \\(1 - \\alpha\\) \\(\\mu_0\\) перебуватиме в довірчому інтервалі.\nЧасто так й вводять визначення довірчого інтервалу. Для вибірки \\(\\xi_1, \\dots, \\xi_n\\) — це така пара статистик \\(\\mathcal{L}(\\xi)\\) і \\(\\mathcal{R}(\\xi)\\), що хоч яким би не було \\(\\mu_0\\),\n\\[\nP(L(\\xi) &lt; \\mu_0 &lt; R(\\xi)) \\geqslant 1 - \\alpha\n\\tag{2.3}\\]\nде \\(L(\\xi)\\) і \\(R(\\xi)\\) — статистики, що залежать від вибірки. Знову звертаємо увагу, що випадковість тут прихована не в параметрі \\(\\mu_0\\), а в статистиках від вибірки.\n\n\n\n2.6.2 Довірчий інтервал Вілсона\nРозглянутий зараз алгоритм побудови довірчого інтервалу працює занадто довго. У Python є функції, які дозволяють швидше розрахувати інтервал. Наприклад, можна скористатися методом Вілсона і функцією proportion_confint.\nПовторимо експерименти з новим типом довірчого інтервалу, тут можемо дозволити більше реалізацій вибірки, оскільки інтервал рахується недовго.\n\n\n\n\nЛістинг 2.14: Довірчий інтервал Вілсона\n\n\nfrom statsmodels.stats.proportion import proportion_confint\n\nstart_time = time.time()\n\nN_EXPERIMENTS = 1000\nSAMPLE_SIZE = 30\nlatent_mu = 0.5\nbinom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\nconfint_fail_cases = 0\n\nfor i in range(N_EXPERIMENTS):\n    q = binom_true.rvs()  \n    L, R = proportion_confint(\n        count=q,\n        nobs=SAMPLE_SIZE,\n        alpha=0.05,\n        method='wilson'\n    )\n    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\nsuccess_cases = round(100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS, 2)\nprint(f\"Відсоток успішних випадків: {success_cases}%\")\nend_time = time.time()\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\n\n\n\nВідсоток успішних випадків: 96.6%\nЧас виконання: 0.0736 секунди\n\n\nЗауважимо, що наше \\(\\mu\\) може знаходитись в довірчому інтервалі менше, ніж у \\(95\\%\\) випадків. Це відбувається через те, що швидкі методи працюють наближено, оцінюючи розподіл статистики при збільшенні розміру вибірки. Чим розмір вибірки більший, тим ближчим буде інтервал до \\(95\\%\\)-ного.\nЗалежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки зобразимо на Рисунок 2.8.\n\n\n\n\nЛістинг 2.15: Залежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки\n\n\nn_grid = np.arange(1, 1000, 25).tolist()\ninterval_success_rate = []\n\nfor n in n_grid:\n    confint_fail_cases = 0\n    for i in range(N_EXPERIMENTS):\n        binom_true = binom(n=n, p=latent_mu)\n        q = binom_true.rvs()  \n        L, R = proportion_confint(\n            count=q,\n            nobs=n,\n            alpha=0.05,\n            method='wilson'\n        )\n        if L &lt; latent_mu &lt; R:\n            pass\n        else:\n            confint_fail_cases += 1\n    interval_success_rate.append(1 - confint_fail_cases / N_EXPERIMENTS)\n\nplt.xlabel('Розмір вибірки $n$')\nplt.ylabel('Частка успішних влучень')\n\nplt.plot(n_grid, interval_success_rate, label='Частка успішних влучень', color=turquoise)\nplt.axhline(0.95, ls='--', label='Желаемая успешность', color=red_pink)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Залежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки\n\n\n\n\n\nВидно, що на будь-якому розмірі вибірки під час використання інтервалу Вілсона можна отримати менше \\(95\\%\\) влучень, але що більший розмір вибірки, то менше графік відхиляється від \\(95\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "z-test.html",
    "href": "z-test.html",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "3.1 Нормальний розподіл\nУ цьому розділі ми розглянемо \\(Z\\)-критерій Фішера, який використовується для перевірки гіпотез про середнє значення генеральної сукупності з відомою дисперсією.\nДалі, для виведення критеріїв нам потрібен нормальний розподіл. Потому що саме цьому розподілу підпорядковується середнє вибірок. Тож давайте подивимося, що це взагалі таке, як з ним працювати в Python й які в нього є властивості.\nНормальний розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\) — неперервний розподіл, у якому щільність спадає зі збільшенням відстані від математичного сподівання \\(\\mu\\) за швидкістю, пропорційною квадрату відстані (див. формулу 3.1).\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2},\n\\tag{3.1}\\] де \\(x\\) — випадкова величина, \\(\\mu\\) — математичне сподівання, \\(\\sigma^2\\) — дисперсія.\nНа графіку нижче показано, як виглядає нормальний розподіл з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\nРисунок 3.1: Нормальний розподіл з різними параметрами",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution",
    "href": "z-test.html#sec-normal-distribution",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "Лістинг 3.1: Візуалізація нормального розподілу з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\n\n\n\nx = np.linspace(-5, 5, 1000)\nparams = [(0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (2, 2)]\n\nfor mu, sigma in params:\n    plt.plot(x, norm.pdf(x, mu, sigma), label=f'μ={mu}, σ={sigma}')\n\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.legend()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-python",
    "href": "z-test.html#sec-normal-distribution-python",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.2 Нормальний розподіл у Python",
    "text": "3.2 Нормальний розподіл у Python\nНехай ми хочемо задати розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Для цього є клас norm1.\nПараметри класу:\n\nloc — це \\(\\mu\\)\nscale — це \\(\\sigma\\), або стандартне відхилення. Не дисперсія!\n\nМетоди класу:\n\nrvs() — згенерувати випадкові числа з розподілу \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\ncdf(x) — кумулятивна функція розподілу (cumulative distribution function, CDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\).\nppf(q) — квантиль функції розподілу (percent-point function, PPF) для ймовірності \\(q\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(q\\).\npdf(x) — щільність ймовірності (probability density function, PDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) дорівнює \\(x\\).\n\nCDF та PPF — це функції, які пов’язані між собою. CDF визначає ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\), а PPF визначає значення \\(x\\), для якого ймовірність \\(X\\) менша або дорівнює \\(q\\).\nІніціалізуємо клас norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\) (стандартний нормальний розподіл). Далі, згенеруємо випадкову вибірку з 50 спостережень, а також обчислимо PDF, CDF та PPF для \\(x = 1.5\\).\n\n\n\nЛістинг 3.2: Нормальний розподіл у Python.\n\n\n\n1std_norm = norm(loc=0, scale=1)\n\n2rnorm = std_norm.rvs(size=50, random_state=42)\n\n3CDF = std_norm.cdf(1.5)\n4PDF = std_norm.pdf(1.5)\n5PPF = std_norm.ppf(0.933)\n\ndisplay(\n6    Markdown(f\"$P(X \\\\leq 1.5) = {CDF:.3f}$\"),\n7    Markdown(f\"$f(1.5) = {PDF:.3f}$\"),\n8    Markdown(f\"$z_{{0.933}} = \\Phi^{{-1}}(0.933) = {PPF:.3f}$\")\n)\n\n\n1\n\nІніціалізація класу norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\).\n\n2\n\nГенерація випадкової вибірки з 50 спостережень.\n\n3\n\nОбчислення PDF для \\(x = 1.5\\).\n\n4\n\nОбчислення CDF для \\(x = 1.5\\).\n\n5\n\nОбчислення PPF для \\(q = 0.933\\).\n\n6\n\nЙмовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(1.5\\).\n\n7\n\nЙмовірність того, що випадкова величина \\(X\\) дорівнює \\(1.5\\).\n\n8\n\nЗначення \\(x\\), для якого ймовірність \\(X\\) менша або дорівнює \\(0.933\\).\n\n\n\n\n\\(P(X \\leq 1.5) = 0.933\\)\n\n\n\\(f(1.5) = 0.130\\)\n\n\n\\(z_{0.933} = \\Phi^{-1}(0.933) = 1.499\\)\n\n\n\n\n\nВізуалізація методів класу norm показана на рисунку 3.2.\n\n\n\n\n\n\n\n\nРисунок 3.2: Демонстрація методів класу norm",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-properties",
    "href": "z-test.html#sec-normal-distribution-properties",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.3 Властивості нормального розподілу",
    "text": "3.3 Властивості нормального розподілу\nНормальний розподіл має кілька важливих властивостей2:\n\nСума двох незалежних нормально розподілених випадкових величин також має нормальний розподіл:\n\n\\[\n\\begin{aligned}\n\\xi_1 &\\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\\\\n\\xi_2 &\\sim \\mathcal{N}(\\mu_2, \\sigma_2^2) \\\\\n\\xi_1 + \\xi_2 &\\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\n\\end{aligned}\n\\tag{3.2}\\] де \\(\\xi_1\\) та \\(\\xi_2\\) — незалежні нормально розподілені випадкові величини з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\) та \\(\\mu_2\\), \\(\\sigma_2^2\\) відповідно.\n\nМноження нормально розподіленої випадкової величини на константу також дає нормально розподілену величину:\n\n\\[\na \\xi_1 \\sim \\mathcal{N}(a\\mu_1, a^2\\sigma_1^2)\n\\tag{3.3}\\] де \\(a\\) — константа, \\(\\xi_1\\) — нормально розподілена випадкова величина з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\).\n\n3.3.1 Перевірка властивостей в Python\nЗа допомогою мови Python ми можемо перевірити ці властивості. Почнемо з Рівняння 3.2. Для цього ми згенеруємо дві нормально розподілені випадкові величини \\(\\xi_1\\) та \\(\\xi_2\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та \\(\\mu_2 = 1\\), \\(\\sigma_2^2 = 4\\). Потім, ми обчислимо їхню суму та перевіримо, чи має вона нормальний розподіл з параметрами \\(\\mu_1 + \\mu_2\\) та \\(\\sigma_1^2 + \\sigma_2^2\\).\n\n\n\nЛістинг 3.3: Візуалізація нормального розподілу суми двох нормально розподілених випадкових величин.\n\n\n\n1mean_one, mean_two = 3, -1\n2var_one, var_two = 4, 2\n\n3n = 10000\n\n4x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\nx2 = norm.rvs(loc=mean_two, scale=np.sqrt(var_two), size=n)\n\n5x_sum = x1 + x2\n6check_sum = norm(loc=mean_one + mean_two, scale=np.sqrt(var_one + var_two))\n\n7x_grid = np.linspace(-8, 12, 1000)\n\nfig, ax = plt.subplots()\n8sns.histplot(x_sum, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_sum.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\mu_2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\) та \\(\\sigma_2^2\\).\n\n3\n\nКількість спостережень.\n\n4\n\nГенерація нормально розподілених випадкових величин \\(\\xi_1\\) та \\(\\xi_2\\).\n\n5\n\nСума двох нормально розподілених випадкових величин.\n\n6\n\nПараметри суми \\(\\xi_1 + \\xi_2\\).\n\n7\n\nСтандартне відхилення суми \\(\\xi_1 + \\xi_2\\).\n\n8\n\nЕмпіричний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n9\n\nТеоретичний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВидно, що розподіли приблизно збіглися! А значить ми переконалися, що формула правильна.\nДругу властивість Рівняння 3.3 можна перевірити аналогічно. Для цього ми згенеруємо нормально розподілену випадкову величину \\(\\xi_1\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та помножимо її на константу \\(a = 2\\). Потім, ми перевіримо, чи має вона нормальний розподіл з параметрами \\(a\\mu_1\\) та \\(a^2\\sigma_1^2\\).\n\n\n\nЛістинг 3.4: Візуалізація нормального розподілу множення нормально розподіленої випадкової величини на константу.\n\n\n\n1mean_one = 0\n2var_one = 1\n3a = 2\n4n = 10000\n5x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\n6x_mult = a * x1\n7check_mult = norm(loc=a * mean_one, scale=np.sqrt(a**2 * var_one))\n8x_grid = np.linspace(-8, 8, 1000)\n\nfig, ax = plt.subplots()\nsns.histplot(x_mult, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_mult.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\sigma_1^2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\).\n\n3\n\nКонстанта \\(a\\).\n\n4\n\nКількість спостережень.\n\n5\n\nГенерація нормально розподіленої випадкової величини \\(\\xi_1\\).\n\n6\n\nМноження нормально розподіленої випадкової величини \\(\\xi_1\\) на константу \\(a\\).\n\n7\n\nПараметри множення \\(\\xi_1\\) на константу \\(a\\).\n\n8\n\nСтандартне відхилення множення \\(\\xi_1\\) на константу \\(a\\).\n\n9\n\nЕмпіричний та теоретичний розподіл множення \\(\\xi_1\\) на константу \\(a\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЦього разу розподіли також збіглися. А значить ми переконалися, що формула правильна.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#footnotes",
    "href": "z-test.html#footnotes",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "Документація доступна за посиланням https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html.↩︎\nДоведення цих властивостей можна знайти в роботі Lemons (2002).↩︎\nПослідовність випадкових величин \\(\\xi_n\\) збігається за розподілом до \\(\\xi\\), позначаємо \\(\\xi_n \\xrightarrow{d} \\xi\\), якщо \\(\\lim_{n \\to \\infty} F_{\\xi_n}(x) = F_{\\xi}(x)\\) для всіх \\(x\\), в яких \\(F_{\\xi}(x)\\) неперервна.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Список літератури",
    "section": "",
    "text": "Gnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit\nDistributions for Sums of Independent Random Variables. Martino\nFine Books.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in\nPhysics. The Johns Hopkins University Press.",
    "crumbs": [
      "Список літератури"
    ]
  },
  {
    "objectID": "z-test.html#sec-central-limit-theorem",
    "href": "z-test.html#sec-central-limit-theorem",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.4 Центральна гранична теорема",
    "text": "3.4 Центральна гранична теорема\nДля початку пригадаємо теорему, яка є основоположною теоремою для всіх критеріїв, які ми розглянемо найближчим часом.\n\nТеорема 3.1 (Центральна гранична теорема, ЦГТ) Нехай \\(\\xi_1, ..., \\xi_n\\) — незалежно однаково розподілені випадкові величини, в яких існують математичне сподівання та дисперсія: \\(E [\\xi_i] = \\mu &lt; \\infty\\) і \\(Var[\\xi_i] = \\sigma^2 &lt; \\infty\\), тоді \\(\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}}\\) збігається за розподілом3 до \\(\\mathcal{N}(0, 1)\\).\n\nЦе означає, що якщо випадкові величини в експерименті незалежні й однаково розподілені й ваша вибірка досить велика, то можна вважати, що\n\\[\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1),\n\\tag{3.4}\\] де \\(\\overline \\xi\\) — середнє арифметичне вибірки, \\(n\\) — кількість спостережень, \\(\\mu\\) — математичне сподівання генеральної сукупності, \\(\\sigma^2\\) — дисперсія генеральної сукупності.\n\n\n\n\n\n\nПримітка\n\n\n\nВипадкові величини можуть бути слабко залежні одна від одної й злегка по-різному розподілені. Центральна гранична теорема все ще буде правильною, Gnedenko and Kolmogorov (2021).\n\n\n\n3.4.1 Візуалізація ЦГТ\nЩоб краще розуміти, як працює ЦГТ, я пропоную візуалізувати теорему: подивимося на розподіл середніх значень у різних вибірках. Як ми це зробимо?\n\nЩоб подивитися, що деяка випадкова величина з нормального розподілу, нам потрібна вибірка цих випадкових величин.\nУ цьому випадку нам потрібна вибірка статистик із ЦГТ. Тому нам потрібно згенерувати \\(N\\) вибірок по \\(M\\) елементів у кожній.\n\nПо кожній вибірці треба порахувати середнє за \\(M\\) елементами.\nУ підсумку ми отримаємо вибірку з \\(N\\) елементів.\nВона і має бути з нормального розподілу.\n\n\n\n\n\nЛістинг 3.5: Візуалізація ЦГТ при великій вибірці з біноміального розподілу.\n\n\n\ndef visualize_CLT(sample_generator, expected_value, variance):\n    np.random.seed(42)\n1    N = 5000\n2    clt_sample = []\n    for _ in range(N):\n3        sample = sample_generator()\n4        sample_size = len(sample)\n5        statistic = np.sqrt(sample_size) * (np.mean(sample) - expected_value) / np.sqrt(variance)\n6        clt_sample.append(statistic)\n\n7    x = np.linspace(-4, 4, 1000)\n    fig, ax = plt.subplots()\n    sns.histplot(clt_sample, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n    ax.plot(x, norm().pdf(x), color=red_pink, label='$\\mathcal{N}(0, 1)$', alpha=0.8)\n    plt.legend()\n    plt.xlabel('X')\n    plt.ylabel('Щільність')\n    plt.show()\n\n\np = 0.01\nn = 20\nsize = 5000\n\n8visualize_CLT(lambda: np.random.binomial(n, p, size),\n9              expected_value = p * n,\n10              variance = n * p * (1 - p)\n)\n\n\n1\n\nКількість вибірок.\n\n2\n\nПустий масив для зберігання статистик.\n\n3\n\nГенерація вибірки з \\(M\\) елементами.\n\n4\n\nКількість елементів у вибірці.\n\n5\n\nОбчислення статистики.\n\n6\n\nДодавання статистики до масиву.\n\n7\n\nВізуалізація емпіричного розподілу та теоретичного розподілу.\n\n8\n\nГенерація вибірки з біноміального розподілу.\n\n9\n\nМатематичне сподівання біноміального розподілу.\n\n10\n\nДисперсія біноміального розподілу.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЕмпірична щільність достатньо близько збігається з теоретичним розподілом. А що якщо зменшити вибірку, за якою рахується середнє?\n\n\n\nЛістинг 3.6: Візуалізація ЦГТ при малій вибірці з біноміального розподілу.\n\n\n\np = 0.05\nn = 20\nsize = 10\n\nvisualize_CLT(lambda: np.random.binomial(n, p, size),\n              expected_value = p * n,\n              variance = n * p * (1 - p)\n)\n\n\n\n\n\n\n\n\n\n\n\nСтало значно гірше: з’явилися прогалини в розподілі, та й сама емпірична функція розподілу зміщена. Тож наш експеримент підтвердив важливість розміру вибірки для коректної роботи ЦГТ.\nТепер подивимось на експоненціальний розподіл.\n\n\n\nЛістинг 3.7: Візуалізація ЦГТ при великій вибірці з експоненціального розподілу.\n\n\n\n1p = 5\n2size = 400\n3visualize_CLT(lambda: np.random.exponential(scale=1/p, size=size),\n4              expected_value = 1/p,\n5              variance = 1/(p**2)\n)\n\n\n1\n\nПараметр \\(\\lambda\\) експоненціального розподілу.\n\n2\n\nРозмір вибірки.\n\n3\n\nГенерація вибірки з експоненціального розподілу.\n\n4\n\nМатематичне сподівання експоненціального розподілу задається як \\(1/\\lambda\\).\n\n5\n\nДисперсія експоненціального розподілу задається як \\(1/\\lambda^2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nБачимо, що і тут усе добре працює!\n\n\n3.4.2 Інші формулювання ЦГТ\nНаступні формулювання є еквівалентними, тому що ми можемо перетворити одне в інше за допомогою простих алгебраїчних перетворень. Вони можуть бути корисними в різних ситуаціях, залежно від того, що ми хочемо перевірити.\n\\[\n\\begin{aligned}\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} &\\sim \\mathcal{N}(0, 1) {\\Leftrightarrow}\\\\\n\\overline \\xi - \\mu &\\sim \\mathcal{N}\\left(0, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\dfrac{\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i}{n} &\\sim \\mathcal{N}\\left(\\mu, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i &\\sim \\mathcal{N}\\left(n \\cdot \\mu, n \\cdot \\sigma^2 \\right)\n\\end{aligned}\n\\tag{3.5}\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-visualization-central-limit-theorem",
    "href": "z-test.html#sec-visualization-central-limit-theorem",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.5 Візуалізація ЦГТ",
    "text": "3.5 Візуалізація ЦГТ\nЩоб краще розуміти, як працює ЦГТ, я пропоную візуалізувати теорему: подивимося на розподіл середніх значень у різних вибірках. Як ми це зробимо?\n\nЩоб подивитися, що деяка випадкова величина з нормального розподілу, нам потрібна вибірка цих випадкових величин.\nУ цьому випадку нам потрібна вибірка статистик із ЦГТ. Тому нам потрібно згенерувати \\(N\\) вибірок по \\(M\\) елементів у кожній.\n\nПо кожній вибірці треба порахувати середнє за \\(M\\) елементами.\nУ підсумку ми отримаємо вибірку з \\(N\\) елементів.\nВона і має бути з нормального розподілу.\n\n\n\n\n\nЛістинг 3.5: Візуалізація ЦГТ при великій вибірці з біноміального розподілу.\n\n\n\ndef visualize_CLT(sample_generator, expected_value, variance):\n    np.random.seed(42)\n1    N = 5000\n2    clt_sample = []\n    for _ in range(N):\n3        sample = sample_generator()\n4        sample_size = len(sample)\n5        statistic = np.sqrt(sample_size) * (np.mean(sample) - expected_value) / np.sqrt(variance)\n6        clt_sample.append(statistic)\n\n7    x = np.linspace(-4, 4, 1000)\n    fig, ax = plt.subplots()\n    sns.histplot(clt_sample, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n    ax.plot(x, norm().pdf(x), color=red_pink, label='$\\mathcal{N}(0, 1)$', alpha=0.8)\n    plt.legend()\n    plt.xlabel('X')\n    plt.ylabel('Щільність')\n    plt.show()\n\n\np = 0.01\nn = 20\nsize = 5000\n\n8visualize_CLT(lambda: np.random.binomial(n, p, size),\n9              expected_value = p * n,\n10              variance = n * p * (1 - p)\n)\n\n\n1\n\nКількість вибірок.\n\n2\n\nПустий масив для зберігання статистик.\n\n3\n\nГенерація вибірки з \\(M\\) елементами.\n\n4\n\nКількість елементів у вибірці.\n\n5\n\nОбчислення статистики.\n\n6\n\nДодавання статистики до масиву.\n\n7\n\nВізуалізація емпіричного розподілу та теоретичного розподілу.\n\n8\n\nГенерація вибірки з біноміального розподілу.\n\n9\n\nМатематичне сподівання біноміального розподілу.\n\n10\n\nДисперсія біноміального розподілу.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЕмпірична щільність достатньо близько збігається з теоретичним розподілом. А що якщо зменшити вибірку, за якою рахується середнє?\n\n\n\nЛістинг 3.6: Візуалізація ЦГТ при малій вибірці з біноміального розподілу.\n\n\n\np = 0.05\nn = 20\nsize = 10\n\nvisualize_CLT(lambda: np.random.binomial(n, p, size),\n              expected_value = p * n,\n              variance = n * p * (1 - p)\n)\n\n\n\n\n\n\n\n\n\n\n\nСтало значно гірше: з’явилися прогалини в розподілі, та й сама емпірична функція розподілу зміщена. Тож наш експеримент підтвердив важливість розміру вибірки для коректної роботи ЦГТ.\nТепер подивимось на експоненціальний розподіл.\n\n\n\nЛістинг 3.7: Візуалізація ЦГТ при великій вибірці з експоненціального розподілу.\n\n\n\n1p = 5\n2size = 400\n3visualize_CLT(lambda: np.random.exponential(scale=1/p, size=size),\n4              expected_value = 1/p,\n5              variance = 1/(p**2)\n)\n\n\n1\n\nПараметр \\(\\lambda\\) експоненціального розподілу.\n\n2\n\nРозмір вибірки.\n\n3\n\nГенерація вибірки з експоненціального розподілу.\n\n4\n\nМатематичне сподівання експоненціального розподілу задається як \\(1/\\lambda\\).\n\n5\n\nДисперсія експоненціального розподілу задається як \\(1/\\lambda^2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-z-test-fisher",
    "href": "z-test.html#sec-z-test-fisher",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.5 \\(Z\\)-критерій Фішера",
    "text": "3.5 \\(Z\\)-критерій Фішера\n\n\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  }
]