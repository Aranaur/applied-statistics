[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладний статистичний аналіз",
    "section": "",
    "text": "Передмова",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "binom.html",
    "href": "binom.html",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "1.1 Генеральна сукупність та вибірка\nВи вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.\nПроте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.\nЩоб це перевірити, ви проводите експеримент: залучаєте 30 нових студентів. 20 із них проходять курс й оплачують доступ, а 11 відмовляються. 20 — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?\nРозв’язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають генеральною сукупністю. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як \\(\\mu\\). Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та досліджувати результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо вибірку з генеральної сукупності та аналізуємо частку успішних випадків.\nЗгідно з результатами нашого експерименту, спостережувана ймовірність оплати становить \\(\\hat{\\mu} = 20/30 = 0.67\\)1. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?\nРозгляньмо, чому отримане значення може не бути переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює \\(\\mu = 0.5\\), і змоделюємо можливі результати для 30 студентів.\nДавайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для 30 спроб:\n1rng = np.random.default_rng(18)\n\n2n = 30\n3results = rng.integers(0, 1, size = 30, endpoint = True)\n4success = np.sum(results) / n\n\n5print(f\"Кількість успішних випадків: {round(success, 3) * 100}%\")\n\n\n1\n\nІніціалізуємо генератор випадкових чисел з фіксованим seed.\n\n2\n\nКількість студентів.\n\n3\n\nГенеруємо випадкові числа2 для кожного студента.\n\n4\n\nОбчислюємо частку успішних випадків.\n\n5\n\nВиводимо результат.\n\n\n\n\nКількість успішних випадків: 70.0%\nМи бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.\nТому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення \\(\\mu\\) у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#генеральна-сукупність-та-вибірка",
    "href": "binom.html#генеральна-сукупність-та-вибірка",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "Якщо монетка випаде орлом, студент оплачує доступ.\nЯкщо монетка випаде решкою, студент відмовляється від курсу.\nВикористаємо метод integers() до класу Generator, яка генерує випадкові цілі числа в заданому діапазоні.\nПідкинемо монетку 30 разів та порахуємо кількість успішних випадків.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-гіпотези",
    "href": "binom.html#статистичні-гіпотези",
    "title": "1  Біноміальний критерій",
    "section": "1.2 Статистичні гіпотези",
    "text": "1.2 Статистичні гіпотези\n\n1.2.1 Постановка задачі\nМи з’ясували, що навіть за ймовірності \\(\\mu = 0.5\\) можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали seed для отримання такого результату. Якщо повторити цей експеримент з іншим значенням seed або збільшити кількість спостережень, результат може виявитися іншим.\n\n\n\n\n\n\nПорада\n\n\n\nСпробуйте змінити seed (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.\n\n\nТож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту статистично значущими необхідно отримати відповідь на питання:\n\nЧи можна вважати, що спостережуване значення \\(\\hat{\\mu}\\) є більшим від \\(\\mu = 0.5\\)?\n\nЗвернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину \\(\\xi\\), яка підпорядковується розподілу Бернуллі3. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.\n\\[\n\\xi \\sim \\text{Bernoulli}(\\mu)\n\\]\nде \\(\\mu\\) — ймовірність успіху.\nНас цікавить підтвердження того, що \\(\\mu &gt; 0.5\\). У статистиці для перевірки гіпотез розглядають дві можливості:\n\nНульова гіпотеза (\\(H_0\\)) формулюється як твердження, яке ми прагнемо спростувати.\nАльтернативна гіпотеза (\\(H_1\\)) висловлює припущення, яке ми хочемо довести.\n\nСкорочено це записують як:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 0.5 \\\\\nH_1 &: \\mu &gt; 0.5\n\\end{aligned}\n\\]\nЗауважимо, що якщо в нашому експерименті з 30 студентами можна дивитися не на частку успіхів, а на їх кількість.\nТоді питання можна переформулювати так:\n\nЗа умови вірності \\(H_0\\) наскільки ймовірно отримати 20 або більше успішних випадків з 30?\n\nЯкщо ми проводимо \\(n\\) незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу4.\n\\[\nS_n = \\sum_{i=1}^{n} \\xi_i \\sim \\text{Binomial}(n, \\mu)\n\\]\nде \\(\\xi_i\\) — випадкова величина, яка показує успіх у \\(i\\)-му спостереженні, \\(S_n\\) — кількість успішних випадків у \\(n\\) спостереженнях, \\(n\\) — кількість спостережень, \\(\\mu\\) — ймовірність успіху.\nДавайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\).\n\nn = 30\nmu = 0.5\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, mu)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= 20], y[x &gt;= 20], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.1: Функція щільності ймовірностей при \\(H_0\\)\n\n\n\n\n\nРисунок 1.1 демонструє функцію щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\). Ціановим5 кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює 20.\n\n\n1.2.2 Критерій\nЩойно ми розробили алгоритм, який на основі вибірки \\(\\xi\\) або визнає наявність доказів на користь \\(H_1\\), або повідомляє, що таких доказів немає. Відповідно, він або відхиляє \\(H_0\\), або не відхиляє її.\nТакий алгоритм називається критерієм. Його можна подати у вигляді функції \\(S\\), яка приймає реалізацію вибірки та повертає \\(1\\), якщо слід відхилити \\(H_0\\), та \\(0\\) в іншому випадку.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо відхиляємо } H_0 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nДавайте припустимо, що ми вирішили відхилити \\(H_0\\), якщо кількість успішних випадків перевищує або дорівнює 21. Тоді критерій набуде вигляду:\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо } \\sum \\xi_i \\geqslant 21 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nЗазвичай скорочують запис і пишуть просто правило, за яким відхиляємо \\(H_0\\)\n\\[\nS = \\{\\sum \\xi_i \\geqslant 21\\}\n\\]\nПозначимо \\(Q = \\sum \\xi_i\\), \\(C = 21\\), тоді критерій набуває вигляду:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}\n\\]\nТак влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. \\(Q\\) називається статистикою критерію, \\(C\\) — критичним значенням.\n\\(Q\\) може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх \\(\\xi_i\\). Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.\n\n\n1.2.3 Критична область\nЗнову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію \\(S\\):\n\nНаскільки часто може бути таке, що за справедливості \\(H_0\\) критерій \\(S\\) відхиляє гіпотезу?\n\nВідповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним 21, побачивши на картинці, що великі відхилення відбуваються при \\(H_0\\) рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення \\(C\\), виходячи з частоти помилок нашого критерію.\nВибираючи \\(C\\), ми можемо або часто відхиляти нульову гіпотезу, коли \\(C\\) мале, або можемо робити це рідше, коли \\(C\\) велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.\n\n\\(C = 16\\). Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із 30, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає \\(1\\), тобто це помилка хибно позитивна (false positive, FP).\n\\(C = 29\\). У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб’ємося цього. Не відхилити гіпотезу \\(H_0\\), коли вона неправильна — це теж помилка. Вона називається хибно негативна (false negative, FN), оскільки критерій повернув 0 помилково.\n\n\\[ \\text{FP} - H_0\\ відхиляється,\\ коли\\ вона\\ вірна \\] \\[ \\text{FN} - H_0\\ не\\ відхиляється,\\ коли\\ вона\\ не вірна \\]\nУ нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.\nТому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж частота хибнопозитивних спрацьовувань (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності \\(H_0\\).\nТепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.\n\nЯкий FPR у критерію \\(S\\) для перевірки гіпотези \\(H_0\\) проти \\(H_1\\)?\n\nКоли \\(H_0\\) є вірною, щоб порахувати кількість успіхів ми проводили 30 разів підкидання монетки з ймовірністю орла \\(0.5\\). Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при \\(\\mu = 0.5\\) наша статистика має біноміальний розподіл \\(Q \\sim Binom(0.5, 30)\\).\nОбчислимо FPR для \\(C = 21\\)\n\\[\n\\begin{aligned}\nFPR &= P(S(\\xi) = 1\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ \\mu = 0.5) = \\\\\n&= P(Q \\geqslant 21\\ |\\ Q \\sim Binom(0.5, 30))\n\\end{aligned}\n\\]\nЦе вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.\n\n\n1.2.4 Обчислення FPR\nДавайте порахуємо суму ймовірностей для кількостей успіхів від 21 до 30 включно. Покажемо графічно, як це виглядає на Рисунку 1.2.\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, 0.5)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink)\nfor i in range(crit_subs - 2, crit_subs + 4):\n    plt.text(i + 0.5, y[i] + 0.001, f\"{round(y[i] * 100, 1)}%\",\n    ha='center', va='bottom', size=8, rotation = 30)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.2: Ймовірність хибно відхилити \\(H_0\\) за умови її вірності\n\n\n\n\n\nЗалишається лише обчислити суму ймовірностей для кількостей успіхів від 21 до 30 включно. Це і буде нашим FPR.\n\\[\nFPR_{21} = \\sum_{i = 21}^{30} P(Q = i) \\approx 0.021\n\\]\nУ нашому випадку це буде 2.1%. Якщо FPR не перевищує деякої константи \\(\\alpha\\), то критерій називається критерієм рівня значущості \\(\\alpha\\). Статистичний критерій з \\(\\alpha\\) = 100% створити тривіально — достатньо завжди відхиляти \\(H_0\\) — тому така постановка не має сенсу.\nРівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть \\(\\alpha = 0.05\\), але якщо потрібне більш точне ухвалення рішення, можуть вибрати \\(0.01\\), \\(0.005\\), \\(0.001\\). Якщо ж рішення не таке критичне, можуть вибрати \\(0.1\\).\nПрипустимо, вибрали значення \\(\\alpha = 0.05\\), скористаємося критерієм \\(S\\): тобто якщо кількість успішних випадків перевищує або дорівнює 21, то відхиляємо \\(H_0\\).\nЯкщо уважно подивитись на Рисунок 1.2, то можна помітити, що ми можемо відхиляти \\(H_0\\) при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати \\(\\alpha = 0.05\\):\n\\[\nFPR_{20} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.049\n\\]\nЯкщо ж обрати 19, то FPR буде більше \\(\\alpha\\): \\[\nFPR_{19} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.1002\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-функції-в-python",
    "href": "binom.html#статистичні-функції-в-python",
    "title": "1  Біноміальний критерій",
    "section": "1.3 Статистичні функції в Python",
    "text": "1.3 Статистичні функції в Python\nУ цій частині подивимося, як вивести те, що ми отримали в частині 2, за допомогою Python. А також зрозуміємо, як знайти відповідне \\(C\\) за допомогою Python.\n\n1.3.1 Біноміальний розподіл\nМи з’ясували, що статистика \\(Q\\) має біноміальний розподіл.\nБіноміальний розподіл \\(Binom(n, \\mu)\\) — розподіл кількості успіхів у послідовності з \\(n\\) незалежних випадкових експериментів, ймовірність успіху в кожному з яких дорівнює \\(\\mu\\).\nЩоб працювати з розподілом, можна створити об’єкт-розподіл за допомогою бібліотеки scipy.stats.\n\nfrom scipy.stats import binom\n\n1n = 30\n2mu = 0.5\n\nbinom_dist = binom(n, mu)\n\n\n1\n\nКількість спостережень.\n\n2\n\nЙмовірність успіху.\n\n\n\n\n\n\n1.3.2 Функція ймовірностей\nФункція ймовірності дискретного розподілу \\(p_\\xi(x)\\) — ймовірність, з якою \\(\\xi\\) приймає значення \\(x\\).\nУ Python це функція pmf (probability mass function).\n\n1binom_dist.pmf(20)\n\n\n1\n\nЙмовірність отримати 20 успішних випадків.\n\n\n\n\n0.027981600724160654\n\n\nЗобразимо розподіл статистики \\(Q\\) за справедливості \\(H_0\\) на графіку. Для цього можна передати відразу масив точок, для яких треба розрахувати ймовірність.\n\n1x = np.arange(0, n + 1)\n2y = binom_dist.pmf(x)\n\n3crit_subs = 21\n\n4plt.bar(x, y, color=turquoise, label=\"Ймовірність успіхів\")\n5plt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink, label=\"Критичне значення\")\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nМасив точок.\n\n2\n\nРозрахунок ймовірностей.\n\n3\n\nКритичне значення.\n\n4\n\nЙмовірність успіхів.\n\n5\n\nКритичне значення.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.3: Функція щільності ймовірностей біноміального розподілу\n\n\n\n\n\nНасправді вже зараз ми можемо порахувати ймовірність потрапляння в критичну область. Потрібно просто підсумувати ймовірності для кількостей успіхів від 21 до 30.\n\nnp.round(np.sum(y[crit_subs:]), 4)\n\n0.0214\n\n\nОтже, ми дійсно побудували критерій рівня значущості \\(\\alpha = 0.05\\). Ба більше, це критерій рівня значущості 0.021.\nА що якби ми взяли \\(C = 19\\)?\n\ncrit_subs = 19\nnp.round(np.sum(y[crit_subs:]), 4)\n\n0.1002\n\n\nТоді ймовірність помилки вже навіть більше \\(10\\%\\), що зовсім нам не підходить.\nА якщо \\(C = 20\\)?\n\ncrit_subs = 20\nnp.round(np.sum(y[crit_subs:]), 4)\n\n0.0494\n\n\nВидно, що немає такого \\(C\\), щоб FPR був рівно \\(5\\%\\).\n\n\n1.3.3 Кумулятивна функція розподілу\nКумулятивна функція розподілу \\(F_\\xi(x) = P(\\xi \\leqslant x)\\)\nУ Python це функція cdf (Cumulative Distribution Function).\n\n1binom_dist.cdf(19)\n\n\n1\n\nЙмовірність отримати 19 або менше успішних випадків.\n\n\n\n\n0.9506314266473055\n\n\nЙмовірність отримати \\(19\\) або менше успіхів у нашому завданні \\(\\geqslant 0.95\\). А оскільки \\(P(\\xi \\leqslant 19) + P(\\xi \\geqslant 20) = 1\\), можемо обчислити рівень значущості нашого критерію.\n\n1 - binom_dist.cdf(19)\n\n0.04936857335269451\n\n\n\n\n1.3.4 Квантиль\nЩоб вибрати критичну область для критерію, ми хотіли б знайти точку, площа стовпців праворуч від якої була б \\(5\\%\\). Тобто площа стовпців зліва — \\(95\\%\\). Така точка називається квантилью.\n\\[\nu_p(\\xi) = \\{x\\ | F_\\xi(x) = p\\}\n\\]\nАле при \\(p = 0.95\\) й нашому біноміальному розподілі, такої точки немає. Ми з’ясували, що є точка, праворуч від якої площа \\(0.494\\), а в наступної вже \\(0.1\\). Щоб визначити квантиль у цьому випадку, модифікуємо визначення. Квантиль \\(u_p(\\xi)\\) — величина, яку \\(\\xi\\) не перевищує з імовірністю хоча б \\(p\\). Тобто \\(F_\\xi(u_p) \\geqslant p\\).\n\\[\nu_p(\\xi) = min\\ \\{x\\ |\\ F_\\xi(x) \\geqslant p \\}\n\\]\n\nДля величини \\(\\xi \\sim Bin(30, 0.5)\\) порахуємо 0.95-квантиль. Вирішимо задачу просто підбором.\n\\[ P(\\xi \\leqslant 18) \\approx 0.90\\] \\[ P(\\xi \\leqslant 19) \\approx 0.951 \\] \\[ P(\\xi \\leqslant 20) \\approx 0.97 \\]\nБачимо, що 18 нам ще не підходить, а 19 й більші значення вже підійдуть. У них функція розподілу буде більшою за \\(p\\). Відповідь — найменше відповідне значення, тобто 19. При цьому немає точки, де функція розподілу дорівнювала б \\(p\\) в точності.\nЯкби розподіл був неперервним, можна було б сказати, що квантиль — це таке \\(x\\), на якому функція розподілу дорівнює \\(p\\). Але для дискретного розподілу такого може не бути.\n\nУ Python квантиль можна порахувати через функцію ppf (Percent Point Function).\n\nbinom_dist.ppf(0.95)\n\n19.0\n\n\nЯк тепер підібрати \\(C\\) для будь-яких \\(n, \\mu\\) й для будь-якого рівня значущості \\(\\alpha\\)?\n\nПотрібно знайти \\(C\\), таке що \\(P(Q \\geqslant C) \\leqslant \\alpha\\)\nТобто потрібно \\(P(Q &lt; C) \\geqslant 1 - \\alpha\\)\n\\(Q\\) приймає тільки цілі значення: \\(P(Q \\leqslant C - 1) \\geqslant 1 - \\alpha\\), або \\(F(C - 1) \\geqslant 1 - \\alpha\\)\nОтже, з визначення квантилі, \\(C - 1 = u_{1 - \\alpha}\\)\nЗначить \\(C = u_{1 - \\alpha} + 1\\)\n\n\ndef find_crit_subs(n, mu, alpha):\n    \"\"\"\n    Знаходить критичне значення для критерію\n    :param n: кількість спостережень\n    :param mu: ймовірність успіху\n    :param alpha: рівень значущості\n    :return: критичне значення\n    \"\"\"\n    binom_dist = binom(n, mu)\n    return binom_dist.ppf(1 - alpha) + 1\n\nВикористаємо функцію для знаходження критичного значення для \\(\\alpha = 0.05\\).\n\nfind_crit_subs(30, 0.5, 0.05)\n\n20.0\n\n\nКритичне значення \\(20\\), отже підсумковий критерій має такий вигляд\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\n\\(Q = 19\\), значить гіпотезу ми не відкидаємо.\nПри цьому нам вдалося побудувати процес, за яким ми ухвалюємо рішення для будь-якого рівня значущості та значення статистики критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#p-значення",
    "href": "binom.html#p-значення",
    "title": "1  Біноміальний критерій",
    "section": "1.4 \\(p\\)-значення",
    "text": "1.4 \\(p\\)-значення\nЗауважимо, що зараз, якщо нам зададуть іншу \\(\\alpha\\), нам доведеться перебудовувати критерій заново. Це не зовсім зручно. У статистиці є механізм \\(p\\)-значення, який дає змогу прийняти рішення для всіх \\(\\alpha\\) відразу.\n\n1.4.1 Більш екстремальні значення\nПрипустимо, ми провели експеримент й порахували для критерію його статистику \\(Q(\\xi)\\). Позначимо отримане значення \\(q\\), у поточній задачі це \\(q = 19\\). Якби кількість успішних підписок була більшою, це б сильніше свідчило на користь альтернативної гіпотези \\(H_1\\). Тобто в разі значення \\(25\\) ми були б ще сильніше впевнені в тому, що наш бізнес буде окупатися. Тоді значення \\(25\\) називається більш екстремальним, ніж значення \\(19\\). У нашій задачі більш екстремальним із двох значень є те, яке більше.\nВизначимо поняття екстремальності формально:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}:\\ t\\ \\text{екстремальніше}\\ q \\Leftrightarrow t &gt; q\n\\]\nНайчастіше критерії інших видів можна привести до цього, тоді для них теж визначено поняття екстремальності.\n\n\n1.4.2 \\(p\\)-значення\np-value — це ймовірність отримати таке або більш екстремальне значення статистики \\(q\\) за умови вірності \\(H_0\\).\n\\[\nP_{H_0}(Q \\geqslant q)\n\\]\n\n\n\n\n\n\n\n\nРисунок 1.4: \\(p\\)-значення для критерію \\(Q = 15\\)\n\n\n\n\n\nТепер виведемо формулу через функції Python:\n\\[\nP_{H_0}(Q \\geqslant q) = 1 - P_{H_0}(Q &lt; q) = 1 - F(q)\n\\]\nЗобразимо на графіку область більш екстремальних значень й p-value для різних значень статистики.\n\n\n\n\n\n\n\n\nРисунок 1.5: \\(p\\)-значення для критерію \\(Q = 10, 19, 20, 25\\)\n\n\n\n\n\nМожна побачити, що в критичній області \\(p\\)-значення \\(\\leqslant \\alpha\\), а поза нею \\(p\\)-значення \\(&gt; \\alpha\\). Саме таке правило й використовується для прийняття рішення.\n\\[\nH_0 \\text{ відкидається } \\Leftrightarrow p-значення \\leqslant \\alpha\n\\]\nПричому за \\(p\\)-значення одразу видно, що якби в нашу критичну область включили значення \\(19\\), наш критерій допускав би FPR у \\(10\\%\\) випадків, що вже неприпустимо. Тому й гіпотезу ми не відкидаємо.\nЗауважимо, що для обчислення \\(p\\)-значення не знадобилося знання \\(\\alpha\\), а потрібна була тільки статистика й форма критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#двосторонні-критерії",
    "href": "binom.html#двосторонні-критерії",
    "title": "1  Біноміальний критерій",
    "section": "1.5 Двосторонні критерії",
    "text": "1.5 Двосторонні критерії\nДо цього моменту нас цікавили відхилення від ймовірності в \\(50\\%\\) тільки в один бік. І логічно, адже це продиктовано бізнесом. Тільки велика частка успішних підписок призведе до успіху. І зазвичай при прийнятті рішень так й буває. При тестуванні нового рішення або продукту розглядають альтернативну гіпотезу тільки в бік поліпшення, тому що в іншому разі немає сенсу впроваджувати рішення на всіх користувачів.\nОднак іноді може знадобитися доводити відхилення в обидва боки, якщо ви перевіряєте якесь припущення. Нехай вам дали монетку й просять перевірити, чесна вона чи ні. Монетка чесна, якщо під час підкидання ймовірність випадання орла дорівнює \\(0.5\\). Ви підкидаєте монетку \\(30\\) разів, кожен кидок — бернуллівська величина, аналогічно завданню з сервісом освітніх послуг. Нульова гіпотеза та ж сама: \\(\\mu = 0.5\\). Але тепер ми хочемо відкидати цю гіпотезу як у разі великої ймовірності орла, так і в разі маленької, відповідно перевіряємо двосторонню гіпотезу.\n\\[\nH_0: \\mu = 0.5\n\\]\n\\[\nH_1: \\mu \\neq 0.5\n\\]\nВиберемо критичну область для критерію за такої альтернативи. Скористаємося тією ж статистикою \\(Q(\\xi) = \\sum \\xi_i\\). Тільки тепер відхилення в кожну сторону однаково важливі. Відкидати гіпотезу будемо не тільки на досить великих значеннях, а й на досить маленьких. Наприклад, якщо у нас було всього \\(2\\) орла з \\(30\\) — це свідчення на користь того, що \\(\\mu \\neq 0.5\\), але не на користь \\(\\mu &gt; 0.5\\).\nОскільки відхилення в різні боки однаково важливі, а розподіл симетричний, шукати критерій можна в такому вигляді:\n\\[\nS = \\{Q \\geqslant C\\} \\cup \\{Q \\leqslant n - C\\}\n\\]\n\n1.5.1 Як вибрати критичну область\nПодивимося, який вигляд матиме критична область у такому разі.\n\n\n\n\n\n\n\n\nРисунок 1.6: Двостороння критична область для критерію \\(С = 6\\)\n\n\n\n\n\nЗ картинки видно, що якщо тепер відкидати відхилення за \\(Q \\geqslant 20\\), то необхідно відкидати й \\(Q \\leqslant 10\\), а отже, загальна площа стовпців буде вже приблизно \\(0.1\\). Тому за рівня значущості \\(0.05\\) й \\(20\\) успіхів гіпотеза вже не відкинеться.\nЯкщо ж виставити \\(C = 6\\), то така область уже підходить, площа стовпців \\(\\approx 0.043 &lt; 0.05\\).\nЩоб вибрати порогову константу за формулою, можна помітити, що критична область симетрична, а значить праворуч площа не повинна бути більшою, ніж \\(\\frac{\\alpha}{2}\\). А таку задачу ми вже вміємо розв’язувати.\nРеалізуємо функцію на Python.\n\ndef find_crit_subs_two_sided(n, mu, alpha):\n    \"\"\"\n    Знаходить критичне значення для двостороннього критерію\n    :param n: кількість спостережень\n    :param mu: ймовірність успіху\n    :param alpha: рівень значущості\n    :return: критичне значення\n    \"\"\"\n    binom_dist = binom(n, mu)\n    return n / 2 - binom_dist.ppf(alpha / 2) + 1\n\nВикористаємо функцію для знаходження критичного значення для \\(\\alpha = 0.05\\).\n\nfind_crit_subs_two_sided(30, 0.5, 0.05)\n\n6.0\n\n\n\n\n1.5.2 Як знайти \\(p\\)-значення",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#footnotes",
    "href": "binom.html#footnotes",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "У статистиці \\(\\hat{\\mu}\\) позначається як оцінка параметра \\(\\mu\\).↩︎\nМетод integers() генерує випадкові цілі числа в заданому діапазоні. Аргумент endpoint вказує, що верхня межа включається у діапазон.↩︎\nРозподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.↩︎\nБіноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума \\(n\\) незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.↩︎\nАнгл. cyan, від грец. κυανoῦς — “блакитний”, “лазуровий”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  }
]