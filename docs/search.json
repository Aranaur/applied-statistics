[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладний статистичний аналіз",
    "section": "",
    "text": "Передмова",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "binom.html",
    "href": "binom.html",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "1.1 Генеральна сукупність та вибірка\nВи вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.\nПроте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.\nЩоб це перевірити, ви проводите експеримент: залучаєте 30 нових студентів. 20 із них проходять курс й оплачують доступ, а 11 відмовляються. 20 — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?\nРозв’язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають генеральною сукупністю. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як \\(\\mu\\). Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та досліджувати результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо вибірку з генеральної сукупності та аналізуємо частку успішних випадків.\nЗгідно з результатами нашого експерименту, спостережувана ймовірність оплати становить \\(\\hat{\\mu} = 20/30 = 0.67\\)1. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?\nРозгляньмо, чому отримане значення може не бути переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює \\(\\mu = 0.5\\), і змоделюємо можливі результати для 30 студентів.\nДавайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для 30 спроб:\nМи бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.\nТому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення \\(\\mu\\) у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#sec-population",
    "href": "binom.html#sec-population",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "Якщо монетка випаде орлом, студент оплачує доступ.\nЯкщо монетка випаде решкою, студент відмовляється від курсу.\nВикористаємо метод integers()2 до класу Generator, яка генерує випадкові цілі числа в заданому діапазоні.\nПідкинемо монетку 30 разів та порахуємо кількість успішних випадків.\n\n\n\n\nЛістинг 1.1: Підкидання монетки\n\n\n\n1rng = np.random.default_rng(seed=18)\n\n2n = 30\n3results = rng.integers(0, 1, size = 30, endpoint = True)\n4success = np.sum(results) / n\n\n5print(f\"Кількість успішних випадків: {round(success, 3) * 100}%\")\n\n\n1\n\nІніціалізуємо генератор випадкових чисел з фіксованим seed.\n\n2\n\nКількість студентів.\n\n3\n\nГенеруємо випадкові числа для кожного студента.\n\n4\n\nОбчислюємо частку успішних випадків.\n\n5\n\nВиводимо результат.\n\n\n\n\nКількість успішних випадків: 70.0%",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-гіпотези",
    "href": "binom.html#статистичні-гіпотези",
    "title": "1  Біноміальний критерій",
    "section": "1.2 Статистичні гіпотези",
    "text": "1.2 Статистичні гіпотези\n\n1.2.1 Постановка задачі\nМи з’ясували, що навіть за ймовірності \\(\\mu = 0.5\\) можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали seed для отримання такого результату. Якщо повторити цей експеримент з іншим значенням seed або збільшити кількість спостережень, результат може виявитися іншим.\n\n\n\n\n\n\nПорада\n\n\n\nСпробуйте змінити seed (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.\n\n\nТож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту статистично значущими необхідно отримати відповідь на питання:\n\nЧи можна вважати, що спостережуване значення \\(\\hat{\\mu}\\) є більшим від \\(\\mu = 0.5\\)?\n\nЗвернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину \\(\\xi\\), яка підпорядковується розподілу Бернуллі3. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.\n\\[\n\\xi \\sim \\text{Bernoulli}(\\mu)\n\\]\nде \\(\\mu\\) — ймовірність успіху.\nНас цікавить підтвердження того, що \\(\\mu &gt; 0.5\\). У статистиці для перевірки гіпотез розглядають дві можливості:\n\nНульова гіпотеза (\\(H_0\\)) формулюється як твердження, яке ми прагнемо спростувати.\nАльтернативна гіпотеза (\\(H_1\\)) висловлює припущення, яке ми хочемо довести.\n\nСкорочено це записують як:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 0.5 \\\\\nH_1 &: \\mu &gt; 0.5\n\\end{aligned}\n\\]\nЗауважимо, що якщо в нашому експерименті з 30 студентами можна дивитися не на частку успіхів, а на їх кількість.\nТоді питання можна переформулювати так:\n\nЗа умови вірності \\(H_0\\) наскільки ймовірно отримати 20 або більше успішних випадків з 30?\n\nЯкщо ми проводимо \\(n\\) незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу4.\n\\[\nS_n = \\sum_{i=1}^{n} \\xi_i \\sim \\text{Binomial}(n, \\mu)\n\\]\nде \\(\\xi_i\\) — випадкова величина, яка показує успіх у \\(i\\)-му спостереженні, \\(S_n\\) — кількість успішних випадків у \\(n\\) спостереженнях, \\(n\\) — кількість спостережень, \\(\\mu\\) — ймовірність успіху.\nДавайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\).\n\n\n\nЛістинг 1.2: Функція щільності ймовірностей для біноміального розподілу\n\n\n\n1n = 30\n2mu = 0.5\n\n3x = np.arange(0, n + 1)\n4y = binom.pmf(x, n, mu)\n\n5plt.bar(x, y, color=turquoise)\n6plt.bar(x[x &gt;= 20], y[x &gt;= 20], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nКількість студентів.\n\n2\n\nЙмовірність успіху.\n\n3\n\nСтворюємо масив з усіма можливими значеннями кількості успішних випадків.\n\n4\n\nОбчислюємо ймовірності для кожної кількості успішних випадків.\n\n5\n\nСтворюємо гістограму з ймовірностями.\n\n6\n\nВиділяємо ймовірності для кількості успішних випадків, які є більшими або рівними 20.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nРисунок 1.1: Візуалізація функції щільності ймовірностей для біноміального розподілу\n\n\n\n\n\nЦіановим5 кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює 20.\n\n\n1.2.2 Критерій\nЩойно ми розробили алгоритм, який на основі вибірки \\(\\xi\\) або визнає наявність доказів на користь \\(H_1\\), або повідомляє, що таких доказів немає. Відповідно, він або відхиляє \\(H_0\\), або не відхиляє її.\nТакий алгоритм називається критерієм. Його можна подати у вигляді функції \\(S\\), яка приймає реалізацію вибірки та повертає \\(1\\), якщо слід відхилити \\(H_0\\), та \\(0\\) в іншому випадку.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо відхиляємо } H_0 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nДавайте припустимо, що ми вирішили відхилити \\(H_0\\), якщо кількість успішних випадків перевищує або дорівнює 21. Тоді критерій набуде вигляду:\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо } \\sum \\xi_i \\geqslant 21 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nЗазвичай скорочують запис і пишуть просто правило, за яким відхиляємо \\(H_0\\)\n\\[\nS = \\{\\sum \\xi_i \\geqslant 21\\}\n\\]\nПозначимо \\(Q = \\sum \\xi_i\\), \\(C = 21\\), тоді критерій набуває вигляду:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}\n\\]\nТак влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. \\(Q\\) називається статистикою критерію, \\(C\\) — критичним значенням.\n\\(Q\\) може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх \\(\\xi_i\\). Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.\n\n\n1.2.3 Критична область\nЗнову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію \\(S\\):\n\nНаскільки часто може бути таке, що за справедливості \\(H_0\\) критерій \\(S\\) відхиляє гіпотезу?\n\nВідповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним 21, побачивши на картинці, що великі відхилення відбуваються при \\(H_0\\) рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення \\(C\\), виходячи з частоти помилок нашого критерію.\nВибираючи \\(C\\), ми можемо або часто відхиляти нульову гіпотезу, коли \\(C\\) мале, або можемо робити це рідше, коли \\(C\\) велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.\n\n\\(C = 16\\). Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із 30, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає \\(1\\), тобто це помилка хибно позитивна (false positive, FP).\n\\(C = 29\\). У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб’ємося цього. Не відхилити гіпотезу \\(H_0\\), коли вона неправильна — це теж помилка. Вона називається хибно негативна (false negative, FN), оскільки критерій повернув 0 помилково.\n\n\\[\n\\text{FP} - H_0 \\text{відхиляється, коли вона вірна}\n\\]\n\\[\n\\text{FN} - H_0 \\text{не відхиляється, коли вона не вірна}\n\\]\nУ нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.\nТому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж частота хибнопозитивних спрацьовувань (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності \\(H_0\\).\nТепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.\n\nЯкий FPR у критерію \\(S\\) для перевірки гіпотези \\(H_0\\) проти \\(H_1\\)?\n\nКоли \\(H_0\\) є вірною, щоб порахувати кількість успіхів ми проводили 30 разів підкидання монетки з ймовірністю орла \\(0.5\\). Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при \\(\\mu = 0.5\\) наша статистика має біноміальний розподіл \\(Q \\sim Binom(0.5, 30)\\).\nОбчислимо FPR для \\(C = 21\\)\n\\[\n\\begin{aligned}\nFPR &= P(S(\\xi) = 1\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ \\mu = 0.5) = \\\\\n&= P(Q \\geqslant 21\\ |\\ Q \\sim Binom(0.5, 30))\n\\end{aligned}\n\\]\nЦе вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.\n\n\n1.2.4 Обчислення FPR\nДавайте порахуємо суму ймовірностей для кількостей успіхів від 21 до 30 включно. Покажемо графічно, як це виглядає на Рисунку 1.2.\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, 0.5)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink)\nfor i in range(crit_subs - 2, crit_subs + 4):\n    plt.text(i + 0.5, y[i] + 0.001, f\"{round(y[i] * 100, 1)}%\",\n    ha='center', va='bottom', size=8, rotation = 30)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.2: Ймовірність хибно відхилити \\(H_0\\) за умови її вірності\n\n\n\n\n\nЗалишається лише обчислити суму ймовірностей для кількостей успіхів від 21 до 30 включно. Це і буде нашим FPR.\n\\[\nFPR_{21} = \\sum_{i = 21}^{30} P(Q = i) \\approx 0.021\n\\]\nУ нашому випадку це буде 2.1%. Якщо FPR не перевищує деякої константи \\(\\alpha\\), то критерій називається критерієм рівня значущості \\(\\alpha\\). Статистичний критерій з \\(\\alpha\\) = 100% створити тривіально — достатньо завжди відхиляти \\(H_0\\) — тому така постановка не має сенсу.\nРівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть \\(\\alpha = 0.05\\), але якщо потрібне більш точне ухвалення рішення, можуть вибрати \\(0.01\\), \\(0.005\\), \\(0.001\\). Якщо ж рішення не таке критичне, можуть вибрати \\(0.1\\).\nПрипустимо, вибрали значення \\(\\alpha = 0.05\\), скористаємося критерієм \\(S\\): тобто якщо кількість успішних випадків перевищує або дорівнює 21, то відхиляємо \\(H_0\\).\nЯкщо уважно подивитись на Рисунок 1.2, то можна помітити, що ми можемо відхиляти \\(H_0\\) при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати \\(\\alpha = 0.05\\):\n\\[\nFPR_{20} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.049\n\\]\nЯкщо ж обрати 19, то FPR буде більше \\(\\alpha\\): \\[\nFPR_{19} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.1002\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-функції-в-python",
    "href": "binom.html#статистичні-функції-в-python",
    "title": "1  Біноміальний критерій",
    "section": "1.3 Статистичні функції в Python",
    "text": "1.3 Статистичні функції в Python\nУ цій частині подивимося, як вивести те, що ми отримали в частині 2, за допомогою Python. А також зрозуміємо, як знайти відповідне \\(C\\) за допомогою Python.\n\n1.3.1 Біноміальний розподіл\nМи з’ясували, що статистика \\(Q\\) має біноміальний розподіл.\nБіноміальний розподіл \\(Binom(n, \\mu)\\) — розподіл кількості успіхів у послідовності з \\(n\\) незалежних випадкових експериментів, ймовірність успіху в кожному з яких дорівнює \\(\\mu\\).\nЩоб працювати з розподілом, можна створити об’єкт-розподіл за допомогою бібліотеки scipy.stats.\n\n\n\n\nЛістинг 1.3: Створення біноміального розподілу\n\n\nfrom scipy.stats import binom\n\nn = 30\nmu = 0.5\n\nbinom_dist = binom(n, mu)\n\n\n\n\n\nКількість спостережень.\nЙмовірність успіху.\n\n\n\n1.3.2 Функція ймовірностей\nФункція ймовірності дискретного розподілу \\(p_\\xi(x)\\) — ймовірність, з якою \\(\\xi\\) приймає значення \\(x\\).\nУ Python це функція pmf (probability mass function).\n\n\n\n\nЛістинг 1.4: Обчислення ймовірностей біноміального розподілу для кількості успіхів\n\n\nbinom_dist.pmf(20)\n\n\n\n\n0.027981600724160654\n\n\nЗобразимо розподіл статистики \\(Q\\) за справедливості \\(H_0\\) на графіку. Для цього можна передати відразу масив точок, для яких треба розрахувати ймовірність.\n\n1x = np.arange(0, n + 1)\n2y = binom_dist.pmf(x)\n\n3crit_subs = 21\n\n4plt.bar(x, y, color=turquoise, label=\"Ймовірність успіхів\")\n5plt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink, label=\"Критичне значення\")\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nМасив точок.\n\n2\n\nРозрахунок ймовірностей.\n\n3\n\nКритичне значення.\n\n4\n\nЙмовірність успіхів.\n\n5\n\nКритичне значення.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.3: Функція щільності ймовірностей біноміального розподілу\n\n\n\n\n\nНасправді вже зараз ми можемо порахувати ймовірність потрапляння в критичну область. Потрібно просто підсумувати ймовірності для кількостей успіхів від 21 до 30.\n\n\n\n\nЛістинг 1.5: Обчислення ймовірностей для критичної області\n\n\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.0214\n\n\nОтже, ми дійсно побудували критерій рівня значущості \\(\\alpha = 0.05\\). Ба більше, це критерій рівня значущості 0.021.\nА що якби ми взяли \\(C = 19\\)?\n\n\n\n\nЛістинг 1.6: Обчислення ймовірностей для критичної області при \\(C = 19\\)\n\n\ncrit_subs = 19\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.1002\n\n\nТоді ймовірність помилки вже навіть більше \\(10\\%\\), що зовсім нам не підходить.\nА якщо \\(C = 20\\)?\n\n\n\n\nЛістинг 1.7: Обчислення ймовірностей для критичної області при \\(C = 20\\)\n\n\ncrit_subs = 20\nnp.round(np.sum(y[crit_subs:]), 4)\n\n\n\n\n0.0494\n\n\nВидно, що немає такого \\(C\\), щоб FPR був рівно \\(5\\%\\).\n\n\n1.3.3 Кумулятивна функція розподілу\nКумулятивна функція розподілу \\(F_\\xi(x) = P(\\xi \\leqslant x)\\)\nУ Python це функція cdf (Cumulative Distribution Function).\n\n\n\n\nЛістинг 1.8: Обчислення кумулятивної функції розподілу біноміального розподілу\n\n\nbinom_dist.cdf(19)\n\n\n\n\n0.9506314266473055\n\n\nЙмовірність отримати \\(19\\) або менше успіхів у нашому завданні \\(\\geqslant 0.95\\). А оскільки \\(P(\\xi \\leqslant 19) + P(\\xi \\geqslant 20) = 1\\), можемо обчислити рівень значущості нашого критерію.\n\n\n\n\nЛістинг 1.9: Обчислення рівня значущості критерію\n\n\n1 - binom_dist.cdf(19)\n\n\n\n\n0.04936857335269451\n\n\n\n\n1.3.4 Квантиль\nЩоб вибрати критичну область для критерію, ми хотіли б знайти точку, площа стовпців праворуч від якої була б \\(5\\%\\). Тобто площа стовпців зліва — \\(95\\%\\). Така точка називається квантилью.\n\\[\nu_p(\\xi) = \\{x\\ | F_\\xi(x) = p\\}\n\\]\nАле при \\(p = 0.95\\) й нашому біноміальному розподілі, такої точки немає. Ми з’ясували, що є точка, праворуч від якої площа \\(0.494\\), а в наступної вже \\(0.1\\). Щоб визначити квантиль у цьому випадку, модифікуємо визначення. Квантиль \\(u_p(\\xi)\\) — величина, яку \\(\\xi\\) не перевищує з імовірністю хоча б \\(p\\). Тобто \\(F_\\xi(u_p) \\geqslant p\\).\n\\[\nu_p(\\xi) = min\\ \\{x\\ |\\ F_\\xi(x) \\geqslant p \\}\n\\]\n\nПриклад 1.1 Для величини \\(\\xi \\sim Bin(30, 0.5)\\) порахуємо 0.95-квантиль. Вирішимо задачу просто підбором.\n\\[\nP(\\xi \\leqslant 18) \\approx 0.90\n\\]\n\\[\nP(\\xi \\leqslant 19) \\approx 0.951\n\\]\n\\[\nP(\\xi \\leqslant 20) \\approx 0.97\n\\]\nБачимо, що 18 нам ще не підходить, а 19 й більші значення вже підійдуть. У них функція розподілу буде більшою за \\(p\\). Відповідь — найменше відповідне значення, тобто 19. При цьому немає точки, де функція розподілу дорівнювала б \\(p\\) в точності.\nЯкби розподіл був неперервним, можна було б сказати, що квантиль — це таке \\(x\\), на якому функція розподілу дорівнює \\(p\\). Але для дискретного розподілу такого може не бути.\n\nУ Python квантиль можна порахувати через функцію ppf (Percent Point Function).\n\n\n\n\nЛістинг 1.10: Обчислення квантилю біноміального розподілу\n\n\nbinom_dist.ppf(0.95)\n\n\n\n\n19.0\n\n\nЯк тепер підібрати \\(C\\) для будь-яких \\(n, \\mu\\) й для будь-якого рівня значущості \\(\\alpha\\)?\n\nПотрібно знайти \\(C\\), таке що \\(P(Q \\geqslant C) \\leqslant \\alpha\\)\nТобто потрібно \\(P(Q &lt; C) \\geqslant 1 - \\alpha\\)\n\\(Q\\) приймає тільки цілі значення: \\(P(Q \\leqslant C - 1) \\geqslant 1 - \\alpha\\), або \\(F(C - 1) \\geqslant 1 - \\alpha\\)\nОтже, з визначення квантилі, \\(C - 1 = u_{1 - \\alpha}\\)\nЗначить \\(C = u_{1 - \\alpha} + 1\\)\n\n\n\n\n\nЛістинг 1.11: Знаходження критичного значення для критерію\n\n\ndef find_crit_subs(n, mu, alpha):\n    binom_dist = binom(n, mu)\n    return binom_dist.ppf(1 - alpha) + 1\n\n\nfind_crit_subs(30, 0.5, 0.05)\n\n\n\n\n20.0\n\n\nКритичне значення \\(20\\), отже підсумковий критерій має такий вигляд\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\n\\(Q = 19\\), значить гіпотезу ми не відкидаємо.\nПри цьому нам вдалося побудувати процес, за яким ми ухвалюємо рішення для будь-якого рівня значущості та значення статистики критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#p-значення",
    "href": "binom.html#p-значення",
    "title": "1  Біноміальний критерій",
    "section": "1.4 \\(p\\)-значення",
    "text": "1.4 \\(p\\)-значення\nЗауважимо, що зараз, якщо нам зададуть іншу \\(\\alpha\\), нам доведеться перебудовувати критерій заново. Це не зовсім зручно. У статистиці є механізм \\(p\\)-значення, який дає змогу прийняти рішення для всіх \\(\\alpha\\) відразу.\n\n1.4.1 Більш екстремальні значення\nПрипустимо, ми провели експеримент й порахували для критерію його статистику \\(Q(\\xi)\\). Позначимо отримане значення \\(q\\), у поточній задачі це \\(q = 19\\). Якби кількість успішних підписок була більшою, це б сильніше свідчило на користь альтернативної гіпотези \\(H_1\\). Тобто в разі значення \\(25\\) ми були б ще сильніше впевнені в тому, що наш бізнес буде окупатися. Тоді значення \\(25\\) називається більш екстремальним, ніж значення \\(19\\). У нашій задачі більш екстремальним із двох значень є те, яке більше.\nВизначимо поняття екстремальності формально:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}:\\ t\\ \\text{екстремальніше}\\ q \\Leftrightarrow t &gt; q\n\\]\nНайчастіше критерії інших видів можна привести до цього, тоді для них теж визначено поняття екстремальності.\n\n\n1.4.2 \\(p\\)-значення\np-value — це ймовірність отримати таке або більш екстремальне значення статистики \\(q\\) за умови вірності \\(H_0\\).\n\\[\nP_{H_0}(Q \\geqslant q)\n\\]\n\n\n\n\n\n\n\n\nРисунок 1.4: \\(p\\)-значення для критерію \\(Q = 15\\)\n\n\n\n\n\nТепер виведемо формулу через функції Python:\n\\[\nP_{H_0}(Q \\geqslant q) = 1 - P_{H_0}(Q &lt; q) = 1 - F(q)\n\\]\nЗобразимо на графіку область більш екстремальних значень й p-value для різних значень статистики.\n\n\n\n\n\n\n\n\nРисунок 1.5: \\(p\\)-значення для критерію \\(Q = 10, 19, 20, 25\\)\n\n\n\n\n\nМожна побачити, що в критичній області \\(p\\)-значення \\(\\leqslant \\alpha\\), а поза нею \\(p\\)-значення \\(&gt; \\alpha\\). Саме таке правило й використовується для прийняття рішення.\n\\[\nH_0 \\text{ відкидається } \\Leftrightarrow p-значення \\leqslant \\alpha\n\\]\nПричому за \\(p\\)-значення одразу видно, що якби в нашу критичну область включили значення \\(19\\), наш критерій допускав би FPR у \\(10\\%\\) випадків, що вже неприпустимо. Тому й гіпотезу ми не відкидаємо.\nЗауважимо, що для обчислення \\(p\\)-значення не знадобилося знання \\(\\alpha\\), а потрібна була тільки статистика й форма критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#двосторонні-критерії",
    "href": "binom.html#двосторонні-критерії",
    "title": "1  Біноміальний критерій",
    "section": "1.5 Двосторонні критерії",
    "text": "1.5 Двосторонні критерії\nДо цього моменту нас цікавили відхилення від ймовірності в \\(50\\%\\) тільки в один бік. І логічно, адже це продиктовано бізнесом. Тільки велика частка успішних підписок призведе до успіху. І зазвичай при прийнятті рішень так й буває. При тестуванні нового рішення або продукту розглядають альтернативну гіпотезу тільки в бік поліпшення, тому що в іншому разі немає сенсу впроваджувати рішення на всіх користувачів.\nОднак іноді може знадобитися доводити відхилення в обидва боки, якщо ви перевіряєте якесь припущення. Нехай вам дали монетку й просять перевірити, чесна вона чи ні. Монетка чесна, якщо під час підкидання ймовірність випадання орла дорівнює \\(0.5\\). Ви підкидаєте монетку \\(30\\) разів, кожен кидок — бернуллівська величина, аналогічно завданню з сервісом освітніх послуг. Нульова гіпотеза та ж сама: \\(\\mu = 0.5\\). Але тепер ми хочемо відкидати цю гіпотезу як у разі великої ймовірності орла, так і в разі маленької, відповідно перевіряємо двосторонню гіпотезу.\n\\[\nH_0: \\mu = 0.5\n\\]\n\\[\nH_1: \\mu \\neq 0.5\n\\]\nВиберемо критичну область для критерію за такої альтернативи. Скористаємося тією ж статистикою \\(Q(\\xi) = \\sum \\xi_i\\). Тільки тепер відхилення в кожну сторону однаково важливі. Відкидати гіпотезу будемо не тільки на досить великих значеннях, а й на досить маленьких. Наприклад, якщо у нас було всього \\(2\\) орла з \\(30\\) — це свідчення на користь того, що \\(\\mu \\neq 0.5\\), але не на користь \\(\\mu &gt; 0.5\\).\nОскільки відхилення в різні боки однаково важливі, а розподіл симетричний, шукати критерій можна в такому вигляді:\n\\[\nS = \\{Q \\geqslant C\\} \\cup \\{Q \\leqslant n - C\\}\n\\]\n\n1.5.1 Як вибрати критичну область\nПодивимося, який вигляд матиме критична область у такому разі.\n\n\n\n\n\n\n\n\nРисунок 1.6: Двостороння критична область для критерію \\(С = 6\\)\n\n\n\n\n\nЗ картинки видно, що якщо тепер відкидати відхилення за \\(Q \\geqslant 20\\), то необхідно відкидати й \\(Q \\leqslant 10\\), а отже, загальна площа стовпців буде вже приблизно \\(0.1\\). Тому за рівня значущості \\(0.05\\) й \\(20\\) успіхів гіпотеза вже не відкинеться.\nЯкщо ж виставити \\(C = 6\\), то така область уже підходить, площа стовпців \\(\\approx 0.043 &lt; 0.05\\).\nЩоб вибрати порогову константу за формулою, можна помітити, що критична область симетрична, а значить праворуч площа не повинна бути більшою, ніж \\(\\frac{\\alpha}{2}\\). А таку задачу ми вже вміємо розв’язувати.\nРеалізуємо функцію на Python.\n\n\n\n\nЛістинг 1.12: Знаходження критичного значення для двостороннього критерію\n\n\ndef find_crit_subs_two_sided(n, mu, alpha):\n    binom_dist = binom(n, mu)\n    return n / 2 - binom_dist.ppf(alpha / 2) + 1\n\nfind_crit_subs_two_sided(30, 0.5, 0.05)\n\n\n\n\n6.0\n\n\n\n\n1.5.2 Як знайти \\(p\\)-значення\nКритерій має вигляд\n\\[\nS = \\{|Q(\\xi) - 15| \\geqslant C\\}\n\\]\nПозначимо відхилення суми від 15 як \\(\\Delta(\\xi) = |Q(\\xi) - 15|\\), тоді ми маємо критерій\n\\[\nS = \\{\\Delta(\\xi) \\geqslant C\\}\n\\]\nТобто більш екстремальними вважатимуться ті значення суми, що знаходяться далі від 15. Щоб обчислити \\(p\\)-значення, доведеться порахувати суму площ із двох сторін окремо.\n\n\n\n\nЛістинг 1.13: Обчислення \\(p\\)-значення для двостороннього критерію\n\n\ndef pvalue_two_sided_sym(n, q):\n    binom_h0 = binom(n=n, p=0.5)\n    diff = np.abs(q - 15)\n    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n    left_sq = binom_h0.cdf(15 - diff)\n    return left_sq + right_sq\n\npvalue_two_sided_sym(30, 21)\n\n\n\n\n0.04277394525706769\n\n\nНасправді через симетричність розподілу ліва і права площа виходять однаковими, тому можна порахувати площу з одного боку і помножити на 2.\n\n\n\n\nЛістинг 1.14: Обчислення \\(p\\)-значення для двостороннього критерію (спрощено)\n\n\ndef pvalue_two_sided_sym_simple(n, q):\n    binom_h0 = binom(n=n, p=0.5)\n    diff = np.abs(q - 15)\n    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n    return 2 * right_sq\n\npvalue_two_sided_sym_simple(30, 21)\n\n\n\n\n0.04277394525706768\n\n\nТепер навіть у разі \\(20\\) орлів \\(p\\)-значення \\(&gt; 0.05\\), тому відкидати будемо значення, починаючи з \\(21\\) й менші або такі, що дорівнюють \\(9\\).\n\n\n1.5.3 Випадок із несиметричним розподілом\nКоли розподіл за справедливості \\(H_0\\) несиметричний, відхилення від очікуваного значення в різні боки можуть бути по-різному критичними. Як приклад розглянемо також біноміальний розподіл, але з імовірністю успіху \\(0.8\\).\nТоді можна ліву і праву критичні області побудувати окремо, виділивши на них по \\(\\frac{\\alpha}{2}\\) площі. Праву область ми вже вміємо шукати, знайдемо ліву.\n\nbinom_h0_nonsym = binom(n=30, p=0.8)\n\nprobs = binom_h0_nonsym.pmf(np.arange(31))\n\nplt.bar(np.arange(31), probs, color=turquoise, label=\"Binom(30, 0.8)\")\nplt.legend(fontsize=8)\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.7: Біноміальний розподіл з імовірністю успіху \\(0.8\\)\n\n\n\n\n\nДля того, щоб побудувати двосторонній критерій, потрібно знайти ліворуч і праворуч області, площа яких становить не більше, ніж \\(\\frac{\\alpha}{2}\\). Для правого боку ми вже розв’язували таку задачу, розв’яжемо для лівого.\nШукаємо \\(C\\), таке що\n\\[\nP(Q(\\xi) \\leqslant C) \\leqslant \\frac{\\alpha}{2}\n\\]\nСпочатку знайдемо перше число, де ймовірність \\(\\geqslant \\frac{\\alpha}{2}\\). А це за визначенням \\(\\frac{\\alpha}{2}\\)-квантиль. Достатньо взяти попереднє число, і воно буде задовольняти нашій умові.\n\n\n\n\nЛістинг 1.15: Знаходження критичного значення для двостороннього критерію\n\n\ndef two_sided_criterion_nonsym(n, mu, alpha):\n    binom_h0 = binom(n=n, p=mu)\n    c2 = binom_h0.ppf(1 - alpha/2) + 1\n    c1 = binom_h0.ppf(alpha/2) - 1\n    return c1, c2\n\ntwo_sided_criterion_nonsym(30, 0.8, 0.05)\n\n\n\n\n(18.0, 29.0)\n\n\nОтже, наш критерій для перевірки гіпотези\n\\[\nH_0: \\mu = 0.8\n\\]\n\\[\nH_1: \\mu \\neq 0.8\n\\]\nмає вигляд\n\\[\nS = \\{Q(\\xi) \\leqslant 18\\} \\cup \\{Q(\\xi) \\geqslant 29\\}\n\\]\nТут межа \\(29\\) уже має логічний вигляд, бо треба спростувати 80% орлів/успіхів, а для цього потрібна велика їхня кількість.\nЗобразимо критичну область на графіку.\n\nC1, C2 = two_sided_criterion_nonsym(30, 0.8, 0.05)\n\nplt.figure(figsize=(6, 4))\nplt.bar(np.arange(31), probs, color=turquoise, label=\"Binom(30, 0.8)\")\nplt.bar(np.arange(31)[np.arange(31) &lt;= C1], probs[np.arange(31) &lt;= C1], color=red_pink, label=\"Критичне значення\")\nplt.bar(np.arange(31)[np.arange(31) &gt;= C2], probs[np.arange(31) &gt;= C2], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.legend(fontsize = '8', loc = 'upper left')\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.8: Двостороння критична область для критерію \\(C_1 = 18, C_2 = 29\\)\n\n\n\n\n\n\n\n1.5.4 \\(p\\)-значення для несиметричного розподілу\nЦей критерій — об’єднання двох критеріїв рівня значущості \\(\\frac{\\alpha}{2}\\), для кожного з яких можна порахувати \\(p\\)-значення. Позначимо їх як \\(p_1, p_2\\). Перший критерій відкидається при \\(p_1 \\leqslant \\frac{\\alpha}{2}\\), другий при \\(p_2 \\leqslant \\frac{\\alpha}{2}\\). А наш об’єднаний, коли виконано одну з цих умов, тобто\n\\[\n2p_1 \\leqslant \\alpha \\vee 2p_2 \\leqslant \\alpha \\Leftrightarrow 2 \\cdot \\min(p_1, p_2) \\leqslant \\alpha\n\\]\nОтже, можна рахувати \\(p\\)-значення як \\(2 \\min(p_1, p_2)\\) й порівнювати з \\(\\alpha\\).\nПроведемо аналогію із симетричним випадком: якщо сума опинилася в лівій частині, то потрібно порахувати \\(p\\)-значення лівого критерію і помножити на 2. Якщо сума опинилася в правій частині, то потрібно порахувати \\(p\\)-значення правого критерію і помножити на 2.\n\n\n\n\nЛістинг 1.16: Обчислення \\(p\\)-значення для двостороннього критерію з несиметричним розподілом\n\n\ndef pvalue_two_sided(n, q, mu=0.5):\n    binom_h0 = binom(n=n, p=mu)\n    pvalue_left = binom_h0.cdf(q)\n    pvalue_right = 1 - binom_h0.cdf(q - 1)\n    return 2 * min(pvalue_left, pvalue_right)\n\npvalue_two_sided(30, 28, 0.8)\n\n\n\n\n0.08835797030399428\n\n\nВидно, що \\(p\\)-значення \\(&gt; 0.05\\), отже, на рівні значущості \\(0.05\\) навіть \\(28\\) успіхів недостатньо, щоб відкинути ймовірність успіху в \\(80\\%\\).\nЗауважимо, що ця ж функція працює і для симетричного випадку, повертаючи той самий результат.\n\n\n\n\nЛістинг 1.17: Обчислення \\(p\\)-значення для двостороннього критерію з симетричним розподілом\n\n\npvalue_two_sided(n=30, q=20, mu=0.5)\n\n\n\n\n0.09873714670538902\n\n\n\n\n\n\nЛістинг 1.18: Знаходження \\(p\\)-значення для двостороннього критерію\n\n\npvalue_two_sided_sym(n=30, q=20)\n\n\n\n\n0.09873714670538904",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#готові-функції",
    "href": "binom.html#готові-функції",
    "title": "1  Біноміальний критерій",
    "section": "1.6 Готові функції",
    "text": "1.6 Готові функції\nЗвісно, можна використати готові функції з бібліотеки scipy. Для цього використаємо функцію binomtest, котра має параметри:\n\nk — кількість успіхів\nn — кількість спостережень\np — ймовірність успіху\nalternative — тип гіпотези:\n\ntwo-sided: двостороння\ngreater: правостороння\nless: лівостороння\n\n\n\n\n\nЛістинг 1.19\n\n\nfrom scipy.stats import binomtest\n\nresult = binomtest(19, 30, 0.5, alternative='two-sided')\n\nprint(f\"Статистика: {result.statistic:.2f}\")\nprint(f\"p-значення: {result.pvalue:.4f}\")\n\nСтатистика: 0.63\np-значення: 0.2005",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#висновки",
    "href": "binom.html#висновки",
    "title": "1  Біноміальний критерій",
    "section": "1.7 Висновки",
    "text": "1.7 Висновки\nМи розглянули, як можна використовувати біноміальний розподіл для перевірки гіпотези про ймовірність успіху. Для цього ми визначили критерій, критичну область, \\(p\\)-значення. Показали, як можна використовувати ці поняття для різних видів гіпотез: односторонніх, двосторонніх, симетричних та несиметричних.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#питання-для-самоперевірки",
    "href": "binom.html#питання-для-самоперевірки",
    "title": "1  Біноміальний критерій",
    "section": "1.8 Питання для самоперевірки",
    "text": "1.8 Питання для самоперевірки\n\nЯкі гіпотези можна перевірити за допомогою біноміального розподілу?\nЯк визначити критичну область для критерію?\nЯк визначити \\(p\\)-значення для критерію?\nЯк визначити критичну область для двостороннього критерію?\nЯк визначити \\(p\\)-значення для двостороннього критерію?\nЯк визначити критичну область для несиметричного розподілу?\nЯк визначити \\(p\\)-значення для несиметричного розподілу?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#footnotes",
    "href": "binom.html#footnotes",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "У статистиці \\(\\hat{\\mu}\\) позначається як оцінка параметра \\(\\mu\\).↩︎\nМетод integers() генерує випадкові цілі числа в заданому діапазоні. Аргумент endpoint вказує, що верхня межа включається у діапазон.↩︎\nРозподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.↩︎\nБіноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума \\(n\\) незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.↩︎\nАнгл. cyan, від грец. κυανouς — “блакитний”, “лазуровий”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "power.html",
    "href": "power.html",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1 Статистична потужність",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#статистична-потужність",
    "href": "power.html#статистична-потужність",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1.1 Хибно негативні помилки\nРаніше під час побудови критеріїв ми звертали увагу тільки на \\(\\alpha\\), рівень значущості критерію. Але цей параметр контролює лише хибнопозитивну помилку (False Positive), а саме ймовірність, що критерій прийме \\(H_1\\) за умови вірності \\(H_0\\).\nАле є ще один вид помилок, які може допустити критерій — хибно негативні помилки (False Negative). Це випадки, коли критерій приймає \\(H_0\\) за умови вірності \\(H_1\\). Це важливо, оскільки вони можуть вказувати на те, що критерій не чутливий до змін, які відбуваються в даних.\nВипадок, коли ймовірність FPR \\(&lt; \\alpha\\), але при цьому ймовірність хибно негативні помилки (False Negative Rate, FNR) величезна, можна навести легко. Для цього достатньо ніколи не відкидати гіпотезу, взявши критерій \\(S \\equiv 0\\).\nНаведемо приклад, коли помилки False Negative відбуваються не завжди, але критерії є все одно нечутливими.\n\n\n2.1.2 Критерій пори року\nПоставимо гіпотезу про те, що зараз на вулиці літо. Для перевірки можна було б, звісно, подивитися в календар, але ми зробимо інакше.\n\\[\nH_0: \\text{ на вулиці літо}\n\\]\n\\[\nH_1: \\text{ на вулиці не літо}\n\\]\nПодивимося у вікно і визначимо, чи йде там сніг. Якщо він йде, то це непоганий доказ того, що зараз не літо, а отже можна відкинути \\(H_0\\).\nПорахуємо FPR та FNR для цього критерію. Ми знаємо, що влітку сніг іде дуже рідко (ймовірність помилки нижча за \\(0.1\\%\\)), тож це точно критерій рівня значущості \\(0.001\\), чого зазвичай достатньо для критеріїв.\n\\[\nFPR(S) = P(\\text{йде сніг}\\ |\\ \\text{сьогодні літо}) &lt; 0.001\n\\]\nАле що з FNR? Розглянемо конкретний випадок: зараз вересень. Оскільки у вересні майже завжди немає снігу, можна сказати, що FNR більша за \\(90\\%\\), отже, цей критерій насправді мало дієвий.\n\\[\nFNR(S) = P(\\text{не йде сніг}\\ |\\ \\text{зараз вересень}) &gt; 0.9\n\\]\nСформулюємо інший критерій рівня значущості \\(\\alpha\\), причому в цьому разі рівень значущості можна вибрати довільним.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо монетка з імовірністю орла } \\alpha \\text{ випала орлом} \\\\\n    0, \\text{ інакше}\n\\end{cases}\n\\]\nВиходить, цей критерій випадковий, і він не використовує взагалі жодної інформації про погоду. Однак вимогам до рівня значущості він задовольняє.\n\\[\nFPR = P(\\text{випав орел}\\ |\\ \\text{сьогодні літо}) = P(\\text{випав орел}) = \\alpha\n\\]\nОбчислимо FNR.\n\\[\nFNR = P(\\text{не випав орел}\\ |\\ \\text{сьогодні не літо}) = P(\\text{не випав орел}) = 1 - \\alpha\n\\]\nЗа \\(\\alpha = 0.001\\), як у першому випадку, отримуємо ймовірність FNR \\(0.999 &gt; 0.9\\), тобто за однакового рівня значущості з першим критерієм, другий критерій частіше припускається хибно негативної помилки.\n\n\n2.1.3 Потужність\nУ статистиці заведено позитивним результатом вважати відкидання нульової гіпотези, бо зазвичай підтвердження альтернативи означає наявність бізнес-результату. Тому вважається хорошим критерій, який частіше дає змогу виявити бізнес-результат. І рахують тоді не ймовірність хибно негативної помилки, а потужність, що дорівнює ймовірності відкинути нульову гіпотезу за вірності \\(H_1\\), тобто ймовірність істинно позитивного результату (True Positive Rate, TPR).\n\\[\n\\text{Power}_S = 1 - FNR\n\\tag{2.1}\\]\nКоли альтернатива \\(H_1\\) складається з множини результатів, потужність розглядають як функцію від результату. Наприклад, можна порахувати потужність першого та другого критеріїв взимку й восени.\n\\[\n\\text{Power}_S(\\mu) = 1 - FNR(\\mu)\n\\]\nПерший критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{їде сніг } | \\text{ травень}) \\approx 0.00001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{їде сніг } | \\text{ жовтень}) \\approx 0.1\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{їде сніг } | \\text{ січень}) \\approx 0.5\n\\]\nДругий критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{випав орел } | \\text{ травень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{випав орел } | \\text{ жовтень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{випав орел } | \\text{ січень}) = \\alpha = 0.001\n\\]\nЗазвичай завдання пошуку найкращого критерію формулюється як пошук якомога потужнішого критерію за заданого рівня значущості \\(FPR \\leqslant \\alpha\\). Але ми сказали, що потужність — функція від параметра, у нашому випадку від місяця.\nЯкщо ми застосовуватимемо критерій у січні, то потужнішим буде перший критерій, а якщо в травні, то потужнішим буде другий критерій. Тому потрібно розуміти, коли буде застосовуватися критерій, а отже, ми шукаємо найпотужніший критерій у галузі, яка нас цікавить.\nХоча в реальності в травні потужність обох критеріїв настільки низька, що вони просто не приносять користі, й використовувати їх не має сенсу.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#потужність-для-біноміального-розподілу",
    "href": "power.html#потужність-для-біноміального-розподілу",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.2 Потужність для біноміального розподілу",
    "text": "2.2 Потужність для біноміального розподілу\nЗастосуємо нові знання про потужність для нашої задачі з освітнім сервісом. З бізнес-міркувань ми вже вибрали \\(\\alpha = 0.05\\), а отже, знаємо, що ми неправильно відкидаємо гіпотезу \\(H_0:\\ \\mu = 0.5\\) з ймовірністю не більше, ніж \\(5\\%\\). Тобто цим обмежена ймовірність хибно позитивної помилки.\nА з якою ймовірністю ми будемо правильно відкидати гіпотезу? І яка в нас буде ймовірність хибно негативної помилки? На це запитання якраз відповість формула потужності.\nЗгадаймо критерій, за яким ми приймаємо рішення:\n\\[\nQ(\\xi) = \\sum\\limits_{i=1}^n \\xi_i - \\text{кількість підписок}\n\\]\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\nТобто якщо отримуємо хоча б \\(20\\) успішних підписок, то відкидаємо \\({H}_0\\).\nЗауважимо, що потужність залежить від того, яке значення \\(\\mu\\) у нашій генеральній сукупності. Зафіксуємо спочатку параметр \\(\\mu = 0.6\\) й порахуємо потужність для нього. Якщо істинний параметр такий, то статистика \\(Q\\) має розподіл \\(Binom(30, 0.6)\\).\n\nbinom_h0 = binom(n=30, p=0.5)\nbinom_alternative = binom(n=30, p=0.6)\n\nx_grid = np.arange(1, 31)\ncrit_reg = x_grid &gt;= 20\n\nprobs_h0 = binom_h0.pmf(x_grid)\nplt.bar(x_grid, probs_h0, color=turquoise, label='PMF, $Binom(0.5, 30)$')\n\nprobs_alternative = binom_alternative.pmf(x_grid)\nplt.bar(x_grid, probs_alternative, color=slate, label='PMF, $Binom(0.6, 30)$')\nplt.bar(x_grid[crit_reg], probs_alternative[crit_reg], color=red_pink, label='Критична область')\n\nplt.legend(fontsize=8)\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.1: Потужність критерію для \\(\\mu = 0.6\\)\n\n\n\n\n\nЯк і раніше, нас цікавить імовірність отримати \\(20\\) або більше успіхів. Але якщо раніше ми дивилися на неї для розподілу з \\(\\mu=0.5\\) й хотіли, щоб вона була меншою за \\(5\\%\\), то тепер ми дивимося за \\(\\mu = 0.6\\) та прагнемо зробити цю величину якомога більшою. Порівняно з обчисленням FPR формула не зміниться, змінюється тільки \\(\\mu\\)\n\n\n\n\nЛістинг 2.1: Обчислення потужності критерію\n\n\ncritical_value = 20\npower = 1 - binom(n=30, p=0.6).cdf(critical_value - 1)\nfpr   = 1 - binom(n=30, p=0.5).cdf(critical_value - 1)\n\nprint(f\"Хибно позитивна помилка: {fpr:.1%}\")\nprint(f\"Потужність: {power:.1%}\")\n\n\n\n\nХибно позитивна помилка: 4.9%\nПотужність: 29.1%\n\n\nВидно, що потужність близько \\(30\\%\\). Це досить маленьке значення, адже якщо наш продукт прибутковий, то ми побачимо це за допомогою нашого тесту тільки з імовірністю в \\(30\\) відсотків. Ми легко можемо пропустити ефект.\nЩо ж можна зробити, щоб зробити потужність вищою? Щоб розібратися, реалізуємо функцію потужності в загальному вигляді.\n\n\n\n\nЛістинг 2.2: Обчислення потужності критерію для загального випадку\n\n\ndef get_stat_power(N, mu_h0, mu_alternative, alpha):\n    '''Обчислює статистичну потужність критерію для біноміального розподілу\n    \n    Параметри:\n        N - кількість бернуллієвських експериментів (розмір вибірки)\n        mu_h0 - імовірність успіху в нульовій гіпотезі\n        mu_alternative - передбачувана ймовірність успіху в експерименті\n        alpha - рівень значущості критерію\n    '''\n    binom_h0 = binom(n=N, p=mu_h0)\n    binom_alternative = binom(n=N, p=mu_alternative)\n    critical_value = binom_h0.ppf(1 - alpha) + 1\n    return 1 - binom_alternative.cdf(critical_value - 1) \n\nget_stat_power(30, 0.5, 0.6, alpha=0.05)\n\n\n\n\n0.2914718612234968\n\n\nКоли в житті ми спостерігаємо якесь явище і бачимо його лише кілька разів, ми не впевнені в тому, що воно не випадкове. Якщо ж бачимо його досить часто, то вже складаємо закономірності. Так і в статистиці. Коли ми подивилися на 30 потенційних підписок, ми помічаємо, що частка доставок більше половини. Але ми все ще не впевнені. Щоб отримати більше впевненості, потрібно провести більше спостережень, тобто знайти більше пробних клієнтів.\nПодивимося, що буде, якщо ми проведемо експеримент на 300 клієнтах.\n\n\n\n\nЛістинг 2.3: Обчислення потужності критерію для 300 клієнтів\n\n\nget_stat_power(300, 0.5, 0.6, alpha=0.05)\n\n\n\n\n0.9655326717180749\n\n\nБачимо, що потужність уже дуже близька до \\(100\\%\\). Але провести 300 пробних занять набагато затратніше, ніж 30. І за ресурсами, і за часом. Тому зазвичай балансують між потужністю і тривалістю/витратами експерименту.\nПрийнято вважати, що прийнятною для роботи потужністю вважається \\(80\\%\\). Подивимося, як змінюється потужність при зростанні розміру вибірки, і скільки потрібно провести експериментів, щоб детектувати ефект при \\(\\mu = 0.6\\) у \\(80\\%\\) випадків.\n\nn_grid = np.arange(10, 600, 10)\npower = get_stat_power(n_grid, 0.5, 0.6, alpha=0.05)\n\nplt.xlabel('Кількість пробних занять')\nplt.ylabel('Потжність')\n\nplt.plot(n_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_n = n_grid[power &gt;= 0.8].min()\nplt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.2: Залежність потужності від розміру вибірки для \\(\\mu = 0.6\\)\n\n\n\n\n\nБачимо, що для потужності в \\(80\\%\\) достатньо набрати 160 пробних занять.\nА що, якщо ми хочемо детектувати ще менший ефект? Наприклад, якщо хочемо відкидати гіпотезу за \\(\\mu = 0.51\\). Часто поліпшення ймовірності успіху на \\(1\\%\\) може бути значущим для продукту, тому це питання не позбавлене сенсу.\n\nn_grid = np.arange(10, 30000, 59)\npower = get_stat_power(n_grid, 0.5, 0.51, alpha=0.05)\n\nplt.xlabel('Кількість пробних занять', fontsize=8)\nplt.ylabel('Потжність', fontsize=8)\n\nplt.plot(n_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_n = n_grid[power &gt;= 0.8].min()\nplt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.3: Залежність потужності від розміру вибірки для \\(\\mu = 0.51\\)\n\n\n\n\n\nБачимо, що потрібно понад 15 тисяч клієнтів, щоб детектувати такий ефект! Дуже складно знайти стільки пробних клієнтів. Але потрібно замислитися над питанням, а чи варто це робити? У нашому випадку, якщо ймовірність успіху \\(51\\%\\), то прибуток із замовлень буде невеликий, і вкладення інвесторів, звісно, окупатимуться, але дуже довго. Тому збільшення на \\(1%\\) для нашого завдання не значуще практично, а отже, не потрібно намагатися набирати 15 тисяч людей, а можна зупинитися і на 160.\nПеред кожним експериментом аналітику варто замислюватися над питанням тривалості тесту і кількості учасників. Для цього потрібно зрозуміти:\n\nЯкий ефект є для завдання практично значущим?\nСкільки знадобиться випробовуваних, щоб детектувати цей ефект частіше, ніж у \\(80\\%\\) випадків?\n\nЗ графіків видно, що для детектування меншого ефекту потрібен більший розмір вибірки. Подивимося, як для фіксованого \\(N=30\\) змінюється потужність для різних параметрів \\(\\mu\\).\n\nmu_grid = np.linspace(0.5, 0.9, 100)\npower = get_stat_power(30, 0.5, mu_grid, alpha=0.05)\n\nplt.xlabel('Ймовірність успіху')\nplt.ylabel('Потужність')\n\nplt.plot(mu_grid, power, color=turquoise)\nplt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\nmin_mu = mu_grid[power &gt;= 0.8].min()\nplt.axvline(min_mu, ls='--', color=slate, label=f'$\\mu = {min_mu:.2f}$')\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nРисунок 2.4: Залежність потужності від параметра \\(\\mu\\)\n\n\n\n\n\nУ нашому експерименті ми добре детектуємо ефект, тільки якщо ймовірність успіху в генеральній сукупності хоча б \\(72\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#мінімальна-величина-ефекту",
    "href": "power.html#мінімальна-величина-ефекту",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.3 Мінімальна величина ефекту",
    "text": "2.3 Мінімальна величина ефекту\nВище на Рисунок 2.4 ми побачили, що з хорошою потужністю понад \\(80\\%\\) ми можемо помітити ефект у \\(22\\) процентних пункти. Причому це можна порахувати навіть до проведення експерименту. У нашому випадку таке збільшення успішності щодо \\(0.5\\) цілком можливо, і з ним можна працювати. Але коли аналітики перевіряють зміни, найчастіше очікуваний ефект коливається в районі одного, максимум двох відсотків! Для подібних змін не підійде обрана постановка експерименту, а значить і проводити його не має сенсу.\nТому перед запуском експериментів аналітики повідомляють мінімальну величину ефекту, яку можна задетектувати (Minimal Detectable Effect, MDE). У нашому випадку \\(MDE = +22\\) процентних пункти.\nБільш формально, MDE для гіпотези \\(H_0: \\mu = \\mu_0\\) — це мінімальний ефект \\(\\delta\\), за якого критерій рівня значущості \\(\\alpha\\) для перевірки цієї гіпотези за істинного параметра \\(\\mu = \\mu_0 + \\delta\\) та розміру вибірки \\(N\\) відкидатиме \\({H}_0\\) з потужністю більшою, ніж \\(1 - \\beta\\).\nНайчастіше беруть \\(1 - \\beta = 80\\%\\). Напишемо функцію, яка обчислюватиме MDE підбором.\n\n\n\n\nЛістинг 2.4: Обчислення MDE\n\n\ndef binom_test_mde_one_sided(N, mu0, alpha=0.05, min_power=0.8):\n    delta_grid = np.linspace(0, 1 - mu0, 500) \n    power = get_stat_power(N, mu0, mu0 + delta_grid, alpha=alpha)\n    fit_delta = delta_grid[power &gt;= min_power]\n    return fit_delta[0]\n\nbinom_test_mde_one_sided(30, 0.5)\n\n\n\n\n0.21843687374749496\n\n\nРезультат збігається з обчисленнями за графіком Рисунок 2.4. Тобто ми можемо детектувати ефект у \\(22\\) процентних пункти.\nЗазвичай MDE розраховують не просто так, а нерозривно з ним іде питання про визначення розміру вибірки.\nУ нашому завданні ми знайшли \\(30\\) клієнтів, не обчислюючи спочатку, скільки їх знадобиться. Але що якщо отриманий MDE занадто великий й потрібно зробити його меншим, оскільки очікувані зміни набагато менші? Тоді вирішується зворотне завдання, За необхідним MDE визначити обсяг вибірки. Якщо ми говоримо, що хочемо детектувати +10 в.п., тобто 60% успішних підписок, то потрібно знайти 160 тестових клієнтів, це видно з попередніх графіків. Якщо 30 осіб нам, наприклад, шукати місяць, такий тест може затягнутися майже на півроку. Тому варто подумати про те, щоб виділити додаткові ресурси на пошук клієнтів, наприклад, залучити маркетологів.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#довірчі-інтервали",
    "href": "power.html#довірчі-інтервали",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.4 Довірчі інтервали",
    "text": "2.4 Довірчі інтервали\nРаніше ми навчилися перевіряти гіпотезу \\({H}_0: \\mu = 0.5\\). Як відповідь ми отримуємо лише вердикт “відкидаємо \\({H}_0\\)” або “не відкидаємо \\({H}_0\\)”. Однак у вибірці міститься набагато більше інформації, й ми можемо більше зрозуміти про параметр, ніж порівняння з числом \\(0.5\\).\nЯкщо гіпотеза \\({H}_0\\) не відкидається, це означає, що значення \\(\\mu = 0.5\\) припустиме для нашої вибірки. Отримані значення можна пояснити значенням \\(\\mu = 0.5\\). Але якщо у нас є механізм перевірки для будь-якого \\(\\mu\\), ми можемо для всіх значень дізнатися, які з них допустимі, і отримати множину можливих значень \\(\\mu\\). Така множина називається довірчим інтервалом.\nДовірчий інтервал рівня \\(1 - \\alpha\\) — множина значень параметра \\(\\mu_0\\), для яких гіпотеза \\(\\mu = \\mu_0\\) не відкидається критерієм рівня значущості \\(\\alpha\\).\nЗ визначення випливає, що різні критерії можуть породжувати різні довірчі інтервали. У цій частині розглянемо, які інтервали породжуються двостороннім критерієм. Для цього з кроком \\(0.001\\) переберемо значення \\(\\mu \\in [0, 1]\\) і перевіримо гіпотези.\n\n\n\n\nЛістинг 2.5: Довірчі інтервали для біноміального розподілу\n\n\ndef two_sided_criterion_nonsym(n, mu, alpha):\n    binom_h0 = binom(n=n, p=mu)\n    c2 = binom_h0.ppf(1 - alpha/2) + 1\n    c1 = binom_h0.ppf(alpha/2) - 1\n    return c1, c2\n\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n\n\n95% довірчий інтервал: [0.439 - 0.8]\n\n\n\nФункція, що обчислює критичні значення для двостороннього критерію.\nКількість успішних підписок.\nСітка значень \\(\\mu\\).\nСписок значень \\(\\mu\\), для яких гіпотеза не відкидається.\nПеребір значень \\(\\mu\\).\n\nОтримавши такий інтервал, ми відразу можемо зробити висновок, що гіпотеза \\({H}_0: \\mu = 0.5\\) не відкидається, оскільки \\(0.5\\) лежить у довірчому інтервалі. Але при цьому відразу зрозуміло, що \\(\\mu \\neq 0.4\\) на рівні значущості \\(\\alpha\\).\nЗвичайно ж, у довірчому інтервалі лежить значення \\(\\mu = \\frac{19}{30}\\), для якого \\(19\\) успіхів — це найбільш правдоподібний результат. При цьому інтервал несиметричний щодо точки \\(\\frac{19}{30}\\).\nПодивимося, як можна візуально знайти межу інтервалу. Ми отримали \\(19\\) успіхів. Для кожного \\(\\mu_0\\) статистика \\(Q\\) має розподіл \\(Binom(30, \\mu_0)\\). Будемо малювати цей розподіл і дивитися, чи потрапляє \\(19\\) у критичну область.\n\n\n\n\nЛістинг 2.6: Довірчі інтервали для біноміального розподілу\n\n\nmus_h0 = [0.2, 0.438, 0.439, 0.8, 0.81, 0.9]\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\nfor mu_h0, ax in zip(mus_h0, axes.flatten()):\n    binom_h0 = binom(n=30, p=mu_h0)\n    probs = binom_h0.pmf(x_grid)\n\n    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    crit_reg = (x_grid &lt;= c1) | (x_grid &gt;= c2)\n    ax.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\n\n    is_rejection = success_cnt &lt;= c1 or success_cnt &gt;= c2\n    ax.axvline(success_cnt, ls='--', label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не видхилено'), color='gray', alpha=0.4)\n\n    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Довірчі інтервали для біноміального розподілу\n\n\n\n\n\nВидно, що зі зростанням \\(\\mu_0\\) гістограма зсувається вправо. І спочатку \\(19\\) потрапляє в праву критичну область. Потім, починаючи з точки \\(0.439\\), значення \\(19\\) вже опиняється поза критичною областю, і тільки з \\(\\mu_0 = 0.81\\) починає потрапляти в ліву критичну область.\nТаким чином, ліва межа довірчого інтервалу — це перша точка, коли значення статистики перестало потрапляти до критичної області, а права межа - остання точка, коли значення не потрапляє до правої критичної області.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#односторонні-довірчі-інтервали",
    "href": "power.html#односторонні-довірчі-інтервали",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.5 Односторонні довірчі інтервали",
    "text": "2.5 Односторонні довірчі інтервали\nНасправді, двосторонній критерій потрібен вкрай рідко. Контролювати хибно похитивну помилку нам потрібно тільки для відхилень у бік, корисний для бізнесу. У випадку завдання з освітнім сервісом це отримання більшої конверсії в успіх.\nСпробуємо скористатися одностороннім критерієм для побудови довірчого інтервалу.\n\n\n\n\nЛістинг 2.7: Односторонні довірчі інтервали для біноміального розподілу\n\n\ndef make_binom_criterion(n, mu=0.5, alpha=0.05):\n    binom_h0 = binom(n=n, p=mu)\n    q = binom_h0.ppf(1 - alpha)\n    return q + 1\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1.001, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n\n\n95% довірчий інтервал: [0.467 - 1.0]\n\n\nКоли ми використовували двосторонній інтервал, ми отримали ліву межу \\(0.439 &lt; 0.467\\). Виходить, що односторонній інтервал з точки зору лівої межі дає нам більше інформації. При цьому з точки зору правої межі ми втрачаємо інформацію зовсім. Вона дорівнює 1 просто тому, що ймовірність не може бути більшою.\nНасправді зазвичай на праву межу не дивляться під час аналізу, коли ми шукаємо позитивний ефект.\nПрипустимо, ми отримали не \\(19\\) успіхів, а \\(22\\). Побудуємо 2 види інтервалів.\n\n\n\n\nЛістинг 2.8: Двосторонній довірчий інтервал для \\(22\\) успіхів\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Двосторонній 95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\nДвосторонній 95% довірчий інтервал: [0.542 - 0.877]\n\n\n\n\n\n\nЛістинг 2.9: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1.001, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Односторонній 95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\nОдносторонній 95% довірчий інтервал: [0.571 - 1.000]\n\n\nЗа обома довірчими інтервалами ми робимо висновок, що конверсія значимо відрізняється від \\(50\\%\\). Але односторонній інтервал дає кращу нижню оцінку на ймовірність успіху. Ми можемо зрозуміти, що наша конверсія більша за \\(57\\%\\). А інформація з двостороннього інтервалу про те, що ймовірність менша за \\(88\\%\\) не додає нам користі.\nНавіщо ж ми тоді взагалі використовуємо двосторонній інтервал? Щоб це зрозуміти, подивимося, як виглядають візуально межі для одностороннього інтервалу.\n\n\n\n\nЛістинг 2.10: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 10))\n\nfor mu_h0, ax in zip(mus_h0, axes.flatten()):\n    binom_h0 = binom(n=30, p=mu_h0)\n    probs = binom_h0.pmf(x_grid)\n\n    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n    c = make_binom_criterion(30, mu_h0, alpha=0.05)\n    crit_reg = (x_grid &gt;= c)\n    ax.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\n\n    is_rejection = success_cnt &gt;= c\n    ax.axvline(success_cnt, ls='--', label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не відхилено'), color='gray', alpha=0.4)\n\n    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\n\n\n\nПорівняно з Рисунок 2.5 ми бачимо, що права критична область стала більшою через те, що там тепер знаходиться не \\(2.5\\%\\), а \\(5\\%\\) від усіх значень. При цьому лівої критичної області просто не існує, тому за великих \\(\\mu\\) не відбувається потрапляння \\(19\\) до неї, а значить ми не відкидаємо гіпотезу.\nЗауважимо, що якби ми будували двосторонній інтервал, але з удвічі більшою \\(\\alpha\\), потрапляння в праву критичну область траплялися б за тих самих \\(\\mu\\), що й в односторонньому критерії. Тому часто для пошуку односторонньої межі будують двосторонній довірчий інтервал із більшою \\(\\alpha\\), ігноруючи при цьому праву межу. Це зручно, оскільки можна користуватися тільки однією функцією для критерію.\nПеревіримо, що вийде за \\(\\alpha = 0.1\\).\n\n\n\n\nЛістинг 2.11: Двосторонній довірчий інтервал для \\(22\\) успіхів з \\(\\alpha = 0.1\\)\n\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.1)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n\n\n\n95% довірчий інтервал: [0.467 - 0.778]\n\n\nБачимо, що отримали таку саму ліву межу, як і в односторонньому інтервалі.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#властивості-довірчих-інтервалів",
    "href": "power.html#властивості-довірчих-інтервалів",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.6 Властивості довірчих інтервалів",
    "text": "2.6 Властивості довірчих інтервалів\nЗгадаймо визначення довірчого інтервалу.\nНехай є критерій \\(S = \\{Q(\\xi) \\leqslant C\\}\\) рівня значущості \\(\\alpha\\) для перевірки гіпотези \\({H}_0: \\mu = \\mu_0\\), \\(Q\\) — статистика критерію, а \\(q\\) — її реалізація на конкретній вибірці \\(\\xi = \\xi_1, \\dots, \\xi_n\\). Тоді довірчим інтервалом називається множина таких \\(\\mu_0\\), на яких критерій \\(S\\) не відкидає гіпотезу \\({H}_0: \\mu = \\mu_0\\).\nПроцедура підрахунку інтервалу — це довгий перебір значень із деяким кроком. Але це все ще залишається деякою функцією від вибірки, тобто статистикою й випадковою величиною, причому її розподіл залежить від статистики \\(Q\\), а отже, і від початкової вибірки, та від параметра \\(\\mu\\) у генеральній сукупності.\nПозначимо межі інтервалу за \\(\\mathcal{L}(Q), \\mathcal{R}(Q)\\) — статистики критерію, які відповідають лівій та правій межі інтервалу.\n\n2.6.1 Ймовірність попадання в інтервал\nЯким би не було істинне значення \\(\\mu = \\mu_0\\), ймовірність того, що воно перебуває між \\(\\mathcal{L}(Q)\\) та \\(\\mathcal{R}(Q)\\), не нижча, ніж \\(1 - \\alpha\\). Значення \\(1 - \\alpha\\) називається рівнем довіри довірчого інтервалу.\n\\[\nP(\\mathcal{L}(Q) &lt; \\mu_0 &lt; \\mathcal{R}(Q)) \\geqslant 1 - \\alpha\n\\tag{2.2}\\]\nВажливо, що випадковість тут прихована саме в \\(\\mathcal{L}\\) і \\(\\mathcal{R}\\), а не в \\(\\mu_0\\). Параметр \\(\\mu_0\\) невідомий, але ми припускаємо його константним і не випадковим.\nПеревіримо справедливість цієї властивості. Для цього зафіксуємо \\(\\mu_0\\) й проведемо множину експериментів:\n\nГенеруємо вибірку з розподілу з параметром \\(\\mu_0\\).\nОбчислюємо статистику \\(q\\).\nРахуємо довірчий інтервал для \\(\\alpha = 0.05\\).\n\nПеревіряємо, що частка випадків, коли параметр \\(\\mu_0\\) опинився всередині інтервалу, хоча б \\(95\\%\\)\n\n\n\nЛістинг 2.12: Перевірка властивості довірчого інтервалу.\n\n\n\nimport time\n\nstart_time = time.time()\n\ndef my_binomial_confint(n, alpha, q):\n    mu_grid = np.arange(0, 1.1, 0.1) # np.arange(0, 1.001, 0.001)\n    mu_no_rejection = []\n\n    for mu_h0 in mu_grid:\n        c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n        if q &gt; c1 and q &lt; c2:\n            mu_no_rejection.append(mu_h0)\n\n    return min(mu_no_rejection), max(mu_no_rejection)\n\nN_EXPERIMENTS = 1000\nSAMPLE_SIZE = 30\nlatent_mu = 0.5\nbinom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\nconfint_fail_cases = 0\n\nfor i in range(N_EXPERIMENTS):\n    q = binom_true.rvs()\n    L, R = my_binomial_confint(n=SAMPLE_SIZE, alpha=0.05, q=q)\n    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\nsuccess_cases = round(100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS, 2)\n\nprint(f\"Відсоток успішних випадків: {success_cases}%\")\n\nend_time = time.time()\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\nВідсоток успішних випадків: 61.4%\nЧас виконання: 3.6300 секунди\n\n\n\n\n\nЗазначимо, що цей код працював понад 5 хвилин. Це через те, що під час кожного експерименту потрібно побудувати довірчий інтервал, а значить перевірити 1000 можливих параметрів \\(\\mu_0\\).\nБачимо, що властивість виконалася. Ми очікували хоча б \\(95\\%\\) влучень, отримали навіть \\(61.4\\%\\). Насправді це значно більше, ніж ми очікували. Це відбувається через дискретність розподілу. З тієї ж причини під час пошуку критичної області ми не могли вибрати стовпці із сумарною висотою рівно \\(\\alpha\\).\n\n2.6.1.1 Доведення\nПід час формулювання властивості ми припускаємо, що є деяка \\(\\mu_0\\) — ймовірність успіху в генеральній сукупності. Коли ми проводимо штучний експеримент, ми фіксуємо її й можемо вважати істинною \\(\\mu\\).\nЩоразу ми генеруємо \\(Q \\sim Binom(\\mu_0, 30)\\) й перевіряємо, чи потрапила \\(\\mu_0\\) у довірчий інтервал. Намалюємо розподіл статистики \\(Q\\), який уже нам знайомий. Намалюємо й область ймовірності \\(\\leqslant \\alpha\\), як ми робили це раніше.\n\n\n\n\nЛістинг 2.13: Розподіл статистики при істинній ймовірності успіху\n\n\nmu0 = 0.5\nbinom_mu0 = binom(n=30, p=mu0)\nprobs = binom_mu0.pmf(x_grid)\n\nplt.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu0}, 30)$')\nc1, c2 = two_sided_criterion_nonsym(30, mu0, alpha=0.05)\ncrit_reg = (x_grid &gt;= c2) | (x_grid &lt;= c1)\nplt.bar(x_grid[crit_reg], probs[crit_reg], color=red_pink, label='Критична область')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Розподіл статистики при істинній ймовірності успіху\n\n\n\n\n\nНехай реалізувалося значення статистики \\(q\\). За такою вибіркою можна побудувати довірчий інтервал на \\(\\mu\\). Він буде якось розташований, але зараз нас цікавить, чи потрапить у нього \\(\\mu_0\\). За визначенням потрапляння в інтервал відбудеться, якщо не відкидається гіпотеза \\({H}_0:\\ \\mu = \\mu_0\\). Але тоді за справедливості \\({H}_0\\) статистика має той розподіл, що і на малюнку. І гіпотеза відкидається тільки в разі потрапляння в критичну область, а це трапляється з ймовірністю \\(\\leqslant \\alpha\\).\nОтже, з ймовірністю хоча б \\(1 - \\alpha\\) \\(\\mu_0\\) перебуватиме в довірчому інтервалі.\nЧасто так й вводять визначення довірчого інтервалу. Для вибірки \\(\\xi_1, \\dots, \\xi_n\\) — це така пара статистик \\(\\mathcal{L}(\\xi)\\) і \\(\\mathcal{R}(\\xi)\\), що хоч яким би не було \\(\\mu_0\\),\n\\[\nP(L(\\xi) &lt; \\mu_0 &lt; R(\\xi)) \\geqslant 1 - \\alpha\n\\tag{2.3}\\]\nде \\(L(\\xi)\\) і \\(R(\\xi)\\) — статистики, що залежать від вибірки. Знову звертаємо увагу, що випадковість тут прихована не в параметрі \\(\\mu_0\\), а в статистиках від вибірки.\n\n\n\n2.6.2 Довірчий інтервал Вілсона\nРозглянутий зараз алгоритм побудови довірчого інтервалу працює занадто довго. У Python є функції, які дозволяють швидше розрахувати інтервал. Наприклад, можна скористатися методом Вілсона і функцією proportion_confint.\nПовторимо експерименти з новим типом довірчого інтервалу, тут можемо дозволити більше реалізацій вибірки, оскільки інтервал рахується недовго.\n\n\n\n\nЛістинг 2.14: Довірчий інтервал Вілсона\n\n\nfrom statsmodels.stats.proportion import proportion_confint\n\nstart_time = time.time()\n\nN_EXPERIMENTS = 1000\nSAMPLE_SIZE = 30\nlatent_mu = 0.5\nbinom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\nconfint_fail_cases = 0\n\nfor i in range(N_EXPERIMENTS):\n    q = binom_true.rvs()  \n    L, R = proportion_confint(\n        count=q,\n        nobs=SAMPLE_SIZE,\n        alpha=0.05,\n        method='wilson'\n    )\n    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\nsuccess_cases = round(100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS, 2)\nprint(f\"Відсоток успішних випадків: {success_cases}%\")\nend_time = time.time()\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\n\n\n\nВідсоток успішних випадків: 96.6%\nЧас виконання: 0.0765 секунди\n\n\nЗауважимо, що наше \\(\\mu\\) може знаходитись в довірчому інтервалі менше, ніж у \\(95\\%\\) випадків. Це відбувається через те, що швидкі методи працюють наближено, оцінюючи розподіл статистики при збільшенні розміру вибірки. Чим розмір вибірки більший, тим ближчим буде інтервал до \\(95\\%\\)-ного.\nЗалежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки зобразимо на Рисунок 2.8.\n\n\n\n\nЛістинг 2.15: Залежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки\n\n\nn_grid = np.arange(1, 1000, 25).tolist()\ninterval_success_rate = []\n\nfor n in n_grid:\n    confint_fail_cases = 0\n    for i in range(N_EXPERIMENTS):\n        binom_true = binom(n=n, p=latent_mu)\n        q = binom_true.rvs()  \n        L, R = proportion_confint(\n            count=q,\n            nobs=n,\n            alpha=0.05,\n            method='wilson'\n        )\n        if L &lt; latent_mu &lt; R:\n            pass\n        else:\n            confint_fail_cases += 1\n    interval_success_rate.append(1 - confint_fail_cases / N_EXPERIMENTS)\n\nplt.xlabel('Розмір вибірки $n$')\nplt.ylabel('Частка успішних влучень')\n\nplt.plot(n_grid, interval_success_rate, label='Частка успішних влучень', color=turquoise)\nplt.axhline(0.95, ls='--', label='Желаемая успешность', color=red_pink)\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Залежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки\n\n\n\n\n\nВидно, що на будь-якому розмірі вибірки під час використання інтервалу Вілсона можна отримати менше \\(95\\%\\) влучень, але що більший розмір вибірки, то менше графік відхиляється від \\(95\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "z-test.html",
    "href": "z-test.html",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "3.1 Нормальний розподіл\nУ цьому розділі ми розглянемо \\(Z\\)-критерій Фішера, який використовується для перевірки гіпотез про середнє значення генеральної сукупності з відомою дисперсією.\nДалі, для виведення критеріїв нам потрібен нормальний розподіл. Потому що саме цьому розподілу підпорядковується середнє вибірок. Тож давайте подивимося, що це взагалі таке, як з ним працювати в Python й які в нього є властивості.\nНормальний розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\) — неперервний розподіл, у якому щільність спадає зі збільшенням відстані від математичного сподівання \\(\\mu\\) за швидкістю, пропорційною квадрату відстані (див. формулу 3.1).\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2},\n\\tag{3.1}\\] де \\(x\\) — випадкова величина, \\(\\mu\\) — математичне сподівання, \\(\\sigma^2\\) — дисперсія.\nНа графіку нижче показано, як виглядає нормальний розподіл з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\nРисунок 3.1: Нормальний розподіл з різними параметрами",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution",
    "href": "z-test.html#sec-normal-distribution",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "Лістинг 3.1: Візуалізація нормального розподілу з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\n\n\n\nx = np.linspace(-5, 5, 1000)\nparams = [(0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (2, 2)]\n\nfor mu, sigma in params:\n    plt.plot(x, norm.pdf(x, mu, sigma), label=f'μ={mu}, σ={sigma}')\n\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.legend()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-python",
    "href": "z-test.html#sec-normal-distribution-python",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.2 Нормальний розподіл у Python",
    "text": "3.2 Нормальний розподіл у Python\nНехай ми хочемо задати розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Для цього є клас norm1.\nПараметри класу:\n\nloc — це \\(\\mu\\)\nscale — це \\(\\sigma\\), або стандартне відхилення. Не дисперсія!\n\nМетоди класу:\n\nrvs() — згенерувати випадкові числа з розподілу \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\ncdf(x) — кумулятивна функція розподілу (cumulative distribution function, CDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\).\nppf(q) — квантиль функції розподілу (percent-point function, PPF) для ймовірності \\(q\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(q\\).\npdf(x) — щільність ймовірності (probability density function, PDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) дорівнює \\(x\\).\n\nCDF та PPF — це функції, які пов’язані між собою. CDF визначає ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\), а PPF визначає значення \\(x\\), для якого ймовірність \\(X\\) менша або дорівнює \\(q\\).\nІніціалізуємо клас norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\) (стандартний нормальний розподіл). Далі, згенеруємо випадкову вибірку з 50 спостережень, а також обчислимо PDF, CDF та PPF для \\(x = 1.5\\).\n\n\n\nЛістинг 3.2: Нормальний розподіл у Python.\n\n\n\n1std_norm = norm(loc=0, scale=1)\n\n2rnorm = std_norm.rvs(size=50, random_state=42)\n\n3CDF = std_norm.cdf(1.5)\n4PDF = std_norm.pdf(1.5)\n5PPF = std_norm.ppf(0.933)\n\ndisplay(\n6    Markdown(f\"$P(X \\\\leq 1.5) = {CDF:.3f}$\"),\n7    Markdown(f\"$f(1.5) = {PDF:.3f}$\"),\n8    Markdown(f\"$z_{{0.933}} = \\Phi^{{-1}}(0.933) = {PPF:.3f}$\")\n)\n\n\n1\n\nІніціалізація класу norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\).\n\n2\n\nГенерація випадкової вибірки з 50 спостережень.\n\n3\n\nОбчислення PDF для \\(x = 1.5\\).\n\n4\n\nОбчислення CDF для \\(x = 1.5\\).\n\n5\n\nОбчислення PPF для \\(q = 0.933\\).\n\n6\n\nЙмовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(1.5\\).\n\n7\n\nЙмовірність того, що випадкова величина \\(X\\) дорівнює \\(1.5\\).\n\n8\n\nЗначення \\(x\\), для якого ймовірність \\(X\\) менша або дорівнює \\(0.933\\).\n\n\n\n\n\\(P(X \\leq 1.5) = 0.933\\)\n\n\n\\(f(1.5) = 0.130\\)\n\n\n\\(z_{0.933} = \\Phi^{-1}(0.933) = 1.499\\)\n\n\n\n\n\nВізуалізація методів класу norm показана на рисунку 3.2.\n\n\n\n\n\n\n\n\nРисунок 3.2: Демонстрація методів класу norm",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-properties",
    "href": "z-test.html#sec-normal-distribution-properties",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.3 Властивості нормального розподілу",
    "text": "3.3 Властивості нормального розподілу\nНормальний розподіл має кілька важливих властивостей2:\n\nСума двох незалежних нормально розподілених випадкових величин також має нормальний розподіл:\n\n\\[\n\\begin{aligned}\n\\xi_1 &\\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\\\\n\\xi_2 &\\sim \\mathcal{N}(\\mu_2, \\sigma_2^2) \\\\\n\\xi_1 + \\xi_2 &\\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\n\\end{aligned}\n\\tag{3.2}\\] де \\(\\xi_1\\) та \\(\\xi_2\\) — незалежні нормально розподілені випадкові величини з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\) та \\(\\mu_2\\), \\(\\sigma_2^2\\) відповідно.\n\nМноження нормально розподіленої випадкової величини на константу також дає нормально розподілену величину:\n\n\\[\na \\xi_1 \\sim \\mathcal{N}(a\\mu_1, a^2\\sigma_1^2)\n\\tag{3.3}\\] де \\(a\\) — константа, \\(\\xi_1\\) — нормально розподілена випадкова величина з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\).\n\n3.3.1 Перевірка властивостей в Python\nЗа допомогою мови Python ми можемо перевірити ці властивості. Почнемо з Рівняння 3.2. Для цього ми згенеруємо дві нормально розподілені випадкові величини \\(\\xi_1\\) та \\(\\xi_2\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та \\(\\mu_2 = 1\\), \\(\\sigma_2^2 = 4\\). Потім, ми обчислимо їхню суму та перевіримо, чи має вона нормальний розподіл з параметрами \\(\\mu_1 + \\mu_2\\) та \\(\\sigma_1^2 + \\sigma_2^2\\).\n\n\n\nЛістинг 3.3: Візуалізація нормального розподілу суми двох нормально розподілених випадкових величин.\n\n\n\n1mean_one, mean_two = 3, -1\n2var_one, var_two = 4, 2\n\n3n = 10000\n\n4x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\nx2 = norm.rvs(loc=mean_two, scale=np.sqrt(var_two), size=n)\n\n5x_sum = x1 + x2\n6check_sum = norm(loc=mean_one + mean_two, scale=np.sqrt(var_one + var_two))\n\n7x_grid = np.linspace(-8, 12, 1000)\n\nfig, ax = plt.subplots()\n8sns.histplot(x_sum, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_sum.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\mu_2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\) та \\(\\sigma_2^2\\).\n\n3\n\nКількість спостережень.\n\n4\n\nГенерація нормально розподілених випадкових величин \\(\\xi_1\\) та \\(\\xi_2\\).\n\n5\n\nСума двох нормально розподілених випадкових величин.\n\n6\n\nПараметри суми \\(\\xi_1 + \\xi_2\\).\n\n7\n\nСтандартне відхилення суми \\(\\xi_1 + \\xi_2\\).\n\n8\n\nЕмпіричний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n9\n\nТеоретичний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВидно, що розподіли приблизно збіглися! А значить ми переконалися, що формула правильна.\nДругу властивість Рівняння 3.3 можна перевірити аналогічно. Для цього ми згенеруємо нормально розподілену випадкову величину \\(\\xi_1\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та помножимо її на константу \\(a = 2\\). Потім, ми перевіримо, чи має вона нормальний розподіл з параметрами \\(a\\mu_1\\) та \\(a^2\\sigma_1^2\\).\n\n\n\nЛістинг 3.4: Візуалізація нормального розподілу множення нормально розподіленої випадкової величини на константу.\n\n\n\n1mean_one = 0\n2var_one = 1\n3a = 2\n4n = 10000\n5x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\n6x_mult = a * x1\n7check_mult = norm(loc=a * mean_one, scale=np.sqrt(a**2 * var_one))\n8x_grid = np.linspace(-8, 8, 1000)\n\nfig, ax = plt.subplots()\nsns.histplot(x_mult, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_mult.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\sigma_1^2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\).\n\n3\n\nКонстанта \\(a\\).\n\n4\n\nКількість спостережень.\n\n5\n\nГенерація нормально розподіленої випадкової величини \\(\\xi_1\\).\n\n6\n\nМноження нормально розподіленої випадкової величини \\(\\xi_1\\) на константу \\(a\\).\n\n7\n\nПараметри множення \\(\\xi_1\\) на константу \\(a\\).\n\n8\n\nСтандартне відхилення множення \\(\\xi_1\\) на константу \\(a\\).\n\n9\n\nЕмпіричний та теоретичний розподіл множення \\(\\xi_1\\) на константу \\(a\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЦього разу розподіли також збіглися. А значить ми переконалися, що формула правильна.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-central-limit-theorem",
    "href": "z-test.html#sec-central-limit-theorem",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.4 Центральна гранична теорема",
    "text": "3.4 Центральна гранична теорема\nДля початку пригадаємо теорему, яка є основоположною теоремою для всіх критеріїв, які ми розглянемо найближчим часом.\n\nТеорема 3.1 (Центральна гранична теорема, ЦГТ) Нехай \\(\\xi_1, ..., \\xi_n\\) — незалежно однаково розподілені випадкові величини, в яких існують математичне сподівання та дисперсія: \\(E [\\xi_i] = \\mu &lt; \\infty\\) і \\(Var[\\xi_i] = \\sigma^2 &lt; \\infty\\), тоді \\(\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}}\\) збігається за розподілом3 до \\(\\mathcal{N}(0, 1)\\).\n\nЦе означає, що якщо випадкові величини в експерименті незалежні й однаково розподілені й ваша вибірка досить велика, то можна вважати, що\n\\[\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1),\n\\tag{3.4}\\] де \\(\\overline \\xi\\) — середнє арифметичне вибірки, \\(n\\) — кількість спостережень, \\(\\mu\\) — математичне сподівання генеральної сукупності, \\(\\sigma^2\\) — дисперсія генеральної сукупності.\n\n\n\n\n\n\nПримітка\n\n\n\nВипадкові величини можуть бути слабко залежні одна від одної й злегка по-різному розподілені. Центральна гранична теорема все ще буде правильною, Gnedenko and Kolmogorov (2021).\n\n\n\n3.4.1 Візуалізація ЦГТ\nЩоб краще розуміти, як працює ЦГТ, я пропоную візуалізувати теорему: подивимося на розподіл середніх значень у різних вибірках. Як ми це зробимо?\n\nЩоб подивитися, що деяка випадкова величина з нормального розподілу, нам потрібна вибірка цих випадкових величин.\nУ цьому випадку нам потрібна вибірка статистик із ЦГТ. Тому нам потрібно згенерувати \\(N\\) вибірок по \\(M\\) елементів у кожній.\n\nПо кожній вибірці треба порахувати середнє за \\(M\\) елементами.\nУ підсумку ми отримаємо вибірку з \\(N\\) елементів.\nВона і має бути з нормального розподілу.\n\n\n\n\n\nЛістинг 3.5: Візуалізація ЦГТ при великій вибірці з біноміального розподілу.\n\n\n\ndef visualize_CLT(sample_generator, expected_value, variance):\n    np.random.seed(42)\n1    N = 5000\n2    clt_sample = []\n    for _ in range(N):\n3        sample = sample_generator()\n4        sample_size = len(sample)\n5        statistic = np.sqrt(sample_size) * (np.mean(sample) - expected_value) / np.sqrt(variance)\n6        clt_sample.append(statistic)\n\n7    x = np.linspace(-4, 4, 1000)\n    fig, ax = plt.subplots()\n    sns.histplot(clt_sample, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax)\n    ax.plot(x, norm().pdf(x), color=red_pink, label='$\\mathcal{N}(0, 1)$', alpha=0.8)\n    plt.legend()\n    plt.xlabel('X')\n    plt.ylabel('Щільність')\n    plt.show()\n\n\np = 0.01\nn = 20\nsize = 5000\n\n8visualize_CLT(lambda: np.random.binomial(n, p, size),\n9              expected_value = p * n,\n10              variance = n * p * (1 - p)\n)\n\n\n1\n\nКількість вибірок.\n\n2\n\nПустий масив для зберігання статистик.\n\n3\n\nГенерація вибірки з \\(M\\) елементами.\n\n4\n\nКількість елементів у вибірці.\n\n5\n\nОбчислення статистики.\n\n6\n\nДодавання статистики до масиву.\n\n7\n\nВізуалізація емпіричного розподілу та теоретичного розподілу.\n\n8\n\nГенерація вибірки з біноміального розподілу.\n\n9\n\nМатематичне сподівання біноміального розподілу.\n\n10\n\nДисперсія біноміального розподілу.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЕмпірична щільність достатньо близько збігається з теоретичним розподілом. А що якщо зменшити вибірку, за якою рахується середнє?\n\n\n\nЛістинг 3.6: Візуалізація ЦГТ при малій вибірці з біноміального розподілу.\n\n\n\np = 0.05\nn = 20\nsize = 10\n\nvisualize_CLT(lambda: np.random.binomial(n, p, size),\n              expected_value = p * n,\n              variance = n * p * (1 - p)\n)\n\n\n\n\n\n\n\n\n\n\n\nСтало значно гірше: з’явилися прогалини в розподілі, та й сама емпірична функція розподілу зміщена. Тож наш експеримент підтвердив важливість розміру вибірки для коректної роботи ЦГТ.\nТепер подивимось на експоненціальний розподіл.\n\n\n\nЛістинг 3.7: Візуалізація ЦГТ при великій вибірці з експоненціального розподілу.\n\n\n\n1p = 5\n2size = 400\n3visualize_CLT(lambda: np.random.exponential(scale=1/p, size=size),\n4              expected_value = 1/p,\n5              variance = 1/(p**2)\n)\n\n\n1\n\nПараметр \\(\\lambda\\) експоненціального розподілу.\n\n2\n\nРозмір вибірки.\n\n3\n\nГенерація вибірки з експоненціального розподілу.\n\n4\n\nМатематичне сподівання експоненціального розподілу задається як \\(1/\\lambda\\).\n\n5\n\nДисперсія експоненціального розподілу задається як \\(1/\\lambda^2\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nБачимо, що і тут усе добре працює!\n\n\n3.4.2 Інші формулювання ЦГТ\nНаступні формулювання є еквівалентними, тому що ми можемо перетворити одне в інше за допомогою простих алгебраїчних перетворень. Вони можуть бути корисними в різних ситуаціях, залежно від того, що ми хочемо перевірити.\n\\[\n\\begin{aligned}\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} &\\sim \\mathcal{N}(0, 1) {\\Leftrightarrow}\\\\\n\\overline \\xi - \\mu &\\sim \\mathcal{N}\\left(0, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\dfrac{\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i}{n} &\\sim \\mathcal{N}\\left(\\mu, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i &\\sim \\mathcal{N}\\left(n \\cdot \\mu, n \\cdot \\sigma^2 \\right)\n\\end{aligned}\n\\tag{3.5}\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#нормальна-апроксимація-й-застосування-z-критерію",
    "href": "z-test.html#нормальна-апроксимація-й-застосування-z-критерію",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.5 Нормальна апроксимація й застосування \\(Z\\)-критерію",
    "text": "3.5 Нормальна апроксимація й застосування \\(Z\\)-критерію\n\n3.5.1 Апроксимація нормальним розподілом\nЗгадайте задачу на самому початку розділу 1.1. У нас є вибірка користувачів \\(X_1,\\ X_2,\\ ...,\\ X_n,\\ X_i \\sim \\text{Bernoulli}(\\mu)\\) з параметром \\(\\mu\\), й ми хочемо перевірити гіпотезу:\n\\[\nH_0: \\mu =\\mu_0 = 0.5\\ \\text{проти} \\ H_1: \\mu &gt; 0.5\n\\] де \\(\\mu_0\\) — гіпотетичне значення параметра \\(\\mu\\).\nРаніше, ми вирішували цю задачу через біноміальний розподіл:\n\n\\(T(X^n) = \\underset{i=1}{\\overset{n}{\\sum}} X_i,\\ T \\overset{H_0}{\\sim} \\text{Binom} (n, \\mu_0)\\)\nНехай реалізація \\(T(X^n) = t\\). Тоді\n\\(p\\text{-значення} = P_{H_0}(T(X^n) \\geq t) = 1 - P_{H_0}(T(X^n) &lt; t)\\)\n\nЗгадаємо, як вирішити цю задачу за допомогою Python (1.19).\nА тепер подивимося, що нам говорить ЦГТ:\n\nЗа досить великого розміру вибірки \\(\\underset{i=1}{\\overset{n}{\\sum}} X_i \\sim \\mathcal{N}\\left(n \\cdot \\mu_0, n \\cdot \\sigma^2 \\right)\\),\n\\(X_i \\overset{H_0}{\\sim} \\text{Bernoulli} (\\mu_0)\\)\n\\(\\sigma^2 = \\mu_0 \\cdot (1 - \\mu_0)\\)\n\\(p\\text{-value} = P_{H_0}(T(X^n) \\geq t)\\).\n\nПри цьому цього разу ми дивимося статистику не в точці \\(t-1\\), як робили раніше, а в точці \\(t\\), оскільки у нас неперервний розподіл, то нам не потрібно віднімати 1:\n\nу разі нормального розподілу: \\(P(T(X^n) \\geq t) = P(T(X^n) &gt; t) = 1 - P(T(X^n) \\leq t)\\);\nу разі біноміального розподілу: \\(P(T(X^n) \\geq t) = 1 - P(T(X^n) \\leq t - 1)\\).\n\nПодивимось, як це виглядає в Python. Для цього створимо функцію get_pvalue_by_normal_approx, яка буде приймати на вхід параметри \\(n\\), \\(\\mu_0\\), \\(t\\) та повертати \\(p\\)-значення. Порівняємо результати за точним біноміальним тестом та нашим наближенням.\n\n\n\nЛістинг 3.8: Порівняння точного біноміального тесту та нормальної апроксимації при малій кількості спостережень.\n\n\n\ndef get_pvalue_by_normal_approx(t, n, mu_0):\n1    mu = n * mu_0\n2    sigma = np.sqrt(n * mu_0 * (1 - mu_0))\n3    return 1 - norm(loc=mu, scale=sigma).cdf(t)\n\n4n = 30\n5mu_0 = 0.5\n6t = 19\n\n7p_value = get_pvalue_by_normal_approx(t, n, mu_0)\n\n8print(f\"p-значення за нормальною апроксимацією = {p_value:.4f}\")\n9print(f\"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}\")\n\n\n1\n\nМатематичне сподівання біноміального розподілу.\n\n2\n\nСтандартне відхилення.\n\n3\n\nОбчислення \\(p\\)-значення.\n\n4\n\nКількість спостережень.\n\n5\n\nГіпотетичне значення параметра \\(\\mu\\).\n\n6\n\nРеалізація статистики.\n\n7\n\nОбчислення \\(p\\)-значення.\n\n8\n\nВиведення \\(p\\)-значення.\n\n9\n\nВиведення точного \\(p\\)-значення.\n\n\n\n\np-значення за нормальною апроксимацією = 0.0721\np-значення за точним біноміальним тестом = 0.1002\n\n\n\n\n\nМи бачимо, що значення не дуже-то й збіглися. Але, як ми пам’ятаємо, нормальна апроксимація працює тільки з деякого великого \\(n\\). Тому давайте спробуємо повторити експеримент із більшаимо кількість спостережень.\n\n\n\nЛістинг 3.9: Порівняння точного біноміального тесту та нормальної апроксимації при великій кількості спостережень.\n\n\n\nn = 3000\nmu_0 = 0.5\nt = 1544\n\np_value = get_pvalue_by_normal_approx(t, n, mu_0)\n\nprint(f\"p-значення за нормальною апроксимацією = {p_value:.4f}\")\nprint(f\"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}\")\n\np-значення за нормальною апроксимацією = 0.0541\np-значення за точним біноміальним тестом = 0.0561\n\n\n\n\n\nМи бачимо, що відмінність тепер тільки в 3 знаку після коми, а не в другому, як раніше. Що більше ми братимемо вибірку, то меншою буде помилка про що говорить ЦГТ.\n\n\n3.5.2 \\(Z\\)-критерій Фішера\n\\(Z\\)-критерій Фішера використовується для перевірки гіпотез про математичне сподівання випадкової величини з відомою дисперсією. Він є одним із найпоширеніших критеріїв у статистиці, оскільки дозволяє оцінити, чи є різниця між середніми значеннями двох груп статистично значущою.\nДля двостороннього критерію ми можемо використовувати \\(Z\\)-критерій Фішера, але з урахуванням того, що ми перевіряємо гіпотезу про те, що \\(\\mu\\) не дорівнює \\(\\mu_0\\). Тобто, ми хочемо перевірити, чи є різниця між середніми значеннями двох груп статистично значущою в обидва боки.\nНульова та альтернативна гіпотези для двостороннього \\(Z\\)-критерію Фішера мають вигляд:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{проти} \\quad H_1: \\mu \\neq \\mu_0\n\\tag{3.6}\\] де \\(\\mu_0\\) — гіпотетичне значення параметра \\(\\mu\\).\nСтатистика \\(Z\\)-критерію Фішера має вигляд:\n\\[\nZ = \\dfrac{\\overline X - \\mu_0}{\\sigma / \\sqrt{n}}\n\\tag{3.7}\\] де \\(\\overline X\\) — середнє арифметичне вибірки, \\(\\sigma\\) — відома дисперсія генеральної сукупності, \\(n\\) — кількість спостережень.\nПри достатньо великій вибірці згідно ЦГТ \\(Z\\)-критерій Фішера має нормальний розподіл:\n\\[\nZ(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\n\\tag{3.8}\\]\nДвосторонній критерій набуває вигляду:\n\\[\nP_{H_0}(Z(X) \\geq z) = 1 - P_{H_0}(Z(X) &lt; z) = 1 - \\Phi(z) = \\dfrac{\\alpha}{2}\n\\tag{3.9}\\] де \\(\\alpha\\) — рівень значущості.\nА \\(p\\)-значення для двостороннього критерію розраховується за формулою:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right]\n\\tag{3.10}\\]\nОдносторонній критерій перевіряє гіпотезу про те, що \\(\\mu\\) більше або менше \\(\\mu_0\\). Нульова та альтернативна гіпотези для одностороннього \\(Z\\)-критерію Фішера мають вигляд:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{проти} \\quad H_1: \\mu &gt; \\mu_0\n\\tag{3.11}\\]\nТоді односторонній \\(Z\\)-критерій Фішера має вигляд:\n\\[\nP_{H_0}(Z(X) \\geq z) = 1 - P_{H_0}(Z(X) &lt; z) = 1 - \\Phi(z) = \\alpha\n\\tag{3.12}\\] де \\(\\Phi(z)\\) — функція розподілу стандартного нормального розподілу, \\(\\alpha\\) — рівень значущості, \\(z\\) — реалізація статистики \\(Z\\)-критерію Фішера.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#z-критерій-фішера-в-python",
    "href": "z-test.html#z-критерій-фішера-в-python",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.6 \\(Z\\)-критерій Фішера в Python",
    "text": "3.6 \\(Z\\)-критерій Фішера в Python\nНапишемо функцію z_test_pvalue, яка буде приймати на вхід параметри sample_mean (середнє арифметичне вибірки), sample_size (кількість спостережень), population_mean (гіпотетичне значення параметра \\(\\mu\\)), population_variance (дисперсія генеральної сукупності) та alternative (альтернативна гіпотеза). Функція буде повертати \\(p\\)-значення для двостороннього або одностороннього \\(Z\\)-критерію Фішера.\n\n\n\nЛістинг 3.10: Реалізація \\(Z\\)-критерію Фішера в Python.\n\n\n\ndef z_test_pvalue(sample_mean, sample_size, population_mean, population_variance, alternative='two-sided'):\n1    z = (sample_mean - population_mean) / (np.sqrt(population_variance) / np.sqrt(sample_size))\n2    if alternative == 'two-sided':\n3        p_value = 2 * min(norm.cdf(z), 1 - norm.cdf(z))\n4    elif alternative == 'greater':\n5        p_value = 1 - norm.cdf(z)\n6    elif alternative == 'less':\n7        p_value = norm.cdf(z)\n    else:\n8        raise ValueError(\"Оберіть одну з альтернатив: ['two-sided', 'greater', 'less']\")\n9    return p_value\n\n\n1\n\nОбчислення статистики \\(Z\\)-критерію Фішера.\n\n2\n\nПеревірка двосторонньої гіпотези.\n\n3\n\nОбчислення \\(p\\)-значення для двостороннього \\(Z\\)-критерію Фішера.\n\n4\n\nПеревірка правосторонньої гіпотези.\n\n5\n\nОбчислення \\(p\\)-значення для правостороннього \\(Z\\)-критерію Фішера.\n\n6\n\nПеревірка лівосторонньої гіпотези.\n\n7\n\nОбчислення \\(p\\)-значення для лівостороннього \\(Z\\)-критерію Фішера.\n\n8\n\nВиклик помилки, якщо альтернативна гіпотеза не відповідає жодній з можливих.\n\n9\n\nПовернення \\(p\\)-значення.\n\n\n\n\n\n\n\nТепер ми можемо перевірити гіпотезу про те, що \\(\\mu\\) не дорівнює \\(\\mu_0\\), за допомогою \\(Z\\)-критерію Фішера. Для цього ми можемо використати функцію z_test_pvalue та порівняємо з результатами, які ми отримали раніше за допомогою біноміального тесту та нормальної апроксимації.\n\n\n\nЛістинг 3.11: Порівняння \\(p\\)-значення за \\(Z\\)-критерієм Фішера, нормальною апроксимацією та точним біноміальним тестом.\n\n\n\nn = 30\nmu_0 = 0.5\nt = 19\n1sample_mean = t / n\n2population_variance = mu_0 * (1 - mu_0)\n\np_value = z_test_pvalue(sample_mean, n, mu_0, population_variance, alternative='greater')\nprint(f\"p-значення за Z-критерієм Фішера = {p_value:.4f}\")\nprint(f\"p-значення за нормальною апроксимацією = {get_pvalue_by_normal_approx(t, n, mu_0):.4f}\")\nprint(f\"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}\")\n\n\n1\n\nОбчислення математичного сподівання вибірки.\n\n2\n\nДисперсія генеральної сукупності.\n\n\n\n\np-значення за Z-критерієм Фішера = 0.0721\np-значення за нормальною апроксимацією = 0.0721\np-значення за точним біноміальним тестом = 0.1002\n\n\n\n\n\nМи бачимо, що \\(p\\)-значення за \\(Z\\)-критерієм Фішера та нормальною апроксимацією збігаються, а точний біноміальний тест дає трохи інше значення. Залишається питання: чи можна уточнити результати \\(Z\\)-тесту при малих вибірках? Відповідь: так, можна. Для цього існує поправка на неперервність, яка дозволяє покращити точність апроксимації і її ми розглянемо далі.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-continuity-correction",
    "href": "z-test.html#sec-continuity-correction",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.7 Поправка на неперервність",
    "text": "3.7 Поправка на неперервність\nЗадля кращого розуміння, давайте спочатку візуалізуємо \\(p\\)-значення в залежності від величини успіхів експерименту \\(t\\) для біноміального тесту та \\(Z\\)-критерію Фішера. Для цього побудуємо три варіанти:\n\n\\(p\\)-значення за нормальною апроксимацією.\n\nРозрахунок в Python: 1 - norm.cdf(t).\n\n\\(p\\)-значення біноміального тесту за умови, що \\(t\\) — неціле число.\n\nРозглянемо на прикладі \\(t = 19.5\\), тоді \\(p\\)-значення буде дорівнювати \\[\\begin{aligned}P(T(X) \\geq t) &= P(T(X) \\geq 19.5) \\\\ &= 1 - P(T(X) &lt; 19.5) \\end{aligned}\\]\nРозрахунок в Python: 1 - binom.cdf(t, n, mu_0).\n\n\\(p\\)-значення біноміального тесту за умови, що \\(t\\) — ціле число.\n\nРозглянемо на прикладі \\(t = 19\\), тоді \\(p\\)-значення буде дорівнювати \\[\\begin{aligned}P(T(X) \\geq t) &= P(T(X) \\geq 19) \\\\ &= 1 - P(T(X) \\leq 18)\\end{aligned}\\]\nРозрахунок в Python: 1 - binom.cdf(t - 1, n, mu_0).\n\n\n\n\n\nЛістинг 3.12: Порівняння \\(p\\)-значення біноміального і нормального розподілів.\n\n\n\ndef cmp_pvalue_binom_and_norm(n, mu0, t, add_to_x=0):\n    x_axis = np.linspace(0, n, 1000)\n    dots_to_show = np.arange(0, n + 1, 1)\n\n1    add_str = \"\" if add_to_x == 0 else f\"{add_to_x}\"\n\n2    sum_mu = n * mu0\n    sum_variance = n * mu0 * (1 - mu0)\n    sum_std = np.sqrt(sum_variance) # 2&gt;\n\n3    binom_dist = binom(n=n, p=mu0)\n    norm_dist = norm(loc=sum_mu, scale=sum_std)\n\n    plt.hlines(1 - binom_dist.cdf(x_axis[:-1]), x_axis[:-1], x_axis[1:], color=turquoise, linestyle='-',linewidth=1)\n    plt.vlines(x_axis[:-1], 1 - binom_dist.cdf(x_axis[:-1]), 1 - binom_dist.cdf(x_axis[1:]), color=turquoise, linestyle=':', linewidth=1)\n    \n4    plt.scatter(dots_to_show, 1 - binom_dist.cdf(dots_to_show-1), color=turquoise,\n                alpha=1, linewidths=0.5, s=25,\n                label=f'Binom pvalue = 1-binom.cdf(x-1)')\n\n5    plt.scatter(t, 1 - norm_dist.cdf(t + add_to_x), color=red_pink,\n                alpha=1, marker='o', s=50, label=f'norm p-value({t})')\n\n6    plt.scatter(t, 1 - binom_dist.cdf(t - 1), color=turquoise, marker='o',\n                alpha=1, s=50, label=f'binom p-value({t})')\n\n7    plt.plot(x_axis, 1 - norm_dist.cdf(x_axis + add_to_x), color=red_pink, alpha=0.5,\n             label=f'Normal pvalue = 1-norm.cdf(x{add_str})')\n\n    \n\n    plt.legend()\n    plt.xlabel('t')\n    plt.ylabel('$p$-значення')\n    plt.show()\n\nn = 30\nmu_0 = 0.5\nt = 15\n\ncmp_pvalue_binom_and_norm(n, mu_0, t)\n\n\n1\n\nДодатковий доданок до \\(x\\)-координати (про нього ми поговоримо пізніше).\n\n2\n\nПараметри нормального розподілу.\n\n3\n\nСтворення біноміального та нормального розподілів.\n\n4\n\n\\(p\\)-значення біноміального розподілу.\n\n5\n\n\\(p\\)-значення нормального розподілу.\n\n6\n\n\\(p\\)-значення біноміального розподілу у точці \\(t\\).\n\n7\n\n\\(p\\)-значення нормального розподілу у точці \\(t\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЯкщо порівняти різницю між \\(p\\)-значеннями біноміального та нормального розподілів, то ми отримаємо, що \\(p\\)-значення біноміального розподілу завжди більше за \\(p\\)-значення нормального розподілу. При цьому із збільшенням вибірки ця різниця зменшується. Давайте подивимось на ці різниці для різних значень \\(t\\).\nДля початку візьмемо \\(n = 20\\) та \\(t = 10\\) (Лістинг 3.13).\n\n\n\nЛістинг 3.13: Порівняння \\(p\\)-значення біноміального та нормального розподілів при малому \\(n=20\\) та \\(t=10\\).\n\n\n\nn = 20\nt = 10\nmu_0 = 0.5\n\n1binom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\n2norm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\n3diff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\n\n1\n\n\\(p\\)-значення біноміального розподілу.\n\n2\n\n\\(p\\)-значення нормального розподілу.\n\n3\n\nРізниця між \\(p\\)-значеннями.\n\n\n\n\np-значення біноміального розподілу = 0.5881\np-значення нормального розподілу = 0.5000\nРізниця між p-значеннями = 0.0881\n\n\n\n\n\nТепер візьмемо \\(n = 20\\) та \\(t = 16\\) (Лістинг 3.14).\n\n\n\nЛістинг 3.14: Порівняння \\(p\\)-значення біноміального та нормального розподілів при малому \\(n=20\\) та \\(t=16\\).\n\n\n\nn = 20\nt = 16\nmu_0 = 0.5\n\nbinom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\nnorm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\ndiff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\np-значення біноміального розподілу = 0.0059\np-значення нормального розподілу = 0.0036\nРізниця між p-значеннями = 0.0023\n\n\n\n\n\nІ накінці візьмемо \\(n = 200\\) та \\(t = 100\\) (Лістинг 3.15).\n\n\n\nЛістинг 3.15: Порівняння \\(p\\)-значення біноміального та нормального розподілів при великому \\(n=200\\) та \\(t=100\\).\n\n\n\nn = 200\nt = 100\nmu_0 = 0.5\n\nbinom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\nnorm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\ndiff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\np-значення біноміального розподілу = 0.5282\np-значення нормального розподілу = 0.5000\nРізниця між p-значеннями = 0.0282\n\n\n\n\n\nМи бачимо, що з ростом вибірки різниця між \\(p\\)-значеннями біноміального та нормального розподілів зменшується. Але як зробити так, щоб два \\(p\\)-значення збіглися? Для цього слід звернути увагу на точки перетину двох ліній: біноміального та нормального розподілів. Зауважимо, що вони перетинаються приблизно на середині відрізка: між \\(t-1\\) та \\(t\\). Тому спробуємо “змістити” графік нормального розподілу на \\(0.5\\) праворуч.\n\\[\nF_{\\text{new}}(x) = F_{\\text{old}}(x - 0.5)\n\\tag{3.13}\\]\nЦе означає, що ми повинні відняти \\(0.5\\) від \\(x\\)-координати точки перетину. Тобто, ми можемо використовувати поправку на неперервність, яка дозволяє покращити точність апроксимації. Тоді \\(p\\)-значення для біноміального розподілу буде дорівнювати:\n\\[\np\\text{-значення} = 1 - \\Phi(t - 0.5)\n\\tag{3.14}\\] де \\(\\Phi(t - 0.5)\\) — функція розподілу стандартного нормального розподілу.\nПодивимось на графік з поправкою на неперервність (Лістинг 3.16).\n\n\n\nЛістинг 3.16: Порівняння \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність.\n\n\n\ncmp_pvalue_binom_and_norm(30, 0.5, 15, add_to_x=-0.5)\n\n\n\n\n\n\n\n\n\n\n\nМи бачимо, що \\(p\\)-значення біноміального та нормального розподілів тепер збігаються.\nПорівняємо \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність (Лістинг 3.17).\n\n\n\nЛістинг 3.17: Порівняння \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність при \\(n=30\\) та \\(t=19\\).\n\n\n\nn = 30\nt = 19\nmu_0 = 0.5\n\n1binom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\n2norm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\n3norm_pvalue_correct = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t - 0.5)\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу з поправкою на неперервність = {norm_pvalue_correct:.4f}\")\n\n\n1\n\n\\(p\\)-значення біноміального розподілу.\n\n2\n\n\\(p\\)-значення нормального розподілу.\n\n3\n\n\\(p\\)-значення нормального розподілу з поправкою на неперервність.\n\n\n\n\np-значення біноміального розподілу = 0.1002\np-значення нормального розподілу = 0.0721\np-значення нормального розподілу з поправкою на неперервність = 0.1006\n\n\n\n\n\nМи бачимо, що \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність тепер збігаються.\nДодамо поправку на неперервність до нашої функції z_test_pvalue (Лістинг 3.18).\n\n\n\nЛістинг 3.18: Функція \\(Z\\)-критерію Фішера з поправкою на неперервність.\n\n\n\ndef z_test_pvalue(sample_mean, sample_size, population_mean, population_variance, alternative='two-sided', continuity_correction=False):\n1    if continuity_correction:\n        sample_mean = (sample_mean * sample_size - 1/2) / sample_size\n    z = (sample_mean - population_mean) / (np.sqrt(population_variance) / np.sqrt(sample_size))\n    if alternative == 'two-sided':\n        p_value = 2 * min(norm.cdf(z), 1 - norm.cdf(z))\n    elif alternative == 'greater':\n        p_value = 1 - norm.cdf(z)\n    elif alternative == 'less':\n        p_value = norm.cdf(z)\n    else:\n        raise ValueError(\"Оберіть одну з альтернатив: ['two-sided', 'greater', 'less']\")\n    return p_value\n\nn = 30\nt = 19\nmu0 = 0.5\nvariance = mu0 * (1 - mu0)\n\np_value = z_test_pvalue(t / n, n, mu0, variance, alternative='greater', continuity_correction=True)\nprint(f\"p-значення за Z-критерієм Фішера з поправкою на неперервність = {p_value:.4f}\")\n\n\n1\n\nПеревірка наявності поправки на неперервність.\n\n\n\n\np-значення за Z-критерієм Фішера з поправкою на неперервність = 0.1006\n\n\n\n\n\nЧудово, тепер ми можемо використовувати \\(Z\\)-критерій Фішера з поправкою на неперервність для перевірки гіпотез про математичне сподівання випадкової величини з відомою дисперсією. Але що робити, якщо дисперсія невідома? Для цього існує \\(t\\)-критерій Стьюдента, який ми розглянемо далі.\n\n\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#footnotes",
    "href": "z-test.html#footnotes",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "Документація доступна за посиланням https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html.↩︎\nДоведення цих властивостей можна знайти в роботі Lemons (2002).↩︎\nПослідовність випадкових величин \\(\\xi_n\\) збігається за розподілом до \\(\\xi\\), позначаємо \\(\\xi_n \\xrightarrow{d} \\xi\\), якщо \\(\\lim_{n \\to \\infty} F_{\\xi_n}(x) = F_{\\xi}(x)\\) для всіх \\(x\\), в яких \\(F_{\\xi}(x)\\) неперервна.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "t-test.html",
    "href": "t-test.html",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "4.1 Основні положення\nСпробуємо розв’язати таке завдання.\nДля початку переформулюємо умову мовою математики. Є вибірка:\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\nprint(f\"Середнє значення: {np.mean(meeting_time):.2f} хвилин\")\n\nСереднє значення: 58.57 хвилин\nНаша гіпотеза звучить так:\n\\[\nH_0: E \\overline{X} \\geq 70 \\; \\text{проти} \\; H_1: E \\overline{X} &lt; 70\n\\]\nЗдається, що ми таке вже вміємо вирішувати: згадаємо про \\(Z\\)-критерій:\n\\[\nH_0: \\mu \\leq \\mu_0\\ \\; \\text{проти} \\; \\ H_1: \\mu &gt; \\mu_0\n\\]\nТоді треба лише порахувати таку статистику: \\(\\sqrt{n}\\dfrac{\\overline X - 70}{\\sqrt{\\sigma^2}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\).\nАле є суттєва проблема: ми не знаємо \\(\\sigma^2\\)! Тому ми не можемо використовувати \\(Z\\)-критерій.\nДавайте спробуємо оцінити \\(\\sigma^2\\) за допомогою вибірки. Для цього скористаємося формулою:\n\\[\n\\hat{\\sigma}^2 = S^2 = \\dfrac{1}{n - 1} \\sum_{i=1}^n (X_i - \\overline X)^2\n\\tag{4.1}\\]\nВона називається вибірковою дисперсією. Вибіркова дисперсія є незміщеною та консистентною оцінкою дисперсії генеральної сукупності.\nВибіркова дисперсія є незміщеною, оскільки ми ділимо на \\(n - 1\\), а не на \\(n\\). Це робиться для того, щоб уникнути систематичної помилки в оцінці дисперсії. Консистентність пояснюється тим, що з ростом вибірки \\(n\\) ми все ближче підходимо до істинної дисперсії генеральної сукупності.\nДля розрахунку вибіркової дисперсії в Python можна скористатися функцією np.var з параметром ddof=1, що означає, що ми ділимо на \\(n - 1\\).\nmeeting_time_var = np.var(meeting_time, ddof=1)\nprint(f\"Вибіркова дисперсія: {meeting_time_var:.2f} хвилин\")\n\nВибіркова дисперсія: 222.62 хвилин\nДавайте введемо новий критерій \\(t'\\)-тест, у якому ми підставимо:\nЗалишилося перевірити: Чи правда, що при \\(H_0\\) розподіл \\(t\\)-статистики — стандартний нормальний?\nДля цього пропонується подивитися, як насправді буде розподілена статистика \\(t(X) = \\sqrt{n}\\dfrac{\\overline{X}-\\mu_0}{\\sqrt{S^2}}\\) у завданні, яке було поставлено від початку.\nДля цього будемо вважати, що вибірка \\(X\\) складається з 7 елементів й \\(X \\sim \\mathcal{N}\\).\nДля цього ми напишемо функцію sample_statistics, яка зможе побудувати розподіл для будь-якої статистики, а не тільки для \\(t(X), Z(X)\\). Вона приймає на вхід:\ndef sample_statistics(number_of_experiments, statistic_function, sample_size, sample_distr):\n    statistic_sample = []\n    for _ in range(number_of_experiments):\n        sample = sample_distr.rvs(sample_size)\n        statistic = statistic_function(sample)\n        statistic_sample.append(statistic)\n    return statistic_sample\nТепер перевіримо, чи дійсно \\(t(X)\\) розподілена нормально. Для цього скористаємося функцією sample_statistics та побудуємо гістограму для \\(t(X)\\). Генерувати вибірку будемо з нормального розподілу \\(\\mathcal{N}(5, 3^2)\\).\nsample_size = 7\nM = 100000\nsample_distr = norm(loc=5, scale=3)\n\nT_X = lambda sample: np.sqrt(sample_size) * (np.mean(sample) - sample_distr.mean()) / np.sqrt(np.var(sample, ddof=1))\nZ_X = lambda sample: np.sqrt(sample_size) * (np.mean(sample) - sample_distr.mean()) / sample_distr.std()\n\nsamples = {\n    \"T(X)\": sample_statistics(\n    number_of_experiments=M, statistic_function=T_X,\n    sample_size=sample_size, sample_distr=sample_distr),\n\n    \"Z(X)\": sample_statistics(\n    number_of_experiments=M, statistic_function=Z_X,\n    sample_size=sample_size, sample_distr=sample_distr)\n}\n\nfor i, name in enumerate([\"T(X)\", \"Z(X)\"]):\n    plt.subplot(1, 2, i + 1)\n    current_sample = samples[name]\n    l_bound, r_bound = np.quantile(current_sample, [0.001, 0.999])\n\n    x = np.linspace(l_bound, r_bound, 1000)\n    sns.distplot(current_sample, label='Емпіричний розподіл', color=turquoise)\n    plt.plot(x, norm(0, 1).pdf(x), label='$\\mathcal{N}(0, 1)$', color=red_pink)\n    plt.legend(loc='upper left')\n    plt.xlabel(f'{name}')\n    plt.xlim((l_bound, r_bound))\n    plt.ylabel('Щільність')\n    plt.grid(linewidth=0.2)\n\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.1: Симуляція розподілу \\(t(X)\\) та \\(Z(X)\\)\nМи бачимо, що:\nДля того щоб стало зрозуміло, чому так сталося, розглянемо \\(t(X)\\) у деталях. При створенні критерію є два кроки:\nАле чому \\(t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}}\\) не розподілена нормально, хоча \\(\\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{\\sigma^2}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\)$? Чому при заміні \\(\\sigma^2\\) на \\(S^2\\) усе зіпсувалося?\nСправа в тому, що \\(S^2\\) — це випадкова величина! Згадаймо, як ми виводили \\(Z\\)-критерій:\nАле ми нічого не знаємо про \\(\\dfrac{\\overline{X}}{\\sqrt{\\eta}}\\), де \\(\\overline{X} \\sim \\mathcal{N}, S^2 := \\eta \\sim P\\), де \\(P\\) невідомо. Ми не знаємо поки що жодних теорем, які б хоч якось доводили, що тут також залишиться нормальний розподіл.\nДавайте подивимося на розподіл \\(\\sqrt{S^2}\\) на все тому ж нормальному розподілі.\nS2 = lambda sample: np.std(sample, ddof=1)\nS2_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=S2,\n    sample_size=sample_size, sample_distr=sample_distr\n)\n\nsns.distplot(S2_sample, label='Емпіричний розподіл', color=turquoise)\nplt.legend()\nplt.xlabel('$\\sqrt{S^2}$')\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.2: Розподіл \\(\\sqrt{S^2}\\)\nРозподіл \\(\\sqrt{S^2}\\) несиметричний й незрозуміло як розподілений. Тому, коли ми якусь величину з нормального розподілу ділимо на несиметричний незрозумілий розподіл, ми й отримуємо, що наша статистика \\(t\\) не з нормального розподілу.\nТож давайте виведемо критерій, який допоможе розв’язати початкову задачу!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#основні-положення",
    "href": "t-test.html#основні-положення",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "Приклад 4.1  \n\nМенеджмент компанії розглядає новий підхід до планування щотижневих нарад, щоб зменшити втрати часу співробітників. Раніше середня тривалість таких нарад складала 70 хвилин. Ідея полягає в тому, щоб перейти до нової структури нарад, яка, за задумом, дозволить зменшити тривалість нарад до 60 хвилин.\n\n\nПротягом одного тижня провели 7 нарад у новому форматі й зафіксували їх тривалість. Якщо з’ясується, що нові наради тривають довше, ніж у середньому 70 хвилин, новий формат вважатимуть неефективним.\n\n\nВаше завдання — перевірити, чи новий формат нарад дійсно ефективніший.\n\n\nВийшла вибірка середньої тривалості нарад (в хвилинах): [50, 55, 70, 45, 40, 70, 80].\n\n\n\n\n\\(X_1, X_2, ..., X_7\\) — значення середньої тривалості нарад у новому форматі;\nБудемо вважати, що \\(X\\) з нормального розподілу, тобто \\(X \\sim N(\\mu, \\sigma^2)\\).\n\n\n\n\n\n\n\nСтатистика \\(Z(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}}\\)\nЗа досить великого розміру вибірки \\(Z(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\) (за ЦГТ)\nОдносторонній критерій: \\(\\left\\{Z(X) \\geq z_{1 - \\alpha} \\right\\}\\)\n\n\\(p\\)-значення = \\(1 - \\Phi(z)\\), де \\(z\\) — реалізація статистики \\(Z(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\)\n\nДвосторонній критерій: \\(\\left\\{Z(X) \\geq z_{1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{Z(X) \\leq -z_{1 - \\frac{\\alpha}{2}} \\right\\}\\)\n\n\\(p\\)-значення = \\(2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right]\\), де \\(z\\) — реалізація статистики \\(Z(X)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\\(t(X) := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\)\n\\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\)\n\n\n\n\n\nМи \\(M\\) раз згенеруємо вибірку \\(X\\) та порахуємо щоразу статистику \\(t(X)\\).\nУ підсумку ми отримаємо вибірку розміру \\(M\\) для \\(t(X)\\) й зможемо побудувати гістограму розподілу. Окремо побудуємо розподіл \\(\\mathcal{N}(0, 1)\\). Якщо емпіричний розподіл візуально збіжиться з теоретичним нормальним, значить, усе добре. А якщо ні, то так просто ми не можемо замінити \\(\\sigma^2\\) на \\(S^2\\).\n\nДодатково подивимося, що буде, якщо замінити \\(t(X)\\) на \\(Z(X)\\). Добре, що на штучному прикладі ми знаємо дисперсію.\n\n\n\n\nnumber_of_experiments — кількість експериментів, які ми хочемо провести;\nstatistic_function — функція, яка обчислює статистику;\nsample_size — розмір вибірки;\nsample_distr — розподіл, з якого ми генеруємо вибірку.\n\n\n\n\n\n\n\\(Z\\)-тест тут працює: \\(\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1)\\).\nАле ось для \\(t(X)\\) це не так! **Вони відрізняються! А значить \\(t'\\)-критерій не підходить для початкової задачі!\n\n\n\nПридумати статистику для критерію\n\nІз цим ми успішно впоралися, придумавши \\(t(X)\\).\n\nЗрозуміти розподіл статистики.\n\nІ ось це найскладніший крок, який не дозволяє використовувати будь-яку придуману статистику. Потрібно також розуміти її розподіл.\nІ з цим, як ми побачили, ми провалилися для \\(t(X)\\). Нормальний розподіл не підійшов.\n\n\n\n\n\nМи порахували, що \\(\\overline X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). З ЦГТ або, у випадку вище, з властивостей нормального розподілу.\nДалі, все також із властивостей цього розподілу випливає, що якщо ми віднімемо константу або поділимо на константу, то нормальний розподіл не перетвориться на інший: тому \\(\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-стьюдента",
    "href": "t-test.html#t-тест-стьюдента",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.2 \\(t\\)-тест Стьюдента",
    "text": "4.2 \\(t\\)-тест Стьюдента\nДля того щоб вивести \\(t\\)-тест, нам потрібно зрозуміти, як розподіляється статистика \\(t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\). Для того, щоб це дізнатися, нам знадобиться кілька фактів:\n\nНехай \\(X_1 \\ldots X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nНехай \\(\\xi_1 \\ldots \\xi_n \\sim \\mathcal{N}(0, 1)\\). Тоді \\(\\eta=\\xi_1^2 +\\ ... +\\xi_n^2 \\sim \\chi^2_n\\)1.\n\nТоді \\(\\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 \\sim \\chi^2_{n-1}\\) 2.\n\\(S^2_X = \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}(X_i - \\overline X)^2\\)\n\\(\\xi_i := \\dfrac{X_i - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1)\\). Тоді \\[\\begin{aligned}\nS^2_{\\xi} &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 =\n      \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i-\\mu}{\\sigma} - \\underset{i=1}{\\overset{n}{\\sum}}\\left[\\dfrac{X_i-\\mu}{n\\sigma}\\right] \\right)^2 = \\\\\n       &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i}{\\sigma} - \\dfrac{\\mu}{\\sigma} - \\underset{i=1}{\\overset{n}{\\sum}}\\left[\\dfrac{X_i}{n\\sigma}\\right] + \\dfrac{n\\mu}{n\\sigma} \\right)^2 =\\\\\n       &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i}{\\sigma} -\\dfrac{\\overline X_i}{\\sigma} \\right)^2 = \\dfrac{1}{\\sigma \\cdot(n - 1)}\\underset{i=1}{\\overset{n}{\\sum}} \\left(X_i - \\overline X_i \\right)^2 = \\dfrac{1}{\\sigma}S^2_X\n\\end{aligned}\n\\]\nА значить \\(\\dfrac{(n - 1)\\cdot S^2_X}{\\sigma^2} = \\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 \\sim \\chi^2_{n-1}\\)\n\nНехай \\(\\xi \\sim \\mathcal{N}(0, 1), \\eta \\sim \\chi^2_k\\) і \\(\\xi\\) з \\(\\eta\\) незалежні. Тоді статистика \\(\\zeta = \\dfrac{\\xi}{\\sqrt{\\eta/k}} \\sim t_{k}\\) — з розподілу Стьюдента3 з \\(k\\) ступенями свободи.\n\n\\(\\xi := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sigma} \\sim \\mathcal{N}(0, 1)\\)\n\\(\\eta := \\dfrac{(n - 1)\\cdot S^2_X}{\\sigma^2} \\sim \\chi^2_{n-1}\\)\n\\(\\xi\\) и \\(\\eta\\) незалежні4.\nТоді \\[\n\\begin{aligned}\n  t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} = \\frac{\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sigma}}{\\sqrt{\\dfrac{(n - 1)\\cdot S^2_X}{(n - 1)\\sigma^2}}} = \\dfrac{\\xi}{\\sqrt{\\dfrac{\\eta}{n-1}}} \\sim t_{n - 1}\n\\end{aligned}\n\\]\n\n\nУ підсумку, статистика \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} \\sim t_{n - 1}\\) — взята з розподілу Стьюдента з \\(n - 1\\) ступенем свободи. Але тільки в разі, якщо початкова вибірка з нормального розподілу!\nТепер нам достатньо даних, щоб побудувати \\(t\\)-тест:\n\\[\nH_0: \\mu =\\mu_0, \\ X \\sim \\mathcal{N}\\ проти\\ H_1: \\mu &gt; \\mu_0\n\\tag{4.2}\\]\nСтатистика \\(t(X)\\) буде виглядати так:\n\\[\nt(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} \\sim t_{n - 1}\n\\tag{4.3}\\]\nТоді односторонній критерій набуває вигляду: \\[\n\\left\\{t(X) \\geq t_{n-1, 1 - \\alpha} \\right\\}\n\\tag{4.4}\\]\nА \\(p\\)-значення для одностороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 1 - \\tau_{n-1}(z),\n\\tag{4.5}\\] де z — реалізація статистики \\(t(X)\\), \\(\\tau_{n-1}(z)\\) — функція розподілу \\(t_{n - 1}\\)\nДвосторонній критерій буде виглядати так: \\[\n\\left\\{t(X) \\geq t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{t(X) \\leq -t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\}\n\\tag{4.6}\\]\nПри цьому \\(p\\)-значення для двостороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\tau_{n-1}(z), 1 - \\tau_{n-1}(z)} \\right],\n\\tag{4.7}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\tau_{n-1}(z)\\) — функція розподілу \\(t_{n - 1}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-у-python",
    "href": "t-test.html#t-тест-у-python",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.3 \\(t\\)-тест у Python",
    "text": "4.3 \\(t\\)-тест у Python\nДавайте тепер протестуємо всі наші теоретичні дослідження на практиці. Для цього нам знадобляться наступні бібліотеки функції:\n\nscipy.stats.chii2 — для розподілу \\(\\chi^2\\);\nscipy.stats.t — для \\(t\\) розподілу Стюдента;\nscipy.stats.ttest_1samp — для \\(t\\)-тесту.\n\nПодивимось на розподіл \\(\\chi^2\\) та розподіл \\(\\eta\\).\n\nsample_size = 7\nsample_distr = norm(loc=5, scale=3)\nsample = sample_distr.rvs(sample_size)\nM = 10000\n\neta_statistic = lambda sample: np.var(sample, ddof=1) * (sample_size - 1) / sample_distr.var()\neta_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=eta_statistic,\n    sample_size=sample_size, sample_distr=sample_distr\n)\n\nchi2_dist = chi2(df=sample_size-1)\n\nl_bound, r_bound = np.quantile(eta_sample, [0.001, 0.999])\nx = np.linspace(l_bound, r_bound, 1000)\n\nsns.distplot(eta_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, chi2_dist.pdf(x), label='$\\chi^2$', color=red_pink)\nplt.legend()\nplt.xlabel('$\\eta$')\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.3: Розподіл емпіричного \\(\\eta\\) та теоретичного \\(\\chi^2\\).\n\n\n\n\n\nМи бачимо, що емпіричний розподіл \\(\\eta\\) та теоретичний \\(\\chi^2\\) збігаються. Це означає, що ми можемо використовувати \\(t\\)-тест для перевірки гіпотези.\nТепер перевіримо, чи дійсно \\(t(X)\\) описується розподілом Стьюдента. Для цього скористаємося функцією sample_statistics та побудуємо гістограму для \\(t(X)\\). Генерувати вибірку будемо з нормального розподілу \\(\\mathcal{N}(5, 3^2)\\).\n\nsample_size = 7\nsample_distr = norm(loc=5, scale=3)\nsample = sample_distr.rvs(sample_size)\nM = 10000\n\nT_X = lambda sample: np.sqrt(sample_size) * (np.mean(sample) - sample_distr.mean()) / np.std(sample, ddof=1)\nT_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=T_X,\n    sample_size=sample_size, sample_distr=sample_distr\n)\n\n\nT_dist = t(df=sample_size-1)\n\nl_bound, r_bound = np.quantile(T_sample, [0.001, 0.999])\nx = np.linspace(l_bound, r_bound, 1000)\n\nsns.distplot(T_sample, color=turquoise, label='Емпіричний розподіл')\nplt.plot(x, T_dist.pdf(x), c=red_pink, label='$t_{n-1}$')\nplt.plot(x, norm(0, 1).pdf(x), c=slate, linestyle='--', label='$\\mathcal{N}(0, 1)$')\nplt.legend()\nplt.xlabel('$t(X)$')\nplt.ylabel('Щільність')\nplt.xlim((l_bound, r_bound))\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.4: Розподіл \\(t(X)\\)\n\n\n\n\n\nРозподіл Стьюдента практично ідеально описує дані, тоді як нормальний розподіл більш “центрований”.\nТепер, як викликати вбудований \\(t\\)-тест у Python? Для цього скористаємося функцією scipy.stats.ttest_1samp. Вона приймає на вхід:\n\na — вибірка;\npopmean — середнє значення генеральної сукупності, яке ми хочемо перевірити;\naxis — вздовж якої осі обчислювати тест. За замовчуванням 0;\nnan_policy — як обробляти NaN. Може приймати значення propagate, raise, omit. За замовчуванням propagate;\nalternative — альтернативна гіпотеза. Може приймати значення two-sided, less, greater. За замовчуванням two-sided.\n\n\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\n\nttest_result = ttest_1samp(meeting_time, 70, alternative='less')\nprint(f\"Статистика: {ttest_result.statistic:.2f}\")\nprint(f\"p-значення: {ttest_result.pvalue:.2f}\")\n\nСтатистика: -2.03\np-значення: 0.04\n\n\nОскільки \\(p\\)-значення менше 0.05, то ми відхиляємо нульову гіпотезу. Це означає, що середня тривалість нарад у новому форматі триває менше 70 хвилин. Відповідно до \\(t\\)-тесту, ми можемо стверджувати, що новий формат нарад дійсно скорочує їх тривалість.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчі-інтервали",
    "href": "t-test.html#довірчі-інтервали",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.4 Довірчі інтервали",
    "text": "4.4 Довірчі інтервали\nДавайте тепер розглянемо, як можна оцінити параметри генеральної сукупності за допомогою \\(t\\)-тесту. Розглянемо два виведення довірчого інтервалу.\n\n4.4.1 Перший метод\n\nНехай є статистика \\(Q\\) та критерій \\(\\psi(Q)\\) для перевірки гіпотези \\(H_0: \\theta = m\\) рівня значущості \\(\\alpha\\).\nТоді довірчий інтервал для \\(\\theta\\) рівня довіри \\(1 - \\alpha\\): множина таких \\(m\\), що критерій \\(\\psi(Q)\\) не відкидає для них \\(H_0\\).\n\nНехай \\(\\mu\\) — істинне середнє вибірки. Ми також знаємо, що за \\(H_0: \\sqrt{n}\\dfrac{\\overline X - m}{\\sqrt{S^2}} \\sim t_{n - 1}\\).\nНас цікавлять такі \\(m\\), що: \\(\\left\\{-t_{n-1, 1 - \\frac{\\alpha}{2}} &lt; \\sqrt{n}\\dfrac{\\overline X - m}{\\sqrt{S^2}} &lt; t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\}\\), у цьому разі критерій не відкинеться.\nРозпишемо, щоб у центрі залишилося тільки \\(m\\): \\(\\left\\{\\overline X - \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} &lt; m &lt; \\overline X + \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}}\\right\\}\\). А отже, наш довірчий інтервал:\n\\[\nCI_{\\mu} = \\left(\\overline X \\pm \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right),\n\\tag{4.8}\\] де \\(S^2 = \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}(X_i - \\overline X)^2\\)\n\n\n4.4.2 Другий метод\n\nДовірчим інтервалом для параметра \\(\\theta\\) рівня довіри \\(1 - \\alpha\\) є пара статистик \\(L(X), R(X)\\), таких, що \\(P(L(X) &lt; \\theta &lt; R(X)) = 1 - \\alpha\\).\n\nЦе класичне визначення довірчого інтервалу. Тобто, ми повинні знайти такі \\(L(X)\\) та \\(R(X)\\), що \\(P(L(X) &lt; \\mu &lt; R(X)) = 1 - \\alpha\\).\n\\[\n\\begin{aligned}\n    &t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} \\sim t_{n - 1} \\Rightarrow \\\\\n    &P\\left(-t_{n - 1, 1-\\alpha/2} &lt; \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} &lt; t_{n - 1, 1-\\alpha/2} \\right) = 1 - \\alpha \\Leftrightarrow \\\\\n    &P\\left(\\overline X - \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}}  &lt; \\mu &lt; \\overline X + \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right) = 1 - \\alpha\n\\end{aligned}\n\\tag{4.9}\\]\nТоді\n\\[\nCI_{\\mu} = \\left(\\overline X \\pm \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right)\n\\tag{4.10}\\]\nЦей довірчий інтервал збігається з попереднім. Тобто, ми можемо використовувати обидва методи для побудови довірчого інтервалу.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчі-інтервали-у-python",
    "href": "t-test.html#довірчі-інтервали-у-python",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.5 Довірчі інтервали у Python",
    "text": "4.5 Довірчі інтервали у Python\nДавайте тепер побудуємо довірчий інтервал для середнього значення тривалості нарад у новому форматі. Для цього скористаємося функцією scipy.stats.t.interval. Вона приймає на вхід:\n\nconfidence — рівень значущості;\ndf — кількість ступенів свободи;\nloc — середнє значення, за замовчуванням 0;\nscale — стандартна девіація, за замовчуванням 1.\n\nДля побудови лівостороннього довірчого інтервалу візьмемо confidence на рівні 90%, оскільки ми хочемо перевірити, чи тривалість нарад у новому форматі менша 70 хвилин.\n\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\n\nconfidence = 0.90\ndf = len(meeting_time) - 1\nloc = np.mean(meeting_time)\nscale = np.std(meeting_time, ddof=1) / np.sqrt(len(meeting_time))\n\ninterval = t.interval(confidence, df, loc, scale)\nprint(f\"Довірчий інтервал: {np.round(interval, 2)}\")\n\nДовірчий інтервал: [47.61 69.53]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-та-вимога-нормальності",
    "href": "t-test.html#t-тест-та-вимога-нормальності",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.6 \\(t\\)-тест та вимога нормальності",
    "text": "4.6 \\(t\\)-тест та вимога нормальності\nМи навчилися розв’язувати задачу оцінки середнього вибірки, коли дисперсія невідома, але вибірка з нормального розподілу. Тепер розглянемо, що буде, якщо вибірка не з нормального розподілу.\n\nПриклад 4.2  \n\nВи запускаєте онлайн-платформу з курсами програмування. Ви плануєте надавати доступ до курсів за фіксовану плату, але також інвестуєте в маркетинг та підтримку студентів. У середньому, прибуток від одного користувача (після вирахування витрат на платформу, рекламу тощо) становить \\(X\\) грн., але витрати на залучення кожного нового студента — 1000 грн.\n\n\nСтуденти можуть скористатися гарантією повернення грошей протягом 14 днів. Ви хочете перевірити, чи є прибуток від нових користувачів більшим за 0 грн. (тобто, чи є прибуток від нових користувачів більшим за витрати на залучення нових студентів). Тому іноді прибуток від користувача — позитивне число, а іноді — негативне.\n\n\nІнвестори готові профінансувати вашу платформу, якщо ви доведете, що вона буде прибутковою. У вас є дані про чистий прибуток або збиток від кожного користувача, який вже зареєструвався.\n\n\nЗгенеруємо штучні дані для цієї задачі. Для цього змішаємо логнормальний розподіл для позитивних значень (прибуток) та від’ємний \\(\\chi^2\\) для від’ємних значень (збиток).\n\nn = 5000\np_positive = 0.6\n\nn_pos = int(n * p_positive)\nprofits = np.random.lognormal(mean=2, sigma=0.8, size=n_pos) * 100\n\nn_neg = n - n_pos\nlosses = -np.random.chisquare(df=2, size=n_neg) * 100\n\nprofits = np.concatenate([profits, losses])\nnp.random.shuffle(profits)\n\nsns.histplot(profits, bins=100, kde=True, color=turquoise)\n\nplt.xlabel('Прибуток або збиток')\nplt.ylabel('Кількість користувачів')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.5: Візуалізація штучних до задачі.\n\n\n\n\n\nПорахуємо середній прибуток.\n\nprint(f\"Середній прибуток: {profits.mean():.2f}\")\n\nСередній прибуток: 547.45\n\n\nНа відміну від попереднього завдання тут 2 відмінності:\n\nПочаткова вибірка не з нормального розподілу\nВибірка досить велика: не 7 елементів, а вже 5000.\n\n\n4.6.1 \\(t'\\)-тест\nЗгадаймо, що в нас від початку була ідея в \\(Z\\)-тесті замість статистики \\(Z\\), у якій дисперсія відома, використовувати критерій \\(t\\), де дисперсія оцінена на даних. І використовувати нормальний розподіл. Тільки в першому завданні цей критерій нам не допоміг. Але що, якби вибірка була великою? Чи могли б ми використовувати нормальний розподіл для наближення?\n\nБудемо розглядати ту саму статистику \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\)\n\\(\\xi := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\stackrel{d}{\\rightarrow} \\mathcal{N}(0, 1)\\). За ЦГТ збіжність є тільки за розподілом.\nтоді \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} = \\xi \\cdot \\sqrt{\\dfrac{\\sigma^2}{S^2}}\\). Позначимо \\(\\phi := \\sqrt{\\dfrac{\\sigma^2}{S^2}}\\)\n\nПам’ятаєте, раніше було сказано, що \\(S^2\\) — найкраща оцінка для дисперсії? Річ у тім, що вона є консистентною оцінкою для \\(\\sigma^2\\). Тобто \\(S^2\\) збігається за ймовірністю до \\(\\sigma^2\\). Тобто \\(S^2 \\stackrel{p}{\\rightarrow} \\sigma^2\\).\nА в цьому випадку існує теорема, яка стверджує, що \\(\\phi = \\dfrac{\\sigma^2}{S^2}  \\stackrel{p}{\\rightarrow} 1\\).\n\n\\(t = \\xi \\cdot \\phi\\).\n\n\\(\\xi \\stackrel{d}{\\rightarrow} \\mathcal{N}(0, 1)\\)\n\\(\\phi \\stackrel{p}{\\rightarrow} 1\\)\nІ тут набуває чинності ще одна теорема: \\(t = \\xi \\cdot \\phi \\stackrel{d}{\\rightarrow} 1\\cdot \\mathcal{N}(0, 1)\\). Та сама збіжність, що й у ЦПТ!\nТобто статистика \\(t\\) так само буде з нормального розподілу.\n\n\nОтже, якщо вибірка велика, то ми можемо вважати, що \\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\).\n\n\n\n\n\n\nПримітка\n\n\n\nЗауважимо, що у випадку “нормальний розподіл, велика вибірка” працюють одразу 2 критерії: \\(t\\)-тест та \\(t'\\)-тест. Це означає, що якщо \\(t(X) \\overset{H_0}{\\sim} t_{n - 1}\\) та \\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\), то \\(t_{n - 1} \\approx \\mathcal{N}(0, 1)\\).\nФормально ж, якщо ступінь свободи в \\(t\\)-розподілі дорівнює нескінченності, то це нормальний розподіл! \\(\\lim_{n\\rightarrow \\infty}t_{n} = \\mathcal{N}(0, 1)\\)\nА якщо \\(t_{n - 1} \\approx \\mathcal{N}(0, 1)\\), то ми замість \\(t'\\)-критерію ми можемо використовувати \\(t\\)-критерій!\n\n\nВ такому випадку критерій \\(t\\)-тесту буде виглядати так:\n\\[\nH_0: \\mu =\\mu_0\\ проти\\ H_1: \\mu &gt; \\mu_0\n\\tag{4.11}\\]\nСтатистика \\(t(X)\\) буде виглядати так:\n\\[\nt(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\n\\tag{4.12}\\]\nПри достатньо великій вибірці \\(t(X) \\sim \\mathcal{N}(0, 1)\\).\nТоді односторонній критерій набуває вигляду:\n\\[\n\\left\\{t(X) \\geq z_{1 - \\alpha} \\right\\}\n\\tag{4.13}\\]\nА \\(p\\)-значення для одностороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 1 - \\Phi(z),\n\\tag{4.14}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\).\nДвосторонній критерій буде виглядати так:\n\\[\n\\left\\{t(X) \\geq z_{1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{t(X) \\leq -z_{1 - \\frac{\\alpha}{2}} \\right\\}\n\\tag{4.15}\\]\nПри цьому \\(p\\)-значення для двостороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right],\n\\tag{4.16}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\).\nПеревіримо наш критерій на великій вибірці. Для цього згеренуємо вибірку з експоненційного розподілу \\(\\mathcal{E}(300)\\), де \\(X \\sim \\mathcal{E}(\\lambda)\\), \\(\\lambda = 1/\\mu\\). Вибірка буде згенерована з параметром \\(\\lambda = 1/300\\). Тобто, середнє значення вибірки буде \\(300\\).\n\nsample_size=2000\nM = 10000\nsample_distr = expon(loc=5, scale=300)\n\nT_X = lambda sample: np.sqrt(sample_size) * (np.mean(sample) - sample_distr.mean()) / np.std(sample, ddof=1)\n\nT_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=T_X,\n    sample_size=sample_size, sample_distr=sample_distr)\n\nl_bound, r_bound = np.quantile(T_sample, [0.001, 0.999])\n\nx = np.linspace(l_bound, r_bound, 1000)\nsns.distplot(T_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, norm(0, 1).pdf(x), label='Експоненціальний розподіл', color=red_pink)\nplt.legend()\nplt.xlabel(f'{name}')\nplt.xlim((l_bound, r_bound))\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.6: Розподіл \\(t'(X)\\) для великої вибірки.\n\n\n\n\n\nМи бачимо, що емпіричний розподіл \\(t'(X)\\) та теоретичний \\(\\mathcal{N}(0, 1)\\) збігаються. Це означає, що ми можемо використовувати \\(t'\\)-тест для перевірки гіпотези. Якщо ж перевірити на великих вибірках з нормального розподілу, то \\(t\\)-тест та \\(t'\\)-тест будуть давати доволі схожі результати.\n\nsample_size=2000\nM = 30000\nsample_distr = norm(loc=5, scale=300)\n\nT_X = lambda sample: np.sqrt(sample_size) * (np.mean(sample) - sample_distr.mean()) / np.std(sample, ddof=1)\nT_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=T_X,\n    sample_size=sample_size, sample_distr=sample_distr)\n\nl_bound, r_bound = np.quantile(T_sample, [0.001, 0.999])\n\nx = np.linspace(l_bound, r_bound, 1000)\nsns.distplot(T_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, norm(0, 1).pdf(x), label='$\\mathcal{N}(0, 1)$', color=red_pink)\nplt.legend()\nplt.xlabel(f'{name}')\nplt.xlim((l_bound, r_bound))\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.7: Розподіл \\(t(X)\\) для великої вибірки.\n\n\n\n\n\nВиходить, що статистика \\(t'(X)\\) при великій вибірці з нормального розподілу також буде з нормального розподілу.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчий-інтервал",
    "href": "t-test.html#довірчий-інтервал",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.7 Довірчий інтервал",
    "text": "4.7 Довірчий інтервал\nДовірчий інтревал виводиться аналогічно до \\(t\\)-тесту.\n\\[\n\\begin{aligned}\n    &t'(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} \\sim \\mathcal{N}(0, 1) \\Rightarrow \\\\\n    &P\\left(-z_{1 - \\frac{\\alpha}{2}} &lt; \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} &lt; z_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha \\Leftrightarrow \\\\\n    &P\\left(\\overline X - \\dfrac{z_{1 - \\frac{\\alpha}{2}} S^2}{\\sqrt{n}}  &lt; \\mu &lt; \\overline X + \\dfrac{z_{1 - \\frac{\\alpha}{2}} S^2}{\\sqrt{n}} \\right) = 1 - \\alpha\n\\end{aligned}\n\\tag{4.17}\\]\nПереглнемо на практиці, як це виглядає у Python.\n\nsample = expon(scale=300).rvs(2000)\nci = norm.interval(confidence=0.95, loc=np.mean(sample), scale=sem(sample))\nprint(f\"CI = {np.round(ci, 2)}\")\n\nCI = [293.89 319.75]\n\n\nТепер ми можемо повернутися до нашої задачі з прибутком.\n\nci_profit = norm.interval(confidence=0.95, loc=np.mean(profits), scale=sem(profits))\nprint(f\"CI = {np.round(ci_profit, 2)}\")\n\nCI = [520.19 574.72]\n\n\nЦе означає, що ми можемо стверджувати, що прибуток від нових користувачів більший за 0 грн.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#вибір-критерію",
    "href": "t-test.html#вибір-критерію",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.8 Вибір критерію",
    "text": "4.8 Вибір критерію\nДля початку визначимося, коли який критерій краще використовувати?\n\nЯкщо вибірка розміру 60, то вже \\(t_{59} \\approx \\mathcal{N}(0, 1)\\).\n\nПодивимося на розподіли Стьюдента і нормального:\n\n\n\ndf = 59\nt_dist = t(df=df)\nz_dist = norm(loc=0, scale=1)\n\nx = np.linspace(-3, 3, 100)\n\nplt.plot(x, z_dist.pdf(x), label='$\\mathcal{N}(0, 1)$', color=red_pink)\nplt.plot(x, t_dist.pdf(x), label='$t_{59}$', color=turquoise)\nplt.legend()\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.8: Розподіл \\(t(X)\\) та \\(N(0, 1)\\).\n\n\n\n\n\n\nМи бачимо, що ці два розподіли візуально повністю збігаються, тому неважливо, як порахувати: статистика \\(t\\sim \\mathcal{N}(0, 1)\\) або \\(t\\sim t_n\\).\nАле це не означає, що з \\(N=60\\) \\(t\\)-тест або \\(t'\\)-тест працюють коректно! Якщо вибірка не з нормального розподілу, вони обидва можуть усе ще помилятися.\n\n\nЯкщо вибірка менше 60, то безпечніше використовувати \\(t\\)-тест, ніж \\(t'\\)-тест.\n\nУ \\(t\\)-тест FPR завжди буде меншим, ніж у \\(t'\\)-тест.\n\nНа FPR впливає відсоток випадків pvalue &lt; alpha. У \\(t\\)-тест \\(p\\)-значення \\(\\geq\\) \\(t'\\)-тест \\(p\\)-значення.\npvalue = t_distr.cdf(x) або pvalue = norm_dist.cdf(x). Тож чим важчий хвіст у розподілу, тим більше \\(p\\)-значення.\n\n\n\nПодивимось на прикладі.\n\ndf_array = [2, 5, 10, 20]\nx = np.linspace(-3, 3, 100)\n\nfor df in df_array:\n    t_dist = t(df=df)\n    plt.plot(x, t_dist.cdf(x), label=f't(df={df})')\n\nz_dist = norm(loc=0, scale=1)\nplt.plot(x, z_dist.cdf(x), c=red_pink, label='$\\mathcal{N}(0, 1)$')\nplt.legend()\nplt.xlabel('X')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.9: Куртки розподілів \\(t\\) та \\(N(0, 1)\\).\n\n\n\n\n\nЯк видно на графіку, що менший ступінь свободи, то вищою є лінія на графіку (за x &lt; 0), а отже \\(P(X &lt; x)\\) буде більшим, ніж у нормальному розподілі. Тобто, \\(t\\)-тест буде давати менше \\(p\\)-значення, ніж \\(t'\\)-тест. А отже, \\(t\\)-тест буде відкидати нульову гіпотезу частіше, ніж \\(t'\\)-тест.\n\n\n\n\n\n\nПримітка\n\n\n\nРозподіл Стьюдента з нескінченністю ступенів свободи — це нормальний розподіл: \\(t_{\\infty} = \\mathcal{N}(0, 1)\\). Тому norm(0, 1).cdf(x) = t_distr(df=infinity).cdf(x) &lt; t_distr(df=N).cdf(x).\n\n\nТому, якщо вибірка невелика, безпечніше використовувати \\(t\\)-тест. Але все ще не факт, що ваш критерій буде валідний!\nМи бачимо, що ми скрізь можемо використовувати \\(t\\)-тест (а \\(t'\\)-тест не завжди), і в разі маленьких вибірок він безпечніший. Тому \\(t\\)-тест і став набагато популярнішим, ніж \\(t'\\)-тест. Але \\(t'\\)-тест на практиці може бути теж корисний:\n\nНе треба думати під час реалізації про ступені свободи.\nНаписати такий критерій на SQL буде набагато простіше: ви можете використовувати табличні значення в коді, щоб зрозуміти, чи відкинувся критерій.\nРобити різні теоретичні обчислення простіше.\nУ ньому складніше помилитися під час реалізації.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#мінімальний-ефект",
    "href": "t-test.html#мінімальний-ефект",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.9 Мінімальний ефект",
    "text": "4.9 Мінімальний ефект\nПовернемося до завдання зі стартапом. Уявімо, що ми хочемо запустити наш стартап на новому ринку, наприклад у іншій країні. Питання: чи можемо ми зменшити розмір вибірки?\nЩо взагалі нам заважає взяти занадто маленьку вибірку? Наприклад, якщо ми перевіряємо наш стартап на 1-2 користувачів, то ми нічого не можемо сказати про наш істинний ефект, він може бути як більшим за 0, так і меншим. Буде занадто широкий довірчий інтервал (через велику дисперсію у вибірці), і нам потрібен величезний ефект, щоб його виявити.\nЩе, можливо, ми не можемо використовувати критерій на такій маленькій вибірці. А якщо вибірка складалася б із нескінченної кількості користувачів, то ми могли б абсолютно точно сказати справжній прибуток від користувача, навіть якщо він дорівнює 1 копійці. При цьому обидва випадки нас не влаштовують. У першому — ми не зможемо запустити стартап через занадто великий шум, а в другому — нам потрібна вічність, щоб перевірити нашу гіпотезу.\nІ тут нам допоможе MDE (minimum detectable effect). Це таке істинне значення ефекту, що наш шанс його виявити дорівнює \\(1-\\beta\\) при використанні нашого критерію.\nМи можемо подивитись, який ефект ми зможемо зафіксувати під меншої кількості користувачів, і від цього вирішити, чи підходить нам така вибірка, чи ні. Наприклад:\n\nМи бачимо, що MDE 100 гривень. Тобто з ймовірністю \\(1-\\beta\\) (на практиці 80%) ми його виявимо, якщо такий ефект буде. І з імовірністю 80% стартап запуститься на новому ринку. Чудово, це нас влаштовує, ми перевіряємо гіпотезу на меншій вибірці.\nМи бачимо, що MDE 10000 гривень. Це, навпаки, занадто багато: у нас 99% послуг коштують менше 1000 гривень. Ми не наберемо такого прибутку, стартап невиграшний, потрібно брати вибірку більшого розміру.\n\nТому слід чітко визначити від чого залежить MDE. Це може бути:\n\nПомилка першого роду, або \\(\\alpha\\). Наприклад, за \\(\\alpha = 1\\) ми знайдемо ефект і за розміру вибірки, що дорівнює одиниці (ми просто завжди відкидатимемо \\(H_0\\)). А за \\(\\alpha = 0\\) ми ніколи не зафіксуємо ефект.\nПотужність, або \\(1 - \\beta\\). Випливає із самого визначення.\nВід шуму в даних, або від дисперсії. Що більш шумні дані, як ми знаємо, то ширший довірчий інтервал. А отже, складніше точно передбачити межі для істинного ефекту, тому й MDE буде більшим.\nВід розміру вибірки. Нас цікавить не просто дисперсія в даних, а дисперсія середнього значення: вона за тією самою логікою має бути якомога меншою. А що таке дисперсія середнього? Це \\(\\dfrac{\\sigma^2}{N}\\), тому MDE також залежить від розміру вибірки.\n\nТепер давайте виведемо формулу виходячи з того, що ми знаємо всі ці чотири параметри. Для початку визначимося з гіпотезою, що перевіряється:\n\\[\nH_0: \\mu_0 = 0\\ проти. \\ H_1: \\mu_0 &gt; 0\n\\tag{4.18}\\]\nПозначимо оцінку дисперсії середнього значення:\n\\[\nS^2_{\\mu} := \\frac{S^2}{N}\n\\tag{4.19}\\]\nА також стандартне відхилення середнього значення:\n\\[\nS_{\\mu} = \\sqrt{\\frac{S^2}{N}}\n\\tag{4.20}\\]\nТепер ми знаємо, що\n\\[\n\\overline X \\sim \\mathcal{N}(\\mu, S^2_{\\mu})\n\\tag{4.21}\\]\nНам треба знайти \\(\\text{MDE}=m\\), таке, що:\n\nякщо \\(\\overline X \\sim \\mathcal{N}(m, S^2_{\\mu})\\), то в \\(1-\\beta\\) відсотку випадків для нього відкинеться критерій. Перевіряємо потужність (ціанова площа на графіку).\nякщо \\(\\overline X \\sim \\mathcal{N}(0, S^2_{\\mu})\\), то критерій відкинеться для нього в \\(\\alpha\\) відсотків випадків. Перевіряємо FPR (рожева площа на графіку).\n\n\n\n\n\n\n\n\n\nРисунок 4.10: Графік MDE.\n\n\n\n\n\nНехай\n\\[\nB(X): P_{H_0}(\\overline X &gt; B(X)) = \\alpha,\n\\tag{4.22}\\] де \\(B(X)\\) — межа відхилення нульової гіпотези.\nТоді\n\\[\nP_{H_1}(\\overline X &gt; B(X)) = 1-\\beta\n\\tag{4.23}\\]\nАбо\n\\[\nP_{H_1}(\\overline X - m &gt; B(X) - m) = 1-\\beta\n\\tag{4.24}\\]\nПозначимо \\(\\xi := \\overline X - m\\). Тоді\n\\[\nP_{H_0}(\\xi &gt; B(X) - m) = 1-\\beta,\n\\tag{4.25}\\] де \\(B(X) - m\\) — межа відхилення нульової гіпотези з урахуванням істинного ефекту.\nТреба розв’язати ці 2 рівняння й ми отримаємо вираз \\(m\\) через усі чотири параметри.\nЗа \\(H_0\\) наш критерій має такий вигляд:\n\\[\n\\left\\{T(X) \\geq z_{1 - \\alpha} \\right\\} \\Leftrightarrow  \\left\\{\\sqrt{N}\\dfrac{\\overline X}{\\sqrt{S^2}} \\geq z_{1 - \\alpha} \\right\\} \\Leftrightarrow B(X) = z_{1 - \\alpha}\\sqrt{\\frac{S^2}{N}} = z_{1 - \\alpha}S_{\\mu}\n\\tag{4.26}\\]\nТоді\n\\[\nP_{H_0}(\\xi &gt; z_{1 - \\alpha}S_{\\mu} - m) = 1-\\beta\n\\tag{4.27}\\]\nАле працювати з розподілом \\(\\mathcal{N}(0, S^2_{\\mu})\\) не дуже зручно, набагато простіше з \\(\\mathcal{N}(0, 1)\\). Для цього переходу достатньо перейти від \\(\\xi \\rightarrow \\dfrac{\\xi}{S_{\\mu}}\\) за властивостями нормального розподілу.\nПозначимо \\(\\eta := \\dfrac{\\xi}{S_{\\mu}}\\). Тоді\n\\[\n\\begin{aligned}\n    &P_{H_0}(\\xi &gt; z_{1 - \\alpha}S_{\\mu} - m) =\\\\\n    &P_{H_0}(\\dfrac{\\xi}{S_{\\mu}} &gt; \\dfrac{z_{1 - \\alpha}S_{\\mu} - m}{S_{\\mu}}) =\\\\\n    & P_{\\mathcal{N}(0, 1)}(\\eta &gt; z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}}) = 1-\\beta\n\\end{aligned}\n\\tag{4.28}\\]\nЗа умови \\(\\Phi(C) = P(\\eta &lt; C)\\), тоді\n\\[\n\\begin{aligned}\n&1 - \\Phi \\left(z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}} \\right) = 1-\\beta \\Leftrightarrow\\\\ &z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}} = z_{\\beta},\n\\end{aligned}\n\\tag{4.29}\\] де \\(z_{\\beta} = \\Phi^{-1}(\\beta)\\) — квантиль \\(\\beta\\) нормального розподілу.\nТепер згадаємо, що \\(\\eta \\sim \\mathcal{N}(0, 1)\\), тоді\n\\[\nm = (z_{1 - \\alpha} - z_{\\beta}) \\cdot S_{\\mu} = (z_{1 - \\alpha} + z_{1 - \\beta}) \\cdot \\sqrt{\\frac{S^2}{N}}\n\\tag{4.30}\\]\nОтже, ми отримали формулу для MDE:\n\\[\n\\text{MDE} = (z_{1 - \\alpha} + z_{1 - \\beta}) \\cdot \\sqrt{\\frac{S^2}{N}}\n\\tag{4.31}\\] де \\(z_{1 - \\alpha}\\) — квантиль \\(\\alpha\\) нормального розподілу, \\(z_{1 - \\beta}\\) — квантиль \\(\\beta\\) нормального розподілу, \\(S^2\\) — оцінка дисперсії, \\(N\\) — розмір вибірки.\nПовернемося до стартапу. Припустимо, що \\(N = 1000\\), \\(\\alpha=5\\)%, \\(1-\\beta=80\\)%, а як дізнатися \\(S^2\\)?\nНа практиці є 3 способи:\n\nОцінити на історичних даних. У цьому випадку це не підходить, тому що раніше стартапу на новому ринку не було.\nОцінити за схожими даними. Наприклад, у нашому випадку, оцінити дисперисію на початковому ринку.\nЯкось теоретично оцінити. Найгірший спосіб, який працює, якщо перші два не допомагають.\n\nПодивимося тепер MDE у нашому завданні.\n\nN = 1000\nS2 = np.var(profits)\nalpha = 0.05\nbeta = 1 - 0.8\n\nMDE = (norm().ppf(1-alpha) + norm().ppf(1 - beta)) * np.sqrt(S2/N)\nprint(f\"MDE при N = {N}: {np.round(MDE, 2)}\")\n\nMDE при N = 1000: 77.33\n\n\nА отже, ми можемо розраховувати на точність лише в 77.33 грн. Але дня нас це може бути занадто великий MDE: хочеться, щоб він був \\(\\leq\\) 50 грн, ми припускаємо, що це ймовірніший істинний ефект, виходячи з поперелднього досвіду.\nДавайте тепер розв’яжемо зворотну задачу: Ми знаємо \\(MDE=50\\) грн., \\(\\alpha=5\\)%, \\(1-\\beta=80\\)%, \\(S^2\\), чому дорівнює \\(N\\)? Виведемо його з формули MDE:\n\\[\nN = \\left(\\dfrac{z_{1 - \\alpha} + z_{1 - \\beta}}{\\text{MDE}}\\right)^2 S^2\n\\tag{4.32}\\]\n\nS2 = np.var(profits)\nalpha = 0.05\nbeta = 1 - 0.8\nmde = 50\n\nN = ((norm().ppf(1-alpha) + norm().ppf(1 - beta)) / mde)**2 * S2\nN = int(N) + 1\nprint(f\"Мінімальний розмір вибірки: {N}\")\n\nМінімальний розмір вибірки: 2392\n\n\nТепер ми знаємо, що нам потрібно 2392 користувачів, щоб перевірити нашу гіпотезу з MDE 50 грн.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#двовибірковий-t-тест",
    "href": "t-test.html#двовибірковий-t-тест",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.10 Двовибірковий \\(t\\)-тест",
    "text": "4.10 Двовибірковий \\(t\\)-тест\n\nПриклад 4.3  \n\nНа нашому онлайн-сервісі з розміщення оголошень є платні послуги просування. Ми плануємо запровадити знижки на ці послуги, щоб залучити більше користувачів і збільшити дохід. Для перевірки ефективності було вирішено провести A/B тест: одній половині нових користувачів ми не надавали знижки, а другій половині — надавали знижки на просування. Потрібно визначити, чи призвело це до зростання доходу.\n\n\nДля вирішення цього завдання ми не можемо використовувати одновибірковий \\(t\\)-тест. Цього разу в нас дві вибірки \\(A\\) — контроль, та \\(B\\) — тест.\nНаша гіпотеза звучить так:\n\\[\nH_0: E A = E B \\; проти \\; H_1: E A &lt; E B\n\\]\nДалі в нас може бути кілька варіантів:\n\nОбидві вибірки нормальні.\n\nТоді у випадку рівних дисперсій \\(\\sigma^2_A = \\sigma^2_B\\), спільна дисперсія \\(S^2_{pooled}\\) обчислюється за формулою:\n\\[\nS^2_{pooled} = \\dfrac{(N - 1)S^2_A + (M - 1)S^2_B}{N + M - 2},\n\\tag{4.33}\\] де \\(N\\), \\(M\\) — розмір контролю і тесту відповідно.\nА критерій має такий вигляд:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{S^2_{pooled}\\sqrt{1/N + 1/M}} \\overset{H_0}{\\sim} t_{n + m - 2}\n\\tag{4.34}\\] де \\(n + m - 2\\) — ступені свободи.\nУ випадку, якщо дисперсії не рівні \\(\\sigma^2_A \\neq \\sigma^2_B\\)5, то:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{\\sqrt{S^2_{A}/N + S^2_{B}/M}} \\overset{H_0}{\\sim} t_{v}\n\\tag{4.35}\\] де \\(v\\) — ступені свободи, які обчислюються за формулою:\n\\[\nv = \\frac{\\left(\\frac{S^2_{A}}{N} + \\frac{S^2_{B}}{M} \\right)^2}{\\left(\\frac{(S^2_{A})^2}{N^2(N - 1)} + \\frac{(S^2_{B})^2}{M^2(M-1)} \\right)}\n\\tag{4.36}\\]\n\nХоча б одна вибірка не нормальна.\n\nТоді ми можемо використовувати нормальну апроксимація при великій вибірці:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{\\sqrt{S^2_{A}/N + S^2_{B}/M}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\n\\tag{4.37}\\] де \\(S^2_{A}\\), \\(S^2_{B}\\) — вибіркові дисперсії.\n\n4.10.1 Двовибірковий \\(t\\)-тест у Python\nДля реалізації двовибіркового \\(t\\)-тесту в Python ми можемо використовувати ttest_ind6 з бібліотеки scipy.stats.\nПодивимось на приклад з двома вибірками, перша вибірка — з експоненційного розподілу, а друга — з нормального розподілу.\n\nX = expon(scale=1100).rvs(1000)\nY = norm(loc=980, scale=30).rvs(1000)\n\nt_results = ttest_ind(X, Y, equal_var=False, alternative='greater')\nci_t_results = t_results.confidence_interval(confidence_level=0.95)\n\nprint(f\"t-статистика = {np.round(t_results.statistic, 2)}\")\nprint(f\"p-значення = {np.round(t_results.pvalue, 5)}\")\nprint(f\"Довірчий інтервал = {np.round(ci_t_results, 2)}\")\n\nt-статистика = 3.62\np-значення = 0.00015\nДовірчий інтервал = [68.38   inf]\n\n\n\n\n\n\n\n\nПопередження\n\n\n\nПри використанні \\(t\\)-тесту, як одновибіркового, так і двовибіркового, важливо пам’ятати, що:\n\nЕлементи вибірок мають бути незалежні.\n\nНаприклад, ваша вибірка не може містити кілька замовлень одного користувача. Вони мають бути агреговані, інакше критерії будуть невалідні!\n\nУ двовибірковому критерії вибірки тесту і контролю повинні бути незалежні!.\n\nІнакше критерії так само будуть невалідними.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#контрольні-питання",
    "href": "t-test.html#контрольні-питання",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.11 Контрольні питання",
    "text": "4.11 Контрольні питання\n\n\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#footnotes",
    "href": "t-test.html#footnotes",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "Розподіл \\(\\chi^2\\) — це розподіл суми квадратів \\(k\\) незалежних нормальних випадкових величин з нульовим математичним сподіванням. Тобто, якщо \\(X_1, X_2, \\ldots, X_k \\sim \\mathcal{N}(0, 1)\\), то \\(Y = X_1^2 + X_2^2 + \\ldots + X_k^2 \\sim \\chi^2_k\\).↩︎\nДоведення Cochran (1934).↩︎\nРозподіл Стьюдента — це розподіл, який виникає при нормальному розподілі з невідомою дисперсією. Якщо \\(X_1, X_2, \\ldots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), то \\(t = \\dfrac{\\overline{X} - \\mu}{S/\\sqrt{n}} \\sim t_{n-1}\\), де \\(\\overline{X}\\) — вибіркове середнє, \\(S\\) — вибіркова стандартна девіація.↩︎\nДоведення Basu (1955).↩︎\nТакий підхід називається \\(t\\)-тестом Уелча.↩︎\nДокументація: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.htm↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Список літератури",
    "section": "",
    "text": "Basu, D. 1955. On Statistics Independent of a Complete Sufficient\nStatistic. Sankhya. Vol. 15.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a\nNormal System, with Applications to the Analysis of Covariance.\nMathematical Proceedings of the Cambridge Philosophical\nSociety. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit\nDistributions for Sums of Independent Random Variables. Martino\nFine Books.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in\nPhysics. The Johns Hopkins University Press.",
    "crumbs": [
      "Список літератури"
    ]
  }
]