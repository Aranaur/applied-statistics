[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладний статистичний аналіз",
    "section": "",
    "text": "Передмова\nЦей посібник створено для тих, хто хоче не просто вивчати статистику, а розуміти, як вона працює на практиці — у даних, рішеннях, дослідженнях. Ми починаємо з простого, але фундаментального — з біноміального критерію — і поступово розширюємо горизонти: від гіпотез й довірчих інтервалів до \\(t\\)- та \\(Z\\)-критеріїв та Монте-Карло моделювання.\nКожен розділ поєднує теоретичне підґрунтя, інтерпретації, візуалізації і, що важливо, реалізацію в Python. Це не академічна теорія заради теорії. Тут — статистика як інструмент: перевіряти гіпотези, оцінювати ефекти, шукати закономірності та ухвалювати обґрунтовані рішення.\nЦей посібник буде корисним:\nМи не обіцяємо, що буде завжди легко. Але гарантуємо, що буде зрозуміло.",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "index.html#sec-how-to-use",
    "href": "index.html#sec-how-to-use",
    "title": "Прикладний статистичний аналіз",
    "section": "Як користуватись цим посібником",
    "text": "Як користуватись цим посібником\nЦей посібник можна проходити послідовно — від першої теми до останньої — або звертатись до окремих розділів за потреби. Щоб отримати максимум користі, ось кілька порад:\n\nЧитайте, але й кодьте. Теорія дає розуміння, але практика — вміння. Якщо бачите фрагмент коду — спробуйте його виконати, змінити параметри, подивитись, що буде.\nГрайте з прикладами. В багатьох місцях можна змінити дані, розміри вибірки чи рівень значущості — робіть це. Так найкраще приходить інтуїція.\nПовертайтесь назад. Якщо на якомусь етапі щось здається складним, це нормально. Часто новий матеріал “вмикає” краще розуміння попереднього.\nНе бійтесь помилятись. Статистика — це не про ідеальні відповіді, а про ймовірності, невизначеність і пояснення того, що ми бачимо.\nЗадавайте собі питання:\n\nЯку гіпотезу ми тут перевіряємо?\nЩо означає результат?\nЩо буде, якщо змінити розмір вибірки чи очікувану різницю?\nЯк це застосувати в моїй сфері?\n\nНе ігноруйте “інтерпретацію”. Це не просто розділ — це ключ до розуміння. Бо мало просто отримати результат — важливо знати, що він означає.\n\nДосліджуйте далі. Цей посібник — стартова платформа. Якщо вам цікаво — глибше копати тільки вітається.",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "index.html#sec-setup",
    "href": "index.html#sec-setup",
    "title": "Прикладний статистичний аналіз",
    "section": "Попередні налаштування Python",
    "text": "Попередні налаштування Python\nДля роботи з цим посібником вам знадобиться Python. В процесі написання ми використовували наступні глобальні бібліотеки та змінні:\n1import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom statsmodels.stats.proportion import proportion_confint\nfrom IPython.display import Markdown, display\n\nfrom scipy.stats import (\n    norm,\n    binom,\n    expon,\n    binomtest,\n    chisquare,\n    t,\n    chi2,\n    pareto,\n    ttest_1samp,\n    ttest_ind,\n    sem,\n    bernoulli,\n    uniform,\n    gamma\n)\n\n2np.random.seed(73)\n\n3sns.despine(left=True, bottom=True)\nbase_size = 13\nsns.set_style(\"whitegrid\")\npalette = sns.color_palette(\"Set2\")\nsns.set_palette(palette)\nsns.set_context(\"talk\")\n\n4plt.rcParams['figure.figsize']      = (8, 3.5)\nplt.rcParams['font.size']           = 12\nplt.rcParams['axes.labelsize']      = 12\nplt.rcParams['axes.titlesize']      = 12\nplt.rcParams['xtick.labelsize']     = 8\nplt.rcParams['ytick.labelsize']     = 8\nplt.rcParams['legend.fontsize']     = 8\nplt.rcParams['figure.titlesize']    = 12\nplt.rcParams['grid.color']          = (0.5, 0.5, 0.5, 0.1)\nplt.rcParams['axes.spines.top']     = False\nplt.rcParams['axes.spines.right']   = False\nplt.rcParams['axes.spines.left']    = False\nplt.rcParams['axes.spines.bottom']  = False\n\n5red_pink   = \"#e64173\"\nturquoise  = \"#20B2AA\"\norange     = \"#FFA500\"\nred        = \"#fb6107\"\nblue       = \"#181485\"\nnavy       = \"#150E37FF\"\ngreen      = \"#8bb174\"\nyellow     = \"#D8BD44\"\npurple     = \"#6A5ACD\"\nslate      = \"#314f4f\"\n\n1\n\nЦі бібліотеки використовуються для статистичних обчислень, візуалізації та роботи з даними.\n\n2\n\nВстановлюємо випадкове зерно для відтворюваності результатів.\n\n3\n\nНалаштовуємо стиль графіків для кращої візуалізації.\n\n4\n\nНалаштовуємо параметри графіків для кращої візуалізації.\n\n5\n\nВизначаємо кольори для графіків.\n\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Вступ",
    "section": "",
    "text": "Статистика — це не просто набір формул чи методів. Це мова, якою ми говоримо про невизначеність, про вибірки, про те, що можна сказати про ціле, спостерігаючи лише частину. Зрештою, це інструмент, який допомагає ухвалювати рішення в умовах, коли 100% впевненості немає — й, чесно кажучи, рідко коли буває.\nУ цьому посібнику ми пройдемо шлях від базових понять (що таке генеральна сукупність й вибірка, як формулюються гіпотези) до застосування складніших методів, таких як \\(t\\)-критерій Стьюдента, \\(Z\\)-критерій Фішера і моделювання Монте-Карло.\nМи навмисно зосередилися на невеликій, але потужній добірці тем, які дозволяють:\n\nзрозуміти логіку перевірки гіпотез;\nінтерпретувати \\(p\\)-значення;\nоцінювати потужність дослідження та мінімальний ефект;\nбудувати довірчі інтервали;\nі, найголовніше, — робити це все в Python.\n\nЦе практичний посібник. Підкріплений кодом, прикладами і поясненнями. Він не охоплює всю статистику (та й хто б це зміг!), але дає міцну базу і навички, які можна використовувати прямо зараз.\nПочнемо з простого — але вже з першої сторінки будемо робити справжню статистику.\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "Вступ"
    ]
  },
  {
    "objectID": "binom.html",
    "href": "binom.html",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "1.1 Генеральна сукупність та вибірка\nВи вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.\nПроте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.\nЩоб це перевірити, ви проводите експеримент: залучаєте 30 нових студентів. 20 із них проходять курс й оплачують доступ, а 11 відмовляються. 20 — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?\nРозв’язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають генеральною сукупністю. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як \\(\\mu\\). Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та досліджувати результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо вибірку з генеральної сукупності та аналізуємо частку успішних випадків.\nЗгідно з результатами нашого експерименту, спостережувана ймовірність оплати становить \\(\\hat{\\mu} = 20/30 = 0.67\\)1. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?\nРозгляньмо, чому отримане значення може не бути переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює \\(\\mu = 0.5\\), і змоделюємо можливі результати для 30 студентів.\nДавайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для 30 спроб:\n1rng = np.random.default_rng(seed=18)\n\n2n = 30\n3results = rng.integers(0, 1, size = 30, endpoint = True)\n4success = np.sum(results) / n\n\n5print(f\"Кількість успішних випадків: {round(success, 3) * 100}%\")\n\n\n1\n\nІніціалізуємо генератор випадкових чисел з фіксованим seed.\n\n2\n\nКількість студентів.\n\n3\n\nГенеруємо випадкові числа для кожного студента.\n\n4\n\nОбчислюємо частку успішних випадків.\n\n5\n\nВиводимо результат.\n\n\n\n\nКількість успішних випадків: 70.0%\nМи бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.\nТому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення \\(\\mu\\) у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#sec-population",
    "href": "binom.html#sec-population",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "Якщо монетка випаде орлом, студент оплачує доступ.\nЯкщо монетка випаде решкою, студент відмовляється від курсу.\nВикористаємо метод integers()2 до класу Generator, яка генерує випадкові цілі числа в заданому діапазоні.\nПідкинемо монетку 30 разів та порахуємо кількість успішних випадків.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-гіпотези",
    "href": "binom.html#статистичні-гіпотези",
    "title": "1  Біноміальний критерій",
    "section": "1.2 Статистичні гіпотези",
    "text": "1.2 Статистичні гіпотези\n\n1.2.1 Постановка задачі\nМи з’ясували, що навіть за ймовірності \\(\\mu = 0.5\\) можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали seed для отримання такого результату. Якщо повторити цей експеримент з іншим значенням seed або збільшити кількість спостережень, результат може виявитися іншим.\n\n\n\n\n\n\nПорада\n\n\n\nСпробуйте змінити seed (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.\n\n\nТож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту статистично значущими необхідно отримати відповідь на питання:\n\nЧи можна вважати, що спостережуване значення \\(\\hat{\\mu}\\) є більшим від \\(\\mu = 0.5\\)?\n\nЗвернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину \\(\\xi\\), яка підпорядковується розподілу Бернуллі3. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.\n\\[\n\\xi \\sim \\text{Bernoulli}(\\mu)\n\\]\nде \\(\\mu\\) — ймовірність успіху.\nНас цікавить підтвердження того, що \\(\\mu &gt; 0.5\\). У статистиці для перевірки гіпотез розглядають дві можливості:\n\nНульова гіпотеза (\\(H_0\\)) формулюється як твердження, яке ми прагнемо спростувати.\nАльтернативна гіпотеза (\\(H_1\\)) висловлює припущення, яке ми хочемо довести.\n\nСкорочено це записують як:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 0.5 \\\\\nH_1 &: \\mu &gt; 0.5\n\\end{aligned}\n\\]\nЗауважимо, що якщо в нашому експерименті з 30 студентами можна дивитися не на частку успіхів, а на їх кількість.\nТоді питання можна переформулювати так:\n\nЗа умови вірності \\(H_0\\) наскільки ймовірно отримати 20 або більше успішних випадків з 30?\n\nЯкщо ми проводимо \\(n\\) незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу4.\n\\[\nS_n = \\sum_{i=1}^{n} \\xi_i \\sim \\text{Binomial}(n, \\mu)\n\\]\nде \\(\\xi_i\\) — випадкова величина, яка показує успіх у \\(i\\)-му спостереженні, \\(S_n\\) — кількість успішних випадків у \\(n\\) спостереженнях, \\(n\\) — кількість спостережень, \\(\\mu\\) — ймовірність успіху.\nДавайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\).\n\n\n\n1n = 30\n2mu = 0.5\n\n3x = np.arange(0, n + 1)\n4y = binom.pmf(x, n, mu)\n\n5plt.bar(x, y, color=turquoise)\n6plt.bar(x[x &gt;= 20], y[x &gt;= 20], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nКількість студентів.\n\n2\n\nЙмовірність успіху.\n\n3\n\nСтворюємо масив з усіма можливими значеннями кількості успішних випадків.\n\n4\n\nОбчислюємо ймовірності для кожної кількості успішних випадків.\n\n5\n\nСтворюємо гістограму з ймовірностями.\n\n6\n\nВиділяємо ймовірності для кількості успішних випадків, які є більшими або рівними 20.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.1: Візуалізація функції щільності ймовірностей для біноміального розподілу\n\n\n\n\n\nЦіановим5 кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює 20.\n\n\n1.2.2 Критерій\nЩойно ми розробили алгоритм, який на основі вибірки \\(\\xi\\) або визнає наявність доказів на користь \\(H_1\\), або повідомляє, що таких доказів немає. Відповідно, він або відхиляє \\(H_0\\), або не відхиляє її.\nТакий алгоритм називається критерієм. Його можна подати у вигляді функції \\(S\\), яка приймає реалізацію вибірки та повертає \\(1\\), якщо слід відхилити \\(H_0\\), та \\(0\\) в іншому випадку.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо відхиляємо } H_0 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nДавайте припустимо, що ми вирішили відхилити \\(H_0\\), якщо кількість успішних випадків перевищує або дорівнює 21. Тоді критерій набуде вигляду:\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо } \\sum \\xi_i \\geqslant 21 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nЗазвичай скорочують запис і пишуть просто правило, за яким відхиляємо \\(H_0\\)\n\\[\nS = \\{\\sum \\xi_i \\geqslant 21\\}\n\\]\nПозначимо \\(Q = \\sum \\xi_i\\), \\(C = 21\\), тоді критерій набуває вигляду:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}\n\\tag{1.1}\\]\nТак влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. \\(Q\\) називається статистикою критерію, \\(C\\) — критичним значенням.\n\\(Q\\) може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх \\(\\xi_i\\). Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.\n\n\n1.2.3 Критична область\nЗнову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію \\(S\\):\n\nНаскільки часто може бути таке, що за справедливості \\(H_0\\) критерій \\(S\\) відхиляє гіпотезу?\n\nВідповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним 21, побачивши на картинці, що великі відхилення відбуваються при \\(H_0\\) рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення \\(C\\), виходячи з частоти помилок нашого критерію.\nВибираючи \\(C\\), ми можемо або часто відхиляти нульову гіпотезу, коли \\(C\\) мале, або можемо робити це рідше, коли \\(C\\) велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.\n\n\\(C = 16\\). Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із 30, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає \\(1\\), тобто це помилка хибно позитивна (false positive, FP).\n\\(C = 29\\). У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб’ємося цього. Не відхилити гіпотезу \\(H_0\\), коли вона неправильна — це теж помилка. Вона називається хибно негативна (false negative, FN), оскільки критерій повернув 0 помилково.\n\n\\[\n\\text{FP} - H_0 \\text{відхиляється, коли вона вірна}\n\\]\n\\[\n\\text{FN} - H_0 \\text{не відхиляється, коли вона не вірна}\n\\]\nУ нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.\nТому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж частота хибнопозитивних спрацьовувань (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності \\(H_0\\).\nТепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.\n\nЯкий FPR у критерію \\(S\\) для перевірки гіпотези \\(H_0\\) проти \\(H_1\\)?\n\nКоли \\(H_0\\) є вірною, щоб порахувати кількість успіхів ми проводили 30 разів підкидання монетки з ймовірністю орла \\(0.5\\). Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при \\(\\mu = 0.5\\) наша статистика має біноміальний розподіл \\(Q \\sim Binom(0.5, 30)\\).\nОбчислимо FPR для \\(C = 21\\)\n\\[\n\\begin{aligned}\nFPR &= P(S(\\xi) = 1\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ \\mu = 0.5) = \\\\\n&= P(Q \\geqslant 21\\ |\\ Q \\sim Binom(0.5, 30))\n\\end{aligned}\n\\]\nЦе вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.\n\n\n1.2.4 Обчислення FPR\nДавайте порахуємо суму ймовірностей для кількостей успіхів від 21 до 30 включно. Покажемо графічно, як це виглядає на Рисунку 1.2.\n\n\n\n1x = np.arange(0, n + 1)\n2y = binom.pmf(x, n, 0.5)\n\nfig, ax = plt.subplots(figsize=(8, 3))\n3plt.bar(x, y, color=turquoise)\n4plt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink)\n5for i in range(crit_subs - 2, crit_subs + 4):\n    plt.text(i + 0.5, y[i] + 0.001, f\"{round(y[i] * 100, 1)}%\",\n    ha='center', va='bottom', size=8, rotation = 30)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nСтворюємо масив з усіма можливими значеннями кількості успішних випадків.\n\n2\n\nОбчислюємо ймовірності для кожної кількості успішних випадків.\n\n3\n\nСтворюємо гістограму з ймовірностями.\n\n4\n\nВиділяємо ймовірності для кількості успішних випадків, яка є більшою або рівною 21.\n\n5\n\nДодаємо текст до гістограми.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.2: Ймовірність хибно відхилити \\(H_0\\) за умови її вірності\n\n\n\n\n\nЗалишається лише обчислити суму ймовірностей для кількостей успіхів від 21 до 30 включно. Це і буде нашим FPR.\n\\[\nFPR_{21} = \\sum_{i = 21}^{30} P(Q = i) \\approx 0.021\n\\]\nУ нашому випадку це буде 2.1%. Якщо FPR не перевищує деякої константи \\(\\alpha\\), то критерій називається критерієм рівня значущості \\(\\alpha\\). Статистичний критерій з \\(\\alpha\\) = 100% створити тривіально — достатньо завжди відхиляти \\(H_0\\) — тому така постановка не має сенсу.\nРівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть \\(\\alpha = 0.05\\), але якщо потрібне більш точне ухвалення рішення, можуть вибрати \\(0.01\\), \\(0.005\\), \\(0.001\\). Якщо ж рішення не таке критичне, можуть вибрати \\(0.1\\).\nПрипустимо, вибрали значення \\(\\alpha = 0.05\\), скористаємося критерієм \\(S\\): тобто якщо кількість успішних випадків перевищує або дорівнює 21, то відхиляємо \\(H_0\\).\nЯкщо уважно подивитись на Рисунок 1.2, то можна помітити, що ми можемо відхиляти \\(H_0\\) при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати \\(\\alpha = 0.05\\):\n\\[\nFPR_{20} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.049\n\\]\nЯкщо ж обрати 19, то FPR буде більше \\(\\alpha\\): \\[\nFPR_{19} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.1002\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-функції-в-python",
    "href": "binom.html#статистичні-функції-в-python",
    "title": "1  Біноміальний критерій",
    "section": "1.3 Статистичні функції в Python",
    "text": "1.3 Статистичні функції в Python\nУ цій частині подивимося, як вивести те, що ми отримали в частині 2, за допомогою Python. А також зрозуміємо, як знайти відповідне \\(C\\) за допомогою Python.\n\n1.3.1 Біноміальний розподіл\nМи з’ясували, що статистика \\(Q\\) має біноміальний розподіл.\nБіноміальний розподіл \\(Binom(n, \\mu)\\) — розподіл кількості успіхів у послідовності з \\(n\\) незалежних випадкових експериментів, ймовірність успіху в кожному з яких дорівнює \\(\\mu\\).\nЩоб працювати з розподілом, можна створити об’єкт-розподіл за допомогою бібліотеки scipy.stats.\n\n\n\nfrom scipy.stats import binom\n\n1n = 30\n2mu = 0.5\n\n3binom_dist = binom(n, mu)\n\n\n1\n\nКількість спостережень.\n\n2\n\nЙмовірність успіху.\n\n3\n\nСтворюємо об’єкт біноміального розподілу.\n\n\n\n\n\n\n1.3.2 Функція ймовірностей\nФункція ймовірності дискретного розподілу \\(p_\\xi(x)\\) — ймовірність, з якою \\(\\xi\\) приймає значення \\(x\\).\nУ Python це функція pmf (probability mass function).\n\n\n\nresult = binom_dist.pmf(20)\nprint(f\"Ймовірність отримати 20 успішних випадків: {result:.4f}\")\n\nЙмовірність отримати 20 успішних випадків: 0.0280\n\n\n\n\nЗобразимо розподіл статистики \\(Q\\) за справедливості \\(H_0\\) на графіку. Для цього можна передати відразу масив точок, для яких треба розрахувати ймовірність.\n\n\n\n1x = np.arange(0, n + 1)\n2y = binom_dist.pmf(x)\n\n3crit_subs = 21\n\nfig, ax = plt.subplots(figsize=(8, 2.5))\n4plt.bar(x, y, color=turquoise, label=\"Ймовірність успіхів\")\n5plt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs],\n        color=red_pink, label=\"Критичне значення\")\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n1\n\nМасив точок.\n\n2\n\nРозрахунок ймовірностей.\n\n3\n\nКритичне значення.\n\n4\n\nЙмовірність успіхів.\n\n5\n\nКритичне значення.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.3: Функція щільності ймовірностей біноміального розподілу\n\n\n\n\n\nНасправді вже зараз ми можемо порахувати ймовірність потрапляння в критичну область. Потрібно просто підсумувати ймовірності для кількостей успіхів від 21 до 30.\n\n\n\nresult = np.sum(y[crit_subs:])\nprint(f\"Ймовірність потрапляння в критичну область: {result:.4f}\")\n\nЙмовірність потрапляння в критичну область: 0.0214\n\n\n\n\nОтже, ми дійсно побудували критерій рівня значущості \\(\\alpha = 0.05\\). Ба більше, це критерій рівня значущості 0.021.\nА що якби ми взяли \\(C = 19\\)?\n\n\n\ncrit_subs = 19\nresult = np.sum(y[crit_subs:])\nprint(f\"Ймовірність потрапляння в критичну область: {result:.4f}\")\n\nЙмовірність потрапляння в критичну область: 0.1002\n\n\n\n\nТоді ймовірність помилки вже навіть більше \\(10\\%\\), що зовсім нам не підходить.\nА якщо \\(C = 20\\)?\n\n\n\ncrit_subs = 20\nresult = np.sum(y[crit_subs:])\nprint(f\"Ймовірність потрапляння в критичну область: {result:.4f}\")\n\nЙмовірність потрапляння в критичну область: 0.0494\n\n\n\n\nВидно, що немає такого \\(C\\), щоб FPR був рівно \\(5\\%\\).\n\n\n1.3.3 Кумулятивна функція розподілу\nКумулятивна функція розподілу задається формулою:\n\\[\nF_\\xi(x) = P(\\xi \\leqslant x)\n\\tag{1.2}\\]\nУ Python це метод cdf() (Cumulative Distribution Function).\n\n\n\nresult = binom_dist.cdf(19)\nprint(f\"Ймовірність отримати 19 або менше успішних випадків: {result:.4f}\")\n\nЙмовірність отримати 19 або менше успішних випадків: 0.9506\n\n\n\n\nА оскільки \\(P(\\xi \\leqslant 19) + P(\\xi \\geqslant 20) = 1\\), можемо обчислити рівень значущості нашого критерію.\n\n\n\nresult = 1 - binom_dist.cdf(19)\nprint(f\"Ймовірність потрапляння в критичну область: {result:.4f}\")\n\nЙмовірність потрапляння в критичну область: 0.0494\n\n\n\n\n\n\n1.3.4 Квантиль\nЩоб вибрати критичну область для критерію, ми хотіли б знайти точку, площа стовпців праворуч від якої була б \\(5\\%\\). Тобто площа стовпців зліва — \\(95\\%\\). Така точка називається квантилью.\n\\[\nu_p(\\xi) = \\{x\\ | F_\\xi(x) = p\\}\n\\tag{1.3}\\]\nАле при \\(p = 0.95\\) й нашому біноміальному розподілі, такої точки немає. Ми з’ясували, що є точка, праворуч від якої площа \\(0.494\\), а в наступної вже \\(0.1\\). Щоб визначити квантиль у цьому випадку, модифікуємо визначення. Квантиль \\(u_p(\\xi)\\) — величина, яку \\(\\xi\\) не перевищує з імовірністю хоча б \\(p\\). Тобто \\(F_\\xi(u_p) \\geqslant p\\).\n\\[\nu_p(\\xi) = min\\ \\{x\\ |\\ F_\\xi(x) \\geqslant p \\}\n\\tag{1.4}\\]\n\nПриклад 1.1 Для величини \\(\\xi \\sim Bin(30, 0.5)\\) порахуємо 0.95-квантиль. Вирішимо задачу просто підбором.\n\\[\nP(\\xi \\leqslant 18) \\approx 0.90\n\\]\n\\[\nP(\\xi \\leqslant 19) \\approx 0.951\n\\]\n\\[\nP(\\xi \\leqslant 20) \\approx 0.97\n\\]\nБачимо, що 18 нам ще не підходить, а 19 й більші значення вже підійдуть. У них функція розподілу буде більшою за \\(p\\). Відповідь — найменше відповідне значення, тобто 19. При цьому немає точки, де функція розподілу дорівнювала б \\(p\\) в точності.\nЯкби розподіл був неперервним, можна було б сказати, що квантиль — це таке \\(x\\), на якому функція розподілу дорівнює \\(p\\). Але для дискретного розподілу такого може не бути.\n\nУ Python квантиль можна порахувати через методу ppf() (Percent Point Function).\n\n\n\nresult = binom_dist.ppf(0.95)\nprint(f\"0.95-квантиль: {result}\")\n\n0.95-квантиль: 19.0\n\n\n\n\nЯк тепер підібрати \\(C\\) для будь-яких \\(n, \\mu\\) й для будь-якого рівня значущості \\(\\alpha\\)?\n\nПотрібно знайти \\(C\\), таке що \\(P(Q \\geqslant C) \\leqslant \\alpha\\)\nТобто потрібно \\(P(Q &lt; C) \\geqslant 1 - \\alpha\\)\n\\(Q\\) приймає тільки цілі значення: \\(P(Q \\leqslant C - 1) \\geqslant 1 - \\alpha\\), або \\(F(C - 1) \\geqslant 1 - \\alpha\\)\nОтже, з визначення квантилі, \\(C - 1 = u_{1 - \\alpha}\\)\nЗначить \\(C = u_{1 - \\alpha} + 1\\)\n\n\n\n\n1def find_crit_subs(n, mu, alpha):\n    \"\"\"\n    Знаходить критичне значення для біноміального розподілу.\n\n    n: кількість спостережень\n    mu: ймовірність успіху\n    alpha: рівень значущості\n    \"\"\"\n2    binom_dist = binom(n, mu)\n3    return binom_dist.ppf(1 - alpha) + 1\n\n\nresult = find_crit_subs(30, 0.5, 0.05)\nprint(f\"Критичне значення для n = 30, mu = 0.5, alpha = 0.05: {result}\")\n\n\n1\n\nФункція, що приймає кількість спостережень, ймовірність успіху та рівень значущості.\n\n2\n\nСтворюємо об’єкт біноміального розподілу.\n\n3\n\nПовертаємо критичне значення.\n\n\n\n\nКритичне значення для n = 30, mu = 0.5, alpha = 0.05: 20.0\n\n\n\n\nКритичне значення \\(20\\), отже підсумковий критерій має такий вигляд:\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\n\\(Q = 19\\), значить гіпотезу ми не відкидаємо.\nПри цьому нам вдалося побудувати процес, за яким ми ухвалюємо рішення для будь-якого рівня значущості та значення статистики критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#p-значення",
    "href": "binom.html#p-значення",
    "title": "1  Біноміальний критерій",
    "section": "1.4 \\(p\\)-значення",
    "text": "1.4 \\(p\\)-значення\nЗауважимо, що зараз, якщо нам зададуть іншу \\(\\alpha\\), нам доведеться перебудовувати критерій заново. Це не зовсім зручно. У статистиці є механізм \\(p\\)-значення, який дає змогу прийняти рішення для всіх \\(\\alpha\\) відразу.\n\n1.4.1 Більш екстремальні значення\nПрипустимо, ми провели експеримент й порахували для критерію його статистику \\(Q(\\xi)\\). Позначимо отримане значення \\(q\\), у поточній задачі це \\(q = 19\\). Якби кількість успішних підписок була більшою, це б сильніше свідчило на користь альтернативної гіпотези \\(H_1\\). Тобто в разі значення \\(25\\) ми були б ще сильніше впевнені в тому, що наш бізнес буде окупатися. Тоді значення \\(25\\) називається більш екстремальним, ніж значення \\(19\\). У нашій задачі більш екстремальним із двох значень є те, яке більше.\nВизначимо поняття екстремальності формально:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}:\\ t\\ \\text{екстремальніше}\\ q \\Leftrightarrow t &gt; q\n\\tag{1.5}\\]\nНайчастіше критерії інших видів можна привести до цього, тоді для них теж визначено поняття екстремальності.\n\n\n1.4.2 \\(p\\)-значення\np-value — це ймовірність отримати таке або більш екстремальне значення статистики \\(q\\) за умови вірності \\(H_0\\).\n\\[\nP_{H_0}(Q \\geqslant q)\n\\tag{1.6}\\]\n\n\n\n\n\n\n\n\nРисунок 1.4: \\(p\\)-значення для критерію \\(Q = 15\\)\n\n\n\n\n\nТепер виведемо формулу через функції Python:\n\\[\nP_{H_0}(Q \\geqslant q) = 1 - P_{H_0}(Q &lt; q) = 1 - F(q)\n\\tag{1.7}\\]\nЗобразимо на графіку область більш екстремальних значень й p-value для різних значень статистики.\n\n\n\n\n\n\n\n\nРисунок 1.5: \\(p\\)-значення для критерію \\(Q = 10, 19, 20, 25\\)\n\n\n\n\n\nМожна побачити, що в критичній області \\(p\\)-значення \\(\\leqslant \\alpha\\), а поза нею \\(p\\)-значення \\(&gt; \\alpha\\). Саме таке правило й використовується для прийняття рішення.\n\\[\nH_0 \\text{ відкидається } \\Leftrightarrow p\\text{-значення} \\leqslant \\alpha\n\\tag{1.8}\\]\nПричому за \\(p\\)-значення одразу видно, що якби в нашу критичну область включили значення \\(19\\), наш критерій допускав би FPR у \\(10\\%\\) випадків, що вже неприпустимо. Тому й гіпотезу ми не відкидаємо.\nЗауважимо, що для обчислення \\(p\\)-значення не знадобилося знання \\(\\alpha\\), а потрібна була тільки статистика й форма критерію.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#двосторонні-критерії",
    "href": "binom.html#двосторонні-критерії",
    "title": "1  Біноміальний критерій",
    "section": "1.5 Двосторонні критерії",
    "text": "1.5 Двосторонні критерії\nДо цього моменту нас цікавили відхилення від ймовірності в \\(50\\%\\) тільки в один бік. І логічно, адже це продиктовано бізнесом. Тільки велика частка успішних підписок призведе до успіху. І зазвичай при прийнятті рішень так й буває. При тестуванні нового рішення або продукту розглядають альтернативну гіпотезу тільки в бік поліпшення, тому що в іншому разі немає сенсу впроваджувати рішення на всіх користувачів.\nОднак іноді може знадобитися доводити відхилення в обидва боки, якщо ви перевіряєте якесь припущення. Нехай вам дали монетку й просять перевірити, чесна вона чи ні. Монетка чесна, якщо під час підкидання ймовірність випадання орла дорівнює \\(0.5\\). Ви підкидаєте монетку \\(30\\) разів, кожен кидок — бернуллівська величина, аналогічно завданню з сервісом освітніх послуг. Нульова гіпотеза та ж сама: \\(\\mu = 0.5\\). Але тепер ми хочемо відкидати цю гіпотезу як у разі великої ймовірності орла, так і в разі маленької, відповідно перевіряємо двосторонню гіпотезу.\n\\[\nH_0: \\mu = 0.5\n\\]\n\\[\nH_1: \\mu \\neq 0.5\n\\]\nВиберемо критичну область для критерію за такої альтернативи. Скористаємося тією ж статистикою \\(Q(\\xi) = \\sum \\xi_i\\). Тільки тепер відхилення в кожну сторону однаково важливі. Відкидати гіпотезу будемо не тільки на досить великих значеннях, а й на досить маленьких. Наприклад, якщо у нас було всього \\(2\\) орла з \\(30\\) — це свідчення на користь того, що \\(\\mu \\neq 0.5\\), але не на користь \\(\\mu &gt; 0.5\\).\nОскільки відхилення в різні боки однаково важливі, а розподіл симетричний, шукати критерій можна в такому вигляді:\n\\[\nS = \\{Q \\geqslant C\\} \\cup \\{Q \\leqslant n - C\\}\n\\tag{1.9}\\]\n\n1.5.1 Як вибрати критичну область\nДля двостороннього критерію потрібно вибрати таку область, щоб ймовірність потрапляння в неї була \\(\\alpha\\). Тобто\n\\[\nP_{H_0}(Q \\geqslant C) + P_{H_0}(Q \\leqslant n - C) = \\alpha\n\\tag{1.10}\\] Але оскільки розподіл симетричний, то \\[\nP_{H_0}(Q \\geqslant C) = P_{H_0}(Q \\leqslant n - C) = \\frac{\\alpha}{2}\n\\tag{1.11}\\]\nПодивимося, який вигляд матиме критична область у такому разі. Для цього зобразимо функцію ймовірностей біноміального розподілу, а також критичну область.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.6: Двостороння критична область для критерію \\(С = 6\\)\n\n\n\n\n\nЗ картинки видно, що якщо тепер відкидати відхилення за \\(Q \\geqslant 20\\), то необхідно відкидати й \\(Q \\leqslant 10\\), а отже, загальна площа стовпців буде вже приблизно \\(0.1\\). Тому за рівня значущості \\(0.05\\) й \\(20\\) успіхів гіпотеза вже не відкинеться.\nЯкщо ж виставити \\(C = 6\\), то така область уже підходить, площа стовпців \\(\\approx 0.043 &lt; 0.05\\).\nЩоб вибрати порогову константу за формулою, можна помітити, що критична область симетрична, а значить праворуч площа не повинна бути більшою, ніж \\(\\frac{\\alpha}{2}\\). А таку задачу ми вже вміємо розв’язувати.\nРеалізуємо функцію на Python.\n\n\n\n1def find_crit_subs_two_sided(n, mu, alpha):\n    \"\"\"\n    Знаходить критичне значення для двостороннього біноміального розподілу.\n\n    n: кількість спостережень\n    mu: ймовірність успіху\n    alpha: рівень значущості\n    \"\"\"\n2    binom_dist = binom(n, mu)\n3    return n / 2 - binom_dist.ppf(alpha / 2) + 1\n\nresult = find_crit_subs_two_sided(30, 0.5, 0.05)\nprint(f\"Критичне значення для n = 30, mu = 0.5, alpha = 0.05: {result}\")\n\n\n1\n\nФункція для знаходження критичного значення.\n\n2\n\nСтворюємо об’єкт біноміального розподілу.\n\n3\n\nЗнаходимо критичне значення.\n\n\n\n\nКритичне значення для n = 30, mu = 0.5, alpha = 0.05: 6.0\n\n\n\n\n1.5.2 Як знайти \\(p\\)-значення\nКритерій має вигляд\n\\[\nS = \\{|Q(\\xi) - 15| \\geqslant C\\}\n\\]\nПозначимо відхилення суми від 15 як \\(\\Delta(\\xi) = |Q(\\xi) - 15|\\), тоді ми маємо критерій\n\\[\nS = \\{\\Delta(\\xi) \\geqslant C\\}\n\\tag{1.12}\\]\nТобто більш екстремальними вважатимуться ті значення суми, що знаходяться далі від 15. Щоб обчислити \\(p\\)-значення, доведеться порахувати суму площ із двох сторін окремо.\n\n\n\n1def pvalue_two_sided_sym(n, q):\n    \"\"\"\n    Обчислює p-значення для двостороннього біноміального розподілу.\n\n    n: кількість спостережень\n    q: значення статистики критерію\n    \"\"\"\n2    binom_h0 = binom(n=n, p=0.5)\n3    diff = np.abs(q - 15)\n4    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n5    left_sq = binom_h0.cdf(15 - diff)\n6    return left_sq + right_sq\n\nresult = pvalue_two_sided_sym(30, 21)\nprint(f\"p-значення для q = 21: {result:.4f}\")\n\n\n1\n\nФункція для обчислення \\(p\\)-значення.\n\n2\n\nСтворюємо об’єкт біноміального розподілу.\n\n3\n\nОбчислюємо відхилення від 15.\n\n4\n\nОбчислюємо праву площу.\n\n5\n\nОбчислюємо ліву площу.\n\n6\n\nПовертаємо суму площ.\n\n\n\n\np-значення для q = 21: 0.0428\n\n\n\n\nНасправді через симетричність розподілу ліва й права площа виходять однаковими, тому можна порахувати площу з одного боку й помножити на 2.\n\n\n\ndef pvalue_two_sided_sym_simple(n, q):\n    \"\"\"\n    Обчислює p-значення для двостороннього біноміального розподілу.\n\n    n: кількість спостережень\n    q: значення статистики критерію\n    \"\"\"\n    binom_h0 = binom(n=n, p=0.5)\n    diff = np.abs(q - 15)\n    right_sq = 1 - binom_h0.cdf(15 + diff - 1)\n    return 2 * right_sq\n\nresult = pvalue_two_sided_sym_simple(30, 21)\nprint(f\"p-значення для q = 21: {result:.4f}\")\n\np-значення для q = 21: 0.0428\n\n\n\n\nТепер навіть у разі \\(20\\) орлів \\(p\\)-значення \\(&gt; 0.05\\), тому відкидати будемо значення, починаючи з \\(21\\) й менші або такі, що дорівнюють \\(9\\).\n\n\n1.5.3 Випадок із несиметричним розподілом\nКоли розподіл за справедливості \\(H_0\\) несиметричний, відхилення від очікуваного значення в різні боки можуть бути по-різному критичними. Як приклад розглянемо також біноміальний розподіл, але з імовірністю успіху \\(0.8\\).\nТоді можна ліву і праву критичні області побудувати окремо, виділивши на них по \\(\\frac{\\alpha}{2}\\) площі. Праву область ми вже вміємо шукати, знайдемо ліву.\n\n\n\nfig, ax = plt.subplots(figsize=(8, 2.5))\n1binom_h0_nonsym = binom(n=30, p=0.8)\n2probs = binom_h0_nonsym.pmf(np.arange(31))\n\nplt.bar(np.arange(31), probs, color=turquoise, label=\"Binom(30, 0.8)\")\nplt.legend()\nplt.show()\n\n\n1\n\nСтворюємо об’єкт біноміального розподілу з ймовірністю успіху \\(0.8\\).\n\n2\n\nОбчислюємо ймовірності для всіх можливих значень.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.7: Біноміальний розподіл з імовірністю успіху \\(0.8\\)\n\n\n\n\n\nДля того, щоб побудувати двосторонній критерій, потрібно знайти ліворуч і праворуч області, площа яких становить не більше, ніж \\(\\frac{\\alpha}{2}\\). Для правого боку ми вже розв’язували таку задачу, розв’яжемо для лівого.\nШукаємо \\(C\\), таке що\n\\[\nP(Q(\\xi) \\leqslant C) \\leqslant \\frac{\\alpha}{2}\n\\tag{1.13}\\]\nСпочатку знайдемо перше число, де ймовірність \\(\\geqslant \\frac{\\alpha}{2}\\). А це за визначенням \\(\\frac{\\alpha}{2}\\)-квантиль. Достатньо взяти попереднє число, і воно буде задовольняти нашій умові.\n\n\n\ndef two_sided_criterion_nonsym(n, mu, alpha):\n    \"\"\"\n    Знаходить критичні значення для двостороннього біноміального розподілу.\n\n    n: кількість спостережень\n    mu: ймовірність успіху\n    alpha: рівень значущості\n    \"\"\"\n    binom_h0 = binom(n=n, p=mu)\n    c2 = binom_h0.ppf(1 - alpha/2) + 1\n    c1 = binom_h0.ppf(alpha/2) - 1\n    return c1, c2\n\nresult = two_sided_criterion_nonsym(30, 0.8, 0.05)\nprint(f\"Критичні значення для n = 30, mu = 0.8, alpha = 0.05: {result}\")\n\nКритичні значення для n = 30, mu = 0.8, alpha = 0.05: (18.0, 29.0)\n\n\n\n\nОтже, наш критерій для перевірки гіпотези\n\\[\nH_0: \\mu = 0.8\n\\]\n\\[\nH_1: \\mu \\neq 0.8\n\\]\nмає вигляд\n\\[\nS = \\{Q(\\xi) \\leqslant 18\\} \\cup \\{Q(\\xi) \\geqslant 29\\}\n\\]\nТут межа \\(29\\) уже має логічний вигляд, бо треба спростувати 80% орлів/успіхів, а для цього потрібна велика їхня кількість.\nЗобразимо критичну область на графіку.\n\n\n\n1C1, C2 = two_sided_criterion_nonsym(30, 0.8, 0.05)\n\n2x = np.arange(31)\n\n3plt.bar(x, probs, color=turquoise, label=\"Binom(30, 0.8)\")\n4plt.bar(x[x &lt;= C1], probs[x &lt;= C1],\n        color=red_pink, label=\"Критичне значення\")\n5plt.bar(x[x &gt;= C2], probs[x &gt;= C2],\n        color=red_pink)\n        \nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.legend(loc = 'upper left')\nplt.show()\n\n\n1\n\nЗнаходимо критичні значення\n\n2\n\nСтворюємо масив значень для графіка.\n\n3\n\nБудуємо графік біноміального розподілу.\n\n4\n\nВідзначаємо ліву критичну область.\n\n5\n\nВідзначаємо праву критичну область.\n\n\n\n\n\n\n\n\n\n\nРисунок 1.8: Двостороння критична область для критерію \\(C_1 = 18, C_2 = 29\\)\n\n\n\n\n\n\n\n1.5.4 \\(p\\)-значення для несиметричного розподілу\nЦей критерій — об’єднання двох критеріїв рівня значущості \\(\\frac{\\alpha}{2}\\), для кожного з яких можна порахувати \\(p\\)-значення. Позначимо їх як \\(p_1, p_2\\). Перший критерій відкидається при \\(p_1 \\leqslant \\frac{\\alpha}{2}\\), другий при \\(p_2 \\leqslant \\frac{\\alpha}{2}\\). А наш об’єднаний, коли виконано одну з цих умов, тобто\n\\[\n2p_1 \\leqslant \\alpha \\vee 2p_2 \\leqslant \\alpha \\Leftrightarrow 2 \\cdot \\min(p_1, p_2) \\leqslant \\alpha\n\\tag{1.14}\\]\nОтже, можна рахувати \\(p\\)-значення як \\(2 \\min(p_1, p_2)\\) й порівнювати з \\(\\alpha\\).\nПроведемо аналогію із симетричним випадком: якщо сума опинилася в лівій частині, то потрібно порахувати \\(p\\)-значення лівого критерію і помножити на 2. Якщо сума опинилася в правій частині, то потрібно порахувати \\(p\\)-значення правого критерію і помножити на 2.\n\n\n\n1def pvalue_two_sided(n, q, mu=0.5):\n    \"\"\"\n    Обчислює p-значення для двостороннього біноміального розподілу.\n\n    n: кількість спостережень\n    q: значення статистики критерію\n    mu: ймовірність успіху\n    \"\"\"\n2    binom_h0 = binom(n=n, p=mu)\n3    pvalue_left = binom_h0.cdf(q)\n4    pvalue_right = 1 - binom_h0.cdf(q - 1)\n5    return 2 * min(pvalue_left, pvalue_right)\n\nresult = pvalue_two_sided(30, 28, 0.8)\nprint(f\"p-значення для q = 28: {result:.4f}\")\n\n\n1\n\nФункція для обчислення \\(p\\)-значення:\n\n2\n\nСтворюємо об’єкт біноміального розподілу.\n\n3\n\nОбчислюємо \\(p\\)-значення для лівого критерію.\n\n4\n\nОбчислюємо \\(p\\)-значення для правого критерію.\n\n5\n\nПовертаємо \\(p\\)-значення.\n\n\n\n\np-значення для q = 28: 0.0884\n\n\n\n\nВидно, що \\(p\\)-значення \\(&gt; 0.05\\), отже, на рівні значущості \\(0.05\\) навіть \\(28\\) успіхів недостатньо, щоб відкинути ймовірність успіху в \\(80\\%\\).\nЗауважимо, що ця ж функція працює і для симетричного випадку, повертаючи той самий результат.\n\n\n\nresult = pvalue_two_sided(n=30, q=20, mu=0.5)\nprint(f\"p-значення для q = 20: {result:.4f}\")\n\np-значення для q = 20: 0.0987\n\n\n\n\n\nresult = pvalue_two_sided_sym(n=30, q=20)\nprint(f\"p-значення для q = 20: {result:.4f}\")\n\np-значення для q = 20: 0.0987",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#sec-scipy",
    "href": "binom.html#sec-scipy",
    "title": "1  Біноміальний критерій",
    "section": "1.6 Готові функції",
    "text": "1.6 Готові функції\nЗвісно, можна використати готові функції з бібліотеки scipy. Для цього використаємо функцію binomtest, котра має параметри:\n\nk — кількість успіхів\nn — кількість спостережень\np — ймовірність успіху\nalternative — тип гіпотези:\n\ntwo-sided: двостороння\ngreater: правостороння\nless: лівостороння\n\n\n\n\n\n1from scipy.stats import binomtest\n\n2result = binomtest(19, 30, 0.5, alternative='two-sided')\n\n3print(f\"Статистика: {result.statistic:.2f}\")\nprint(f\"p-значення: {result.pvalue:.4f}\")\n\n\n1\n\nІмпортуємо функцію binomtest.\n\n2\n\nВикликаємо функцію з параметрами.\n\n3\n\nВиводимо статистику та \\(p\\)-значення.\n\n\n\n\nСтатистика: 0.63\np-значення: 0.2005",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#sec-questions-1",
    "href": "binom.html#sec-questions-1",
    "title": "1  Біноміальний критерій",
    "section": "1.7 Питання для самоперевірки",
    "text": "1.7 Питання для самоперевірки\nЗагальні поняття та постановка задачі:\n\nЩо таке генеральна сукупність та вибірка в контексті наведеного прикладу з онлайн-курсами?\nЩо позначають символи \\(\\mu\\) та \\(\\hat{\\mu}\\)? Яка між ними різниця?\nЧому спостережувана частка успіхів у вибірці (\\(\\hat{\\mu}\\)) може не точно відображати справжню частку (\\(\\mu\\)) в генеральній сукупності?\nЯкий розподіл ймовірностей описує результат для одного студента (успіх/невдача)?\nЯкий розподіл ймовірностей описує загальну кількість успішних випадків серед \\(n\\) студентів? Які параметри має цей розподіл?\n\nСтатистичні гіпотези та критерій:\n\nЩо таке нульова (\\(H_0\\)) та альтернативна (\\(H_1\\)) гіпотези? Сформулюйте їх для прикладу з онлайн-курсами.\nЩо таке статистичний критерій? Яка його мета?\nЩо таке статистика критерію (\\(Q\\)) та критичне значення (\\(C\\)) у контексті біноміального тесту?\nЩо таке критична область критерію?\n\nПомилки та рівень значущості:\n\nЯкі два типи помилок можливі при перевірці статистичних гіпотез? Опишіть їх (хибно позитивна та хибно негативна). Яка помилка була важливішою для інвесторів у прикладі?\nЩо таке рівень хибнопозитивних спрацьовувань (FPR)? Як він пов’язаний з нульовою гіпотезою?\nЩо таке рівень значущості (\\(\\alpha\\))? Як він використовується для вибору критичного значення (\\(C\\))?\nЯк розрахувати FPR для заданого критичного значення \\(C\\), використовуючи функцію щільності ймовірностей (PMF) біноміального розподілу?\n\nОбчислення в Python (scipy.stats):\n\nЯкі функції з scipy.stats.binom використовуються для обчислення:\n\nЙмовірності конкретної кількості успіхів (\\(P(Q=k)\\))?\nКумулятивної ймовірності (\\(P(Q \\le k)\\))?\nКвантиля розподілу?\n\nЯк можна знайти критичне значення \\(C\\) для правостороннього тесту (\\(H_1: \\mu &gt; \\mu_0\\)) з заданим рівнем значущості \\(\\alpha\\), використовуючи функцію квантиля (ppf)?\n\nP-значення:\n\nЩо таке p-значення (p-value)? Як воно інтерпретується?\nЯк визначається поняття “більш екстремального” значення статистики для правостороннього тесту?\nЯк розраховується p-значення для правостороннього біноміального тесту, знаючи спостережувану кількість успіхів \\(q\\)?\nЯке правило прийняття рішення щодо \\(H_0\\) використовується на основі p-значення та рівня значущості \\(\\alpha\\)?\nЯка перевага використання p-значення порівняно з визначенням критичної області?\n\nДвосторонні критерії:\n\nКоли використовують двосторонні критерії? Як формулюються гіпотези (\\(H_0\\) та \\(H_1\\)) для двостороннього тесту?\nЯк зазвичай визначається критична область для двостороннього критерію при симетричному розподілі (наприклад, \\(Binom(n, 0.5)\\))? Як рівень значущості \\(\\alpha\\) розподіляється між “хвостами”?\nЯк розраховується p-значення для двостороннього критерію при симетричному розподілі?\nЯк визначається критична область для двостороннього критерію, коли розподіл статистики при \\(H_0\\) є несиметричним (наприклад, \\(Binom(n, 0.8)\\))?\nЯк розраховується p-значення для двостороннього критерію при несиметричному розподілі?\n\nГотові функції:\n\nЯк можна виконати біноміальний тест (односторонній або двосторонній) за допомогою функції binomtest з бібліотеки scipy.stats? Які основні параметри вона приймає і що повертає?\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#footnotes",
    "href": "binom.html#footnotes",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "У статистиці \\(\\hat{\\mu}\\) позначається як оцінка параметра \\(\\mu\\).↩︎\nМетод integers() генерує випадкові цілі числа в заданому діапазоні. Аргумент endpoint вказує, що верхня межа включається у діапазон.↩︎\nРозподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.↩︎\nБіноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума \\(n\\) незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.↩︎\nАнгл. cyan, від грец. κυανouς — “блакитний”, “лазуровий”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "power.html",
    "href": "power.html",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1 Статистична потужність",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#sec-power",
    "href": "power.html#sec-power",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "",
    "text": "2.1.1 Хибно негативні помилки\nРаніше під час побудови критеріїв ми звертали увагу тільки на \\(\\alpha\\), рівень значущості критерію. Але цей параметр контролює лише хибнопозитивну помилку (False Positive), а саме ймовірність, що критерій прийме \\(H_1\\) за умови вірності \\(H_0\\).\nАле є ще один вид помилок, які може допустити критерій — хибно негативні помилки (False Negative). Це випадки, коли критерій приймає \\(H_0\\) за умови вірності \\(H_1\\). Це важливо, оскільки вони можуть вказувати на те, що критерій не чутливий до змін, які відбуваються в даних.\nВипадок, коли ймовірність FPR \\(&lt; \\alpha\\), але при цьому ймовірність хибно негативні помилки (False Negative Rate, FNR) величезна, можна навести легко. Для цього достатньо ніколи не відкидати гіпотезу, взявши критерій \\(S \\equiv 0\\).\nНаведемо приклад, коли помилки False Negative відбуваються не завжди, але критерії є все одно нечутливими.\n\n\n2.1.2 Критерій пори року\nПоставимо гіпотезу про те, що зараз на вулиці літо. Для перевірки можна було б, звісно, подивитися в календар, але ми зробимо інакше.\n\\[\nH_0: \\text{ на вулиці літо}\n\\]\n\\[\nH_1: \\text{ на вулиці не літо}\n\\]\nПодивимося у вікно і визначимо, чи йде там сніг. Якщо він йде, то це непоганий доказ того, що зараз не літо, а отже можна відкинути \\(H_0\\).\nПорахуємо FPR та FNR для цього критерію. Ми знаємо, що влітку сніг іде дуже рідко (ймовірність помилки нижча за \\(0.1\\%\\)), тож це точно критерій рівня значущості \\(0.001\\), чого зазвичай достатньо для критеріїв.\n\\[\n\\text{FPR}(S) = P(\\text{йде сніг}\\ |\\ \\text{сьогодні літо}) &lt; 0.001\n\\]\nАле що з FNR? Розглянемо конкретний випадок: зараз вересень. Оскільки у вересні майже завжди немає снігу, можна сказати, що FNR більша за \\(90\\%\\), отже, цей критерій насправді мало дієвий.\n\\[\n\\text{FPR}(S) = P(\\text{не йде сніг}\\ |\\ \\text{зараз вересень}) &gt; 0.9\n\\]\nСформулюємо інший критерій рівня значущості \\(\\alpha\\), причому в цьому разі рівень значущості можна вибрати довільним.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо монетка з імовірністю орла } \\alpha \\text{ випала орлом} \\\\\n    0, \\text{ інакше}\n\\end{cases}\n\\]\nВиходить, цей критерій випадковий, і він не використовує взагалі жодної інформації про погоду. Однак вимогам до рівня значущості він задовольняє.\n\\[\n\\text{FPR} = P(\\text{випав орел}\\ |\\ \\text{сьогодні літо}) = P(\\text{випав орел}) = \\alpha\n\\]\nОбчислимо FNR.\n\\[\n\\text{FNR} = P(\\text{не випав орел}\\ |\\ \\text{сьогодні не літо}) = P(\\text{не випав орел}) = 1 - \\alpha\n\\]\nЗа \\(\\alpha = 0.001\\), як у першому випадку, отримуємо ймовірність FNR \\(0.999 &gt; 0.9\\), тобто за однакового рівня значущості з першим критерієм, другий критерій частіше припускається хибно негативної помилки.\n\n\n2.1.3 Потужність\nУ статистиці заведено позитивним результатом вважати відкидання нульової гіпотези, бо зазвичай підтвердження альтернативи означає наявність бізнес-результату. Тому вважається хорошим критерій, який частіше дає змогу виявити бізнес-результат. І рахують тоді не ймовірність хибно негативної помилки, а потужність, що дорівнює ймовірності відкинути нульову гіпотезу за вірності \\(H_1\\), тобто ймовірність істинно позитивного результату (True Positive Rate, TPR).\n\\[\n\\text{Power}_S = 1 - FNR\n\\tag{2.1}\\]\nКоли альтернатива \\(H_1\\) складається з множини результатів, потужність розглядають як функцію від результату. Наприклад, можна порахувати потужність першого та другого критеріїв взимку й восени.\n\\[\n\\text{Power}_S(\\mu) = 1 - FNR(\\mu)\n\\tag{2.2}\\]\nПерший критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{їде сніг } | \\text{ травень}) \\approx 0.00001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{їде сніг } | \\text{ жовтень}) \\approx 0.1\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{їде сніг } | \\text{ січень}) \\approx 0.5\n\\]\nДругий критерій\n\\[\n\\text{Power}_S(\\text{травень}) = P(\\text{випав орел } | \\text{ травень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{жовтень}) = P(\\text{випав орел } | \\text{ жовтень}) = \\alpha = 0.001\n\\]\n\\[\n\\text{Power}_S(\\text{січень}) = P(\\text{випав орел } | \\text{ січень}) = \\alpha = 0.001\n\\]\nЗазвичай завдання пошуку найкращого критерію формулюється як пошук якомога потужнішого критерію за заданого рівня значущості \\(FPR \\leqslant \\alpha\\). Але ми сказали, що потужність — функція від параметра, у нашому випадку від місяця.\nЯкщо ми застосовуватимемо критерій у січні, то потужнішим буде перший критерій, а якщо в травні, то потужнішим буде другий критерій. Тому потрібно розуміти, коли буде застосовуватися критерій, а отже, ми шукаємо найпотужніший критерій у галузі, яка нас цікавить.\nХоча в реальності в травні потужність обох критеріїв настільки низька, що вони просто не приносять користі, й використовувати їх не має сенсу.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#потужність-для-біноміального-розподілу",
    "href": "power.html#потужність-для-біноміального-розподілу",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.2 Потужність для біноміального розподілу",
    "text": "2.2 Потужність для біноміального розподілу\nЗастосуємо нові знання про потужність для нашої задачі з освітнім сервісом. З бізнес-міркувань ми вже вибрали \\(\\alpha = 0.05\\), а отже, знаємо, що ми неправильно відкидаємо гіпотезу \\(H_0:\\ \\mu = 0.5\\) з ймовірністю не більше, ніж \\(5\\%\\). Тобто цим обмежена ймовірність хибно позитивної помилки.\nА з якою ймовірністю ми будемо правильно відкидати гіпотезу? І яка в нас буде ймовірність хибно негативної помилки? На це запитання якраз відповість формула потужності.\nЗгадаймо критерій, за яким ми приймаємо рішення:\n\\[\nQ(\\xi) = \\sum\\limits_{i=1}^n \\xi_i - \\text{кількість підписок}\n\\]\n\\[\nS = \\{Q \\geqslant 20\\}\n\\]\nТобто якщо отримуємо хоча б \\(20\\) успішних підписок, то відкидаємо \\({H}_0\\).\nЗауважимо, що потужність залежить від того, яке значення \\(\\mu\\) у нашій генеральній сукупності. Зафіксуємо спочатку параметр \\(\\mu = 0.6\\) й порахуємо потужність для нього. Якщо істинний параметр такий, то статистика \\(Q\\) має розподіл \\(Binom(30, 0.6)\\).\n\n\n\n1binom_h0 = binom(n=30, p=0.5)\n2binom_alternative = binom(n=30, p=0.6)\n\n3x_grid = np.arange(1, 31)\n4crit_reg = x_grid &gt;= 20\n\n5probs_h0 = binom_h0.pmf(x_grid)\n6plt.bar(x_grid, probs_h0, color=turquoise, label='PMF, $Binom(0.5, 30)$')\n\n7probs_alternative = binom_alternative.pmf(x_grid)\n8plt.bar(x_grid, probs_alternative, color=slate,\n        label='PMF, $Binom(0.6, 30)$')\n9plt.bar(x_grid[crit_reg], probs_alternative[crit_reg], color=red_pink,\n        label='Критична область')\n\nplt.legend()\nplt.show()\n\n\n1\n\nРозподіл нульової гіпотези\n\n2\n\nРозподіл альтернативної гіпотези\n\n3\n\nВибираємо значення для осі \\(x\\)\n\n4\n\nКритична область\n\n5\n\nОбчислюємо ймовірності для нульової гіпотези\n\n6\n\nБудуємо гістограму для нульової гіпотези\n\n7\n\nОбчислюємо ймовірності для альтернативної гіпотези\n\n8\n\nБудуємо гістограму для альтернативної гіпотези\n\n9\n\nБудуємо гістограму для критичної області\n\n\n\n\n\n\n\n\n\n\nРисунок 2.1: Потужність критерію для \\(\\mu = 0.6\\)\n\n\n\n\n\nЯк і раніше, нас цікавить імовірність отримати \\(20\\) або більше успіхів. Але якщо раніше ми дивилися на неї для розподілу з \\(\\mu=0.5\\) й хотіли, щоб вона була меншою за \\(5\\%\\), то тепер ми дивимося за \\(\\mu = 0.6\\) та прагнемо зробити цю величину якомога більшою. Порівняно з обчисленням FPR формула не зміниться, змінюється тільки \\(\\mu\\)\n\n\n\ncritical_value = 20\npower = 1 - binom(n=30, p=0.6).cdf(critical_value - 1)\nfpr   = 1 - binom(n=30, p=0.5).cdf(critical_value - 1)\n\nprint(f\"Хибно позитивна помилка: {fpr:.1%}\")\nprint(f\"Потужність: {power:.1%}\")\n\nХибно позитивна помилка: 4.9%\nПотужність: 29.1%\n\n\n\n\nВидно, що потужність близько \\(30\\%\\). Це досить маленьке значення, адже якщо наш продукт прибутковий, то ми побачимо це за допомогою нашого тесту тільки з імовірністю в \\(30\\) відсотків. Ми легко можемо пропустити ефект.\nЩо ж можна зробити, щоб зробити потужність вищою? Щоб розібратися, реалізуємо функцію потужності в загальному вигляді.\n\n\n\n1def get_stat_power(N, mu_h0, mu_alternative, alpha):\n    \"\"\"\n    Функція потужності для біноміального розподілу\n\n    N: розмір вибірки\n    mu_h0: ймовірність успіху в нульовій гіпотезі\n    mu_alternative: ймовірність успіху в альтернативній гіпотезі\n    alpha: рівень значущості\n    \"\"\"\n2    binom_h0 = binom(n=N, p=mu_h0)\n3    binom_alternative = binom(n=N, p=mu_alternative)\n4    critical_value = binom_h0.ppf(1 - alpha) + 1\n5    return 1 - binom_alternative.cdf(critical_value - 1)\n\nresult = get_stat_power(30, 0.5, 0.6, alpha=0.05)\nprint(f\"Потужність: {result:.1%}\")\n\n\n1\n\nФункція потужності:\n\n2\n\nРозподіл нульової гіпотези\n\n3\n\nРозподіл альтернативної гіпотези\n\n4\n\nКритичне значення\n\n5\n\nПовертаємо потужність\n\n\n\n\nПотужність: 29.1%\n\n\n\n\nКоли в житті ми спостерігаємо якесь явище і бачимо його лише кілька разів, ми не впевнені в тому, що воно не випадкове. Якщо ж бачимо його досить часто, то вже складаємо закономірності. Так і в статистиці. Коли ми подивилися на 30 потенційних підписок, ми помічаємо, що частка доставок більше половини. Але ми все ще не впевнені. Щоб отримати більше впевненості, потрібно провести більше спостережень, тобто знайти більше пробних клієнтів.\nПодивимося, що буде, якщо ми проведемо експеримент на 300 клієнтах.\n\n\n\nresult = get_stat_power(300, 0.5, 0.6, alpha=0.05)\nprint(f\"Потужність при N=300: {result:.1%}\")\n\nПотужність при N=300: 96.6%\n\n\n\n\nБачимо, що потужність уже дуже близька до \\(100\\%\\). Але провести 300 пробних занять набагато затратніше, ніж 30. І за ресурсами, і за часом. Тому зазвичай балансують між потужністю і тривалістю/витратами експерименту.\nПрийнято вважати, що прийнятною для роботи потужністю вважається \\(80\\%\\). Подивимося, як змінюється потужність при зростанні розміру вибірки, і скільки потрібно провести експериментів, щоб детектувати ефект при \\(\\mu = 0.6\\) у \\(80\\%\\) випадків.\n\n\n\n1n_grid = np.arange(10, 600, 10)\n2power = get_stat_power(n_grid, 0.5, 0.6, alpha=0.05)\n\n3plt.plot(n_grid, power, color=turquoise)\n4plt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\n5min_n = n_grid[power &gt;= 0.8].min()\n6plt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.xlabel('Кількість пробних занять')\nplt.ylabel('Потжність')\nplt.legend()\nplt.show()\n\n\n1\n\nВибираємо значення для осі \\(x\\)\n\n2\n\nОбчислюємо потужність для різних розмірів вибірки\n\n3\n\nБудуємо графік\n\n4\n\nДодаємо горизонтальну лінію для потужності \\(80\\%\\)\n\n5\n\nЗнаходимо мінімальну кількість пробних занять, щоб потужність була більшою за \\(80\\%\\)\n\n6\n\nДодаємо вертикальну лінію для мінімальної кількості пробних занять\n\n\n\n\n\n\n\n\n\n\nРисунок 2.2: Залежність потужності від розміру вибірки для \\(\\mu = 0.6\\)\n\n\n\n\n\nБачимо, що для потужності в \\(80\\%\\) достатньо набрати 160 пробних занять.\nА що, якщо ми хочемо детектувати ще менший ефект? Наприклад, якщо хочемо відкидати гіпотезу за \\(\\mu = 0.51\\). Часто поліпшення ймовірності успіху на \\(1\\%\\) може бути значущим для продукту, тому це питання не позбавлене сенсу.\n\n\n\n1n_grid = np.arange(10, 30000, 59)\n2power = get_stat_power(n_grid, 0.5, 0.51, alpha=0.05)\n\n3plt.plot(n_grid, power, color=turquoise)\n4plt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\n5min_n = n_grid[power &gt;= 0.8].min()\n6plt.axvline(min_n, ls='--', color=slate, label=f'N = {min_n}')\n\nplt.xlabel('Кількість пробних занять')\nplt.ylabel('Потжність')\nplt.legend()\nplt.show()\n\n\n1\n\nВибираємо значення для осі \\(x\\)\n\n2\n\nОбчислюємо потужність для різних розмірів вибірки\n\n3\n\nБудуємо графік\n\n4\n\nДодаємо горизонтальну лінію для потужності \\(80\\%\\)\n\n5\n\nЗнаходимо мінімальну кількість пробних занять, щоб потужність була більшою за \\(80\\%\\)\n\n6\n\nДодаємо вертикальну лінію для мінімальної кількості пробних занять\n\n\n\n\n\n\n\n\n\n\nРисунок 2.3: Залежність потужності від розміру вибірки для \\(\\mu = 0.51\\)\n\n\n\n\n\nБачимо, що потрібно понад 15 тисяч клієнтів, щоб детектувати такий ефект! Дуже складно знайти стільки пробних клієнтів. Але потрібно замислитися над питанням, а чи варто це робити? У нашому випадку, якщо ймовірність успіху \\(51\\%\\), то прибуток із замовлень буде невеликий, і вкладення інвесторів, звісно, окупатимуться, але дуже довго. Тому збільшення на \\(1%\\) для нашого завдання не значуще практично, а отже, не потрібно намагатися набирати 15 тисяч людей, а можна зупинитися і на 160.\nПеред кожним експериментом аналітику варто замислюватися над питанням тривалості тесту і кількості учасників. Для цього потрібно зрозуміти:\n\nЯкий ефект є для завдання практично значущим?\nСкільки знадобиться випробовуваних, щоб детектувати цей ефект частіше, ніж у \\(80\\%\\) випадків?\n\nЗ графіків видно, що для детектування меншого ефекту потрібен більший розмір вибірки. Подивимося, як для фіксованого \\(N=30\\) змінюється потужність для різних параметрів \\(\\mu\\).\n\n\n\n1mu_grid = np.linspace(0.5, 0.9, 100)\n2power = get_stat_power(30, 0.5, mu_grid, alpha=0.05)\n\n3plt.plot(mu_grid, power, color=turquoise)\n4plt.axhline(0.8, ls='--', color=red_pink, label='Потужність = 80%')\n\n5min_mu = mu_grid[power &gt;= 0.8].min()\n6plt.axvline(min_mu, ls='--', color=slate, label=f'$\\mu = {min_mu:.2f}$')\n\nplt.xlabel('Ймовірність успіху')\nplt.ylabel('Потужність')\nplt.legend()\nplt.show()\n\n\n1\n\nВибираємо значення для осі \\(x\\)\n\n2\n\nОбчислюємо потужність для різних параметрів \\(\\mu\\)\n\n3\n\nБудуємо графік\n\n4\n\nДодаємо горизонтальну лінію для потужності \\(80\\%\\)\n\n5\n\nЗнаходимо мінімальну ймовірність успіху, щоб потужність була більшою за \\(80\\%\\)\n\n6\n\nДодаємо вертикальну лінію для мінімальної ймовірності успіху\n\n\n\n\n\n\n\n\n\n\nРисунок 2.4: Залежність потужності від параметра \\(\\mu\\)\n\n\n\n\n\nУ нашому експерименті ми добре детектуємо ефект, тільки якщо ймовірність успіху в генеральній сукупності хоча б \\(72\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#мінімальна-величина-ефекту",
    "href": "power.html#мінімальна-величина-ефекту",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.3 Мінімальна величина ефекту",
    "text": "2.3 Мінімальна величина ефекту\nВище на Рисунок 2.4 ми побачили, що з хорошою потужністю понад \\(80\\%\\) ми можемо помітити ефект у \\(22\\) процентних пункти. Причому це можна порахувати навіть до проведення експерименту. У нашому випадку таке збільшення успішності щодо \\(0.5\\) цілком можливо, і з ним можна працювати. Але коли аналітики перевіряють зміни, найчастіше очікуваний ефект коливається в районі одного, максимум двох відсотків! Для подібних змін не підійде обрана постановка експерименту, а значить і проводити його не має сенсу.\nТому перед запуском експериментів аналітики повідомляють мінімальну величину ефекту, яку можна задетектувати (Minimal Detectable Effect, MDE). У нашому випадку \\(MDE = +22\\) процентних пункти.\nБільш формально, MDE для гіпотези \\(H_0: \\mu = \\mu_0\\) — це мінімальний ефект \\(\\delta\\), за якого критерій рівня значущості \\(\\alpha\\) для перевірки цієї гіпотези за істинного параметра \\(\\mu = \\mu_0 + \\delta\\) та розміру вибірки \\(N\\) відкидатиме \\({H}_0\\) з потужністю більшою, ніж \\(1 - \\beta\\).\nНайчастіше беруть \\(1 - \\beta = 80\\%\\). Напишемо функцію, яка обчислюватиме MDE підбором.\n\n\n\n1def binom_test_mde_one_sided(N, mu0, alpha=0.05, min_power=0.8):\n    \"\"\"\n    Розрахунок MDE для біноміального тесту\n\n    N: розмір вибірки\n    mu0: параметр нульової гіпотези\n    alpha: рівень значущості\n    min_power: мінімальна потужність\n    \"\"\"\n2    delta_grid = np.linspace(0, 1 - mu0, 500)\n3    power = get_stat_power(N, mu0, mu0 + delta_grid, alpha=alpha)\n4    fit_delta = delta_grid[power &gt;= min_power]\n5    return fit_delta[0]\n\nresult = binom_test_mde_one_sided(30, 0.5)\nprint(f\"MDE: {result:.1%}\")\n\n\n1\n\nФункція, яка обчислює MDE.\n\n2\n\nСтворюємо сітку для \\(\\delta\\)\n\n3\n\nОбчислюємо потужність для різних значень \\(\\delta\\)\n\n4\n\nЗнаходимо значення \\(\\delta\\), для яких потужність більша за \\(80\\%\\)\n\n5\n\nПовертаємо перше значення \\(\\delta\\), для якого потужність більша за \\(80\\%\\)\n\n\n\n\nMDE: 21.8%\n\n\n\n\nРезультат збігається з обчисленнями за графіком Рисунок 2.4. Тобто ми можемо детектувати ефект у \\(22\\) процентних пункти.\nЗазвичай MDE розраховують не просто так, а нерозривно з ним іде питання про визначення розміру вибірки.\nУ нашому завданні ми знайшли \\(30\\) клієнтів, не обчислюючи спочатку, скільки їх знадобиться. Але що якщо отриманий MDE занадто великий й потрібно зробити його меншим, оскільки очікувані зміни набагато менші? Тоді вирішується зворотне завдання, За необхідним MDE визначити обсяг вибірки. Якщо ми говоримо, що хочемо детектувати +10 в.п., тобто 60% успішних підписок, то потрібно знайти 160 тестових клієнтів, це видно з попередніх графіків. Якщо 30 осіб нам, наприклад, шукати місяць, такий тест може затягнутися майже на півроку. Тому варто подумати про те, щоб виділити додаткові ресурси на пошук клієнтів, наприклад, залучити маркетологів.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#sec-ci",
    "href": "power.html#sec-ci",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.4 Довірчі інтервали",
    "text": "2.4 Довірчі інтервали\nРаніше ми навчилися перевіряти гіпотезу \\({H}_0: \\mu = 0.5\\). Як відповідь ми отримуємо лише вердикт “відкидаємо \\({H}_0\\)” або “не відкидаємо \\({H}_0\\)”. Однак у вибірці міститься набагато більше інформації, й ми можемо більше зрозуміти про параметр, ніж порівняння з числом \\(0.5\\).\nЯкщо гіпотеза \\({H}_0\\) не відкидається, це означає, що значення \\(\\mu = 0.5\\) припустиме для нашої вибірки. Отримані значення можна пояснити значенням \\(\\mu = 0.5\\). Але якщо у нас є механізм перевірки для будь-якого \\(\\mu\\), ми можемо для всіх значень дізнатися, які з них допустимі, і отримати множину можливих значень \\(\\mu\\). Така множина називається довірчим інтервалом.\nДовірчий інтервал рівня \\(1 - \\alpha\\) — множина значень параметра \\(\\mu_0\\), для яких гіпотеза \\(\\mu = \\mu_0\\) не відкидається критерієм рівня значущості \\(\\alpha\\).\nЗ визначення випливає, що різні критерії можуть породжувати різні довірчі інтервали. У цій частині розглянемо, які інтервали породжуються двостороннім критерієм. Для цього з кроком \\(0.001\\) переберемо значення \\(\\mu \\in [0, 1]\\) і перевіримо гіпотези.\n\n\n\n1def two_sided_criterion_nonsym(n, mu, alpha):\n    \"\"\"\n    Функція, що обчислює критичні значення для двостороннього критерію\n\n    n: розмір вибірки\n    mu: параметр нульової гіпотези\n    alpha: рівень значущості\n    \"\"\"\n2    binom_h0 = binom(n=n, p=mu)\n3    c2 = binom_h0.ppf(1 - alpha/2) + 1\n4    c1 = binom_h0.ppf(alpha/2) - 1\n5    return c1, c2\n\n\n6success_cnt = 19\n7mu_grid = np.arange(0, 1, 0.001)\n8mu_no_rejection = []\n\n9for mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n1\n\nФункція, що обчислює критичні значення для двостороннього критерію.\n\n2\n\nРозподіл нульової гіпотези\n\n3\n\nПрава межа критичної області\n\n4\n\nЛіва межа критичної області\n\n5\n\nПовертаємо межі критичної області\n\n6\n\nКількість успіхів\n\n7\n\nСітка для \\(\\mu\\)\n\n8\n\nСписок для значень \\(\\mu\\), для яких \\({H}_0\\) не відкидається\n\n9\n\nПеребираємо значення \\(\\mu\\) та обчислюємо критичні значення\n\n\n\n\n95% довірчий інтервал: [0.439 - 0.8]\n\n\n\n\nОтримавши такий інтервал, ми відразу можемо зробити висновок, що гіпотеза \\({H}_0: \\mu = 0.5\\) не відкидається, оскільки \\(0.5\\) лежить у довірчому інтервалі. Але при цьому відразу зрозуміло, що \\(\\mu \\neq 0.4\\) на рівні значущості \\(\\alpha\\).\nЗвичайно ж, у довірчому інтервалі лежить значення \\(\\mu = \\frac{19}{30}\\), для якого \\(19\\) успіхів — це найбільш правдоподібний результат. При цьому інтервал несиметричний щодо точки \\(\\frac{19}{30}\\).\nПодивимося, як можна візуально знайти межу інтервалу. Ми отримали \\(19\\) успіхів. Для кожного \\(\\mu_0\\) статистика \\(Q\\) має розподіл \\(Binom(30, \\mu_0)\\). Будемо малювати цей розподіл і дивитися, чи потрапляє \\(19\\) у критичну область.\n\n\n\n1mus_h0 = [0.2, 0.438, 0.439, 0.8, 0.81, 0.9]\n\n2fig, axes = plt.subplots(3, 2, figsize=(8, 8))\n\n3for mu_h0, ax in zip(mus_h0, axes.flatten()):\n4    binom_h0 = binom(n=30, p=mu_h0)\n5    probs = binom_h0.pmf(x_grid)\n\n6    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n7    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n8    crit_reg = (x_grid &lt;= c1) | (x_grid &gt;= c2)\n9    ax.bar(x_grid[crit_reg], probs[crit_reg],\n           color=red_pink, label='Критична область')\n10    is_rejection = success_cnt &lt;= c1 or success_cnt &gt;= c2\n11    ax.axvline(success_cnt, ls='--',\n        label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не відхилено'),\n        color='gray', alpha=0.4)\n\n12    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n1\n\nСітка для \\(\\mu\\)\n\n2\n\nСтворюємо сітку для графіків\n\n3\n\nПеребираємо значення \\(\\mu\\) та осі\n\n4\n\nРозподіл нульової гіпотези\n\n5\n\nОбчислюємо ймовірності\n\n6\n\nБудуємо гістограму\n\n7\n\nОбчислюємо критичні значення\n\n8\n\nКритична область\n\n9\n\nПідсвічуємо критичну область\n\n10\n\nЧи потрапляє \\(19\\) у критичну область\n\n11\n\nВертикальна лінія для \\(19\\) успіхів\n\n12\n\nЙмовірність потрапляння в критичну область\n\n\n\n\n\n\n\n\n\n\nРисунок 2.5: Довірчі інтервали для біноміального розподілу\n\n\n\n\n\nВидно, що зі зростанням \\(\\mu_0\\) гістограма зсувається вправо. І спочатку \\(19\\) потрапляє в праву критичну область. Потім, починаючи з точки \\(0.439\\), значення \\(19\\) вже опиняється поза критичною областю, і тільки з \\(\\mu_0 = 0.81\\) починає потрапляти в ліву критичну область.\nТаким чином, ліва межа довірчого інтервалу — це перша точка, коли значення статистики перестало потрапляти до критичної області, а права межа - остання точка, коли значення не потрапляє до правої критичної області.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#односторонні-довірчі-інтервали",
    "href": "power.html#односторонні-довірчі-інтервали",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.5 Односторонні довірчі інтервали",
    "text": "2.5 Односторонні довірчі інтервали\nНасправді, двосторонній критерій потрібен вкрай рідко. Контролювати хибно похитивну помилку нам потрібно тільки для відхилень у бік, корисний для бізнесу. У випадку завдання з освітнім сервісом це отримання більшої конверсії в успіх.\nСпробуємо скористатися одностороннім критерієм для побудови довірчого інтервалу.\n\n\n\n1def make_binom_criterion(n, mu=0.5, alpha=0.05):\n    \"\"\"\n    Функція, що обчислює критичне значення для одностороннього критерію\n\n    n: розмір вибірки\n    mu: параметр нульової гіпотези\n    alpha: рівень значущості\n    \"\"\"\n2    binom_h0 = binom(n=n, p=mu)\n3    q = binom_h0.ppf(1 - alpha)\n4    return q + 1\n\n5success_cnt = 19\n6mu_grid = np.arange(0, 1.001, 0.001)\n7mu_no_rejection = []\n\n8for mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% довірчий інтервал: [{min(mu_no_rejection)} - {max(mu_no_rejection)}]')\n\n\n1\n\nФункція, що обчислює критичне значення для одностороннього критерію.\n\n2\n\nРозподіл нульової гіпотези\n\n3\n\nКритичне значення\n\n4\n\nПовертаємо критичне значення\n\n5\n\nКількість успіхів\n\n6\n\nСітка для \\(\\mu\\)\n\n7\n\nСписок для значень \\(\\mu\\), для яких \\({H}_0\\) не відкидається\n\n8\n\nПеребираємо значення \\(\\mu\\) та обчислюємо критичне значення\n\n\n\n\n95% довірчий інтервал: [0.467 - 1.0]\n\n\n\n\nКоли ми використовували двосторонній інтервал, ми отримали ліву межу \\(0.439 &lt; 0.467\\). Виходить, що односторонній інтервал з точки зору лівої межі дає нам більше інформації. При цьому з точки зору правої межі ми втрачаємо інформацію зовсім. Вона дорівнює 1 просто тому, що ймовірність не може бути більшою.\nНасправді зазвичай на праву межу не дивляться під час аналізу, коли ми шукаємо позитивний ефект.\nПрипустимо, ми отримали не \\(19\\) успіхів, а \\(22\\). Побудуємо 2 види інтервалів.\n\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Двосторонній 95% ДІ: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\nДвосторонній 95% ДІ: [0.542 - 0.877]\n\n\n\n\n\nsuccess_cnt = 22\nmu_grid = np.arange(0, 1.001, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    crit_val = make_binom_criterion(n=30, mu=mu_h0, alpha=0.05)\n    if success_cnt &lt; crit_val:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'Односторонній 95% ДІ: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\nОдносторонній 95% ДІ: [0.571 - 1.000]\n\n\n\n\nЗа обома довірчими інтервалами ми робимо висновок, що конверсія значимо відрізняється від \\(50\\%\\). Але односторонній інтервал дає кращу нижню оцінку на ймовірність успіху. Ми можемо зрозуміти, що наша конверсія більша за \\(57\\%\\). А інформація з двостороннього інтервалу про те, що ймовірність менша за \\(88\\%\\) не додає нам користі.\nНавіщо ж ми тоді взагалі використовуємо двосторонній інтервал? Щоб це зрозуміти, подивимося, як виглядають візуально межі для одностороннього інтервалу.\n\n\n\nfig, axes = plt.subplots(3, 2, figsize=(8, 7))\n\n1for mu_h0, ax in zip(mus_h0, axes.flatten()):\n2    binom_h0 = binom(n=30, p=mu_h0)\n3    probs = binom_h0.pmf(x_grid)\n\n4    ax.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu_h0}, 30)$')\n5    c = make_binom_criterion(30, mu_h0, alpha=0.05)\n6    crit_reg = (x_grid &gt;= c)\n7    ax.bar(x_grid[crit_reg], probs[crit_reg],\n           color=red_pink, label='Критична область')\n\n8    is_rejection = success_cnt &gt;= c\n9    ax.axvline(success_cnt, ls='--',\n    label=f'Q = {success_cnt} ' + ('відхилено' if is_rejection else 'не відхилено'),\n    color='gray', alpha=0.4)\n\n10    rejection_prob = probs[crit_reg].sum()\n    ax.set_title(f'$\\mu = {mu_h0}$', fontsize=8)\n    ax.legend()\n\n\n1\n\nСітка для \\(\\mu\\)\n\n2\n\nРозподіл нульової гіпотези\n\n3\n\nОбчислюємо ймовірності\n\n4\n\nБудуємо гістограму\n\n5\n\nОбчислюємо критичні значення\n\n6\n\nКритична область\n\n7\n\nПідсвічуємо критичну область\n\n8\n\nЧи потрапляє \\(22\\) у критичну область\n\n9\n\nВертикальна лінія для \\(22\\) успіхів\n\n10\n\nЙмовірність потрапляння в критичну область\n\n\n\n\n\n\n\n\n\n\nРисунок 2.6: Односторонній довірчий інтервал для \\(22\\) успіхів\n\n\n\n\n\nПорівняно з Рисунок 2.5 ми бачимо, що права критична область стала більшою через те, що там тепер знаходиться не \\(2.5\\%\\), а \\(5\\%\\) від усіх значень. При цьому лівої критичної області просто не існує, тому за великих \\(\\mu\\) не відбувається потрапляння \\(19\\) до неї, а значить ми не відкидаємо гіпотезу.\nЗауважимо, що якби ми будували двосторонній інтервал, але з удвічі більшою \\(\\alpha\\), потрапляння в праву критичну область траплялися б за тих самих \\(\\mu\\), що й в односторонньому критерії. Тому часто для пошуку односторонньої межі будують двосторонній довірчий інтервал із більшою \\(\\alpha\\), ігноруючи при цьому праву межу. Це зручно, оскільки можна користуватися тільки однією функцією для критерію.\nПеревіримо, що вийде за \\(\\alpha = 0.1\\).\n\n\n\nsuccess_cnt = 19\nmu_grid = np.arange(0, 1, 0.001)\nmu_no_rejection = []\n\nfor mu_h0 in mu_grid:\n    c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.1)\n    if success_cnt &gt; c1 and success_cnt &lt; c2:\n        mu_no_rejection.append(mu_h0)\n\nprint(f'95% ДІ: [{min(mu_no_rejection):.3f} - {max(mu_no_rejection):.3f}]')\n\n95% ДІ: [0.467 - 0.778]\n\n\n\n\nБачимо, що отримали таку саму ліву межу, як і в односторонньому інтервалі.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#sec-ci-prop",
    "href": "power.html#sec-ci-prop",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.6 Властивості довірчих інтервалів",
    "text": "2.6 Властивості довірчих інтервалів\nЗгадаймо визначення довірчого інтервалу.\nНехай є критерій \\(S = \\{Q(\\xi) \\leqslant C\\}\\) рівня значущості \\(\\alpha\\) для перевірки гіпотези \\({H}_0: \\mu = \\mu_0\\), \\(Q\\) — статистика критерію, а \\(q\\) — її реалізація на конкретній вибірці \\(\\xi = \\xi_1, \\dots, \\xi_n\\). Тоді довірчим інтервалом називається множина таких \\(\\mu_0\\), на яких критерій \\(S\\) не відкидає гіпотезу \\({H}_0: \\mu = \\mu_0\\).\nПроцедура підрахунку інтервалу — це довгий перебір значень із деяким кроком. Але це все ще залишається деякою функцією від вибірки, тобто статистикою й випадковою величиною, причому її розподіл залежить від статистики \\(Q\\), а отже, і від початкової вибірки, та від параметра \\(\\mu\\) у генеральній сукупності.\nПозначимо межі інтервалу за \\(\\mathcal{L}(Q), \\mathcal{R}(Q)\\) — статистики критерію, які відповідають лівій та правій межі інтервалу.\n\n2.6.1 Ймовірність попадання в інтервал\nЯким би не було істинне значення \\(\\mu = \\mu_0\\), ймовірність того, що воно перебуває між \\(\\mathcal{L}(Q)\\) та \\(\\mathcal{R}(Q)\\), не нижча, ніж \\(1 - \\alpha\\). Значення \\(1 - \\alpha\\) називається рівнем довіри довірчого інтервалу.\n\\[\nP(\\mathcal{L}(Q) &lt; \\mu_0 &lt; \\mathcal{R}(Q)) \\geqslant 1 - \\alpha\n\\tag{2.3}\\]\nВажливо, що випадковість тут прихована саме в \\(\\mathcal{L}\\) і \\(\\mathcal{R}\\), а не в \\(\\mu_0\\). Параметр \\(\\mu_0\\) невідомий, але ми припускаємо його константним і не випадковим.\nПеревіримо справедливість цієї властивості. Для цього зафіксуємо \\(\\mu_0\\) й проведемо множину експериментів:\n\nГенеруємо вибірку з розподілу з параметром \\(\\mu_0\\).\nОбчислюємо статистику \\(q\\).\nРахуємо довірчий інтервал для \\(\\alpha = 0.05\\).\n\nПеревіряємо, що частка випадків, коли параметр \\(\\mu_0\\) опинився всередині інтервалу, хоча б \\(95\\%\\).\n\n\n\n1import time\n\n2start_time = time.time()\n\n3def my_binomial_confint(n, alpha, q):\n    \"\"\"\n    Функція, що обчислює довірчий інтервал для біноміального розподілу\n\n    n: розмір вибірки\n    alpha: рівень значущості\n    q: кількість успіхів\n    \"\"\"\n4    mu_grid = np.arange(0, 1.1, 0.1) # np.arange(0, 1.001, 0.001)\n5    mu_no_rejection = []\n\n6    for mu_h0 in mu_grid:\n7        c1, c2 = two_sided_criterion_nonsym(30, mu_h0, alpha=0.05)\n8        if q &gt; c1 and q &lt; c2:\n9            mu_no_rejection.append(mu_h0)\n\n10    return min(mu_no_rejection), max(mu_no_rejection)\n\n\n1\n\nІмпортуємо бібліотеку для вимірювання часу\n\n2\n\nЗапускаємо таймер\n\n3\n\nФункція, що обчислює довірчий інтервал\n\n4\n\nСітка для \\(\\mu\\)\n\n5\n\nСписок для значень \\(\\mu\\), для яких \\({H}_0\\) не відкидається\n\n6\n\nПеребираємо значення \\(\\mu\\) та осі\n\n7\n\nОбчислюємо критичні значення\n\n8\n\nЧи потрапляє \\(q\\) у критичну область\n\n9\n\nДодаємо значення \\(\\mu\\), для яких \\({H}_0\\) не відкидається\n\n10\n\nПовертаємо межі довірчого інтервалу\n\n\n\n\nТепер запустимо експеримент. Для цього зафіксуємо \\(\\mu_0 = 0.5\\) й проведемо \\(1000\\) експериментів. У кожному з них будемо генерувати \\(30\\) успіхів, а потім перевіряти, чи потрапила \\(\\mu_0\\) у довірчий інтервал.\n\n\n\n1N_EXPERIMENTS = 1000\n2SAMPLE_SIZE = 30\n3latent_mu = 0.5\n4binom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\n5confint_fail_cases = 0\n\n6for i in range(N_EXPERIMENTS):\n7    q = binom_true.rvs()\n8    L, R = my_binomial_confint(n=SAMPLE_SIZE, alpha=0.05, q=q)\n9    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\n10success_cases = 100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS\n11end_time = time.time()\n\nprint(f\"Відсоток успішних випадків: {success_cases:.2f}%\")\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\n\n1\n\nКількість експериментів\n\n2\n\nРозмір вибірки\n\n3\n\nІстинне значення ймовірності успіху\n\n4\n\nРозподіл нульової гіпотези\n\n5\n\nЛічильник невдалих випадків\n\n6\n\nПеребираємо експерименти\n\n7\n\nГенеруємо вибірку\n\n8\n\nОбчислюємо довірчий інтервал\n\n9\n\nПеревіряємо, чи потрапила \\(\\mu_0\\) у довірчий інтервал\n\n10\n\nОбчислюємо частку успішних випадків\n\n11\n\nВимірюємо час виконання\n\n\n\n\nВідсоток успішних випадків: 61.40%\nЧас виконання: 3.7189 секунди\n\n\n\n\nЗазначимо, що цей код працював понад 5 хвилин. Це через те, що під час кожного експерименту потрібно побудувати довірчий інтервал, а значить перевірити 1000 можливих параметрів \\(\\mu_0\\).\nБачимо, що властивість виконалася. Ми очікували хоча б \\(95\\%\\) влучень, отримали навіть \\(61.4\\%\\). Насправді це значно більше, ніж ми очікували. Це відбувається через дискретність розподілу. З тієї ж причини під час пошуку критичної області ми не могли вибрати стовпці із сумарною висотою рівно \\(\\alpha\\).\n\n2.6.1.1 Доведення\nПід час формулювання властивості ми припускаємо, що є деяка \\(\\mu_0\\) — ймовірність успіху в генеральній сукупності. Коли ми проводимо штучний експеримент, ми фіксуємо її й можемо вважати істинною \\(\\mu\\).\nЩоразу ми генеруємо \\(Q \\sim Binom(\\mu_0, 30)\\) й перевіряємо, чи потрапила \\(\\mu_0\\) у довірчий інтервал. Намалюємо розподіл статистики \\(Q\\), який уже нам знайомий. Намалюємо й область ймовірності \\(\\leqslant \\alpha\\), як ми робили це раніше.\n\n\n\n1mu0 = 0.5\n2binom_mu0 = binom(n=30, p=mu0)\n3probs = binom_mu0.pmf(x_grid)\n\n4plt.bar(x_grid, probs, color=turquoise, label=f'PMF, $Binom({mu0}, 30)$')\n5c1, c2 = two_sided_criterion_nonsym(30, mu0, alpha=0.05)\n6crit_reg = (x_grid &gt;= c2) | (x_grid &lt;= c1)\n7plt.bar(x_grid[crit_reg], probs[crit_reg],\n        color=red_pink, label='Критична область')\nplt.legend()\nplt.show()\n\n\n1\n\nІстинне значення ймовірності успіху\n\n2\n\nРозподіл нульової гіпотези\n\n3\n\nОбчислюємо ймовірності\n\n4\n\nБудуємо гістограму\n\n5\n\nОбчислюємо критичні значення\n\n6\n\nКритична область\n\n7\n\nПідсвічуємо критичну область\n\n\n\n\n\n\n\n\n\n\nРисунок 2.7: Розподіл статистики при істинній ймовірності успіху\n\n\n\n\n\nНехай реалізувалося значення статистики \\(q\\). За такою вибіркою можна побудувати довірчий інтервал на \\(\\mu\\). Він буде якось розташований, але зараз нас цікавить, чи потрапить у нього \\(\\mu_0\\). За визначенням потрапляння в інтервал відбудеться, якщо не відкидається гіпотеза \\({H}_0:\\ \\mu = \\mu_0\\). Але тоді за справедливості \\({H}_0\\) статистика має той розподіл, що і на малюнку. І гіпотеза відкидається тільки в разі потрапляння в критичну область, а це трапляється з ймовірністю \\(\\leqslant \\alpha\\).\nОтже, з ймовірністю хоча б \\(1 - \\alpha\\) \\(\\mu_0\\) перебуватиме в довірчому інтервалі.\nЧасто так й вводять визначення довірчого інтервалу. Для вибірки \\(\\xi_1, \\dots, \\xi_n\\) — це така пара статистик \\(\\mathcal{L}(\\xi)\\) і \\(\\mathcal{R}(\\xi)\\), що хоч яким би не було \\(\\mu_0\\),\n\\[\nP(L(\\xi) &lt; \\mu_0 &lt; R(\\xi)) \\geqslant 1 - \\alpha\n\\tag{2.4}\\]\nде \\(L(\\xi)\\) і \\(R(\\xi)\\) — статистики, що залежать від вибірки. Знову звертаємо увагу, що випадковість тут прихована не в параметрі \\(\\mu_0\\), а в статистиках від вибірки.\n\n\n\n2.6.2 Довірчий інтервал Вілсона\nРозглянутий зараз алгоритм побудови довірчого інтервалу працює занадто довго. У Python є функції, які дозволяють швидше розрахувати інтервал. Наприклад, можна скористатися методом Вілсона і функцією proportion_confint.\nПовторимо експерименти з новим типом довірчого інтервалу, тут можемо дозволити більше реалізацій вибірки, оскільки інтервал рахується недовго.\n\n\n\nfrom statsmodels.stats.proportion import proportion_confint\n\nstart_time = time.time()\n\nN_EXPERIMENTS = 1000\nSAMPLE_SIZE = 30\nlatent_mu = 0.5\nbinom_true = binom(n=SAMPLE_SIZE, p=latent_mu)\n\nconfint_fail_cases = 0\n\nfor i in range(N_EXPERIMENTS):\n    q = binom_true.rvs()  \n    L, R = proportion_confint(\n        count=q,\n        nobs=SAMPLE_SIZE,\n        alpha=0.05,\n        method='wilson'\n    )\n    if L &lt; latent_mu &lt; R:\n        pass\n    else:\n        confint_fail_cases += 1\n\nsuccess_cases = 100 * (N_EXPERIMENTS - confint_fail_cases) / N_EXPERIMENTS\nend_time = time.time()\n\nprint(f\"Відсоток успішних випадків: {success_cases:.2f}%\")\nprint(f\"Час виконання: {end_time - start_time:.4f} секунди\")\n\nВідсоток успішних випадків: 96.60%\nЧас виконання: 0.0765 секунди\n\n\n\n\nЗауважимо, що наше \\(\\mu\\) може знаходитись в довірчому інтервалі менше, ніж у \\(95\\%\\) випадків. Це відбувається через те, що швидкі методи працюють наближено, оцінюючи розподіл статистики при збільшенні розміру вибірки. Чим розмір вибірки більший, тим ближчим буде інтервал до \\(95\\%\\)-ного.\nЗалежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки зобразимо на Рисунок 2.8.\n\n\n\n1n_grid = np.arange(1, 1000, 25).tolist()\n2interval_success_rate = []\n\n3for n in n_grid:\n4    confint_fail_cases = 0\n5    for i in range(N_EXPERIMENTS):\n6        binom_true = binom(n=n, p=latent_mu)\n7        q = binom_true.rvs()\n8        L, R = proportion_confint(\n            count=q,\n            nobs=n,\n            alpha=0.05,\n            method='wilson'\n        )\n9        if L &lt; latent_mu &lt; R:\n            pass\n        else:\n            confint_fail_cases += 1\n10    interval_success_rate.append(1 - confint_fail_cases / N_EXPERIMENTS)\n\n\n1\n\nСітка для розміру вибірки\n\n2\n\nСписок для частки успішних влучень\n\n3\n\nПеребираємо розміри вибірки\n\n4\n\nЛічильник невдалих випадків\n\n5\n\nПеребираємо експерименти\n\n6\n\nГенеруємо вибірку\n\n7\n\nГенеруємо \\(q\\) з розподілу\n\n8\n\nОбчислюємо довірчий інтервал\n\n9\n\nПеревіряємо, чи потрапила \\(\\mu_0\\) у довірчий інтервал\n\n10\n\nОбчислюємо частку успішних випадків\n\n\n\n\n\n\nТепер побудуємо графік.\n\n\n\nfig, ax = plt.subplots(figsize=(8, 2.5))\n1plt.plot(n_grid, interval_success_rate,\n         label='Частка успішних влучень', color=turquoise)\n2plt.axhline(0.95, ls='--',\n            label='Желаемая успешность', color=red_pink)\n\nplt.xlabel('Розмір вибірки $n$')\nplt.ylabel('Частка успішних влучень')\nplt.legend()\nplt.show()\n\n\n1\n\nГрафік частки успішних влучень\n\n2\n\nЛінія бажаної частки успішних влучень\n\n\n\n\n\n\n\n\n\n\nРисунок 2.8: Залежність частки успішних влучень \\(\\mu\\) у довірчий інтервал від розміру вибірки\n\n\n\n\n\nВидно, що на будь-якому розмірі вибірки під час використання інтервалу Вілсона можна отримати менше \\(95\\%\\) влучень, але що більший розмір вибірки, то менше графік відхиляється від \\(95\\%\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "power.html#sec-questions-2",
    "href": "power.html#sec-questions-2",
    "title": "2  Статистична потужність, ефект та довірчі інтервали",
    "section": "2.7 Питання для самоперевірки",
    "text": "2.7 Питання для самоперевірки\nЗагальні поняття та Помилки\n\nЯкі два основні типи помилок можна зробити при перевірці статистичних гіпотез? Назвіть їх (FPR та FNR) та поясніть, що кожна з них означає.\nЯк рівень значущості (\\(\\alpha\\)) пов’язаний з одним із типів помилок?\nПоясніть на прикладі “критерію пори року”, чому критерій з низьким рівнем значущості (\\(\\alpha\\)) не обов’язково є хорошим чи корисним.\n\nСтатистична Потужність\n\nЩо таке статистична потужність критерію? Як вона пов’язана з хибно негативною помилкою (FNR)?\nЧому в статистиці часто фокусуються на максимізації потужності (або мінімізації FNR) при фіксованому рівні значущості \\(\\alpha\\)?\nВід яких основних факторів залежить потужність статистичного критерію? Як кожен з них (розмір вибірки, величина ефекту, рівень значущості) впливає на потужність?\nЯк змінюється потужність критерію для біноміального розподілу при збільшенні розміру вибірки (N)? Наведіть приклад з тексту.\nЯк змінюється потужність критерію для біноміального розподілу при збільшенні різниці між параметром нульової гіпотези (\\(\\mu_0\\)) та параметром альтернативної гіпотези (\\(\\mu_{alternative}\\))? Наведіть приклад з тексту.\nЯке значення потужності часто вважається прийнятним мінімальним рівнем у практичних дослідженнях?\n\nМінімальна Величина Ефекту (MDE)\n\nЩо таке Мінімальна величина ефекту, яку можна задетектувати (MDE)?\nЯк MDE пов’язаний з потужністю, розміром вибірки та рівнем значущості?\nЧому важливо розраховувати MDE перед початком експерименту?\nПоясніть різницю між статистичною значущістю та практичною значущістю ефекту. Чому ця різниця важлива?\n\nДовірчі Інтервали (ДІ)\n\nДайте визначення довірчого інтервалу рівня \\(1 - \\alpha\\). Як він пов’язаний з перевіркою гіпотез?\nОпишіть основний принцип побудови довірчого інтервалу, який використовувався в тексті для біноміального розподілу (через перебір значень \\(\\mu_0\\)).\nЧим відрізняються двосторонні та односторонні довірчі інтервали? В якій ситуації може бути доцільніше використовувати односторонній ДІ?\nЯк межа одностороннього довірчого інтервалу пов’язана з межами двостороннього довірчого інтервалу, побудованого з подвоєним рівнем значущості (наприклад, \\(\\alpha=0.1\\) для 95% одностороннього інтервалу)?\nПоясніть ключову властивість довірчого інтервалу: \\(P(\\mathcal{L}(Q) &lt; \\mu_0 &lt; \\mathcal{R}(Q)) \\geqslant 1 - \\alpha\\). Що є випадковим у цій нерівності (параметр \\(\\mu_0\\) чи межі інтервалу \\(\\mathcal{L}, \\mathcal{R}\\))?\nЧому при використанні точних методів побудови ДІ для дискретних розподілів (як біноміальний) фактична ймовірність покриття істинного параметра може бути більшою за \\(1 - \\alpha\\)?\nЯкі переваги та недоліки використання наближених методів побудови ДІ, таких як метод Вілсона? Коли їх використання виправдане?\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Статистична потужність, ефект та довірчі інтервали</span>"
    ]
  },
  {
    "objectID": "z-test.html",
    "href": "z-test.html",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "3.1 Нормальний розподіл\nУ цьому розділі ми розглянемо \\(Z\\)-критерій Фішера, який використовується для перевірки гіпотез про середнє значення генеральної сукупності з відомою дисперсією.\nДалі, для виведення критеріїв нам потрібен нормальний розподіл. Потому що саме цьому розподілу підпорядковується середнє вибірок. Тож давайте подивимося, що це взагалі таке, як з ним працювати в Python й які в нього є властивості.\nНормальний розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\) — неперервний розподіл, у якому щільність спадає зі збільшенням відстані від математичного сподівання \\(\\mu\\) за швидкістю, пропорційною квадрату відстані (див. формулу 3.1).\n\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2},\n\\tag{3.1}\\] де \\(x\\) — випадкова величина, \\(\\mu\\) — математичне сподівання, \\(\\sigma^2\\) — дисперсія.\nНа графіку нижче показано, як виглядає нормальний розподіл з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\n1x = np.linspace(-5, 5, 1000)\n2params = [(0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (2, 2)]\n3colors = [turquoise, orange, red, blue, slate, purple]\n\n4for (mu, sigma), color in zip(params, colors):\n    plt.plot(x, norm.pdf(x, mu, sigma), label=f'μ={mu}, σ={sigma}', color=color)\n\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.legend()\nplt.show()\n\n\n1\n\nГенерація значень \\(x\\) для побудови графіка.\n\n2\n\nПараметри \\(\\mu\\) та \\(\\sigma^2\\).\n\n3\n\nКольори для графіків.\n\n4\n\nПобудова графіка нормального розподілу з різними параметрами \\(\\mu\\) та \\(\\sigma^2\\).\n\n\n\n\n\n\n\n\n\n\nРисунок 3.1: Нормальний розподіл з різними параметрами",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-python",
    "href": "z-test.html#sec-normal-distribution-python",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.2 Нормальний розподіл у Python",
    "text": "3.2 Нормальний розподіл у Python\nНехай ми хочемо задати розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Для цього є клас norm1.\nПараметри класу:\n\nloc — це \\(\\mu\\)\nscale — це \\(\\sigma\\), або стандартне відхилення. Не дисперсія!\n\nМетоди класу:\n\nrvs() — згенерувати випадкові числа з розподілу \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\ncdf(x) — кумулятивна функція розподілу (cumulative distribution function, CDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\).\nppf(q) — квантиль функції розподілу (percent-point function, PPF) для ймовірності \\(q\\), ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(q\\).\npdf(x) — щільність ймовірності (probability density function, PDF) в точці \\(x\\), ймовірність того, що випадкова величина \\(X\\) дорівнює \\(x\\).\n\nCDF та PPF — це функції, які пов’язані між собою. CDF визначає ймовірність того, що випадкова величина \\(X\\) менша або дорівнює \\(x\\), а PPF визначає значення \\(x\\), для якого ймовірність \\(X\\) менша або дорівнює \\(q\\).\nІніціалізуємо клас norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\) (стандартний нормальний розподіл). Далі, згенеруємо випадкову вибірку з 50 спостережень, а також обчислимо PDF, CDF та PPF для \\(x = 1.5\\).\n\n\n\n1std_norm = norm(loc=0, scale=1)\n\n2rnorm = std_norm.rvs(size=50, random_state=42)\n\n3CDF = std_norm.cdf(1.5)\n4PDF = std_norm.pdf(1.5)\n5PPF = std_norm.ppf(0.933)\n\n6display(\n    Markdown(f\"$P(X \\\\leq 1.5) = {CDF:.3f}$\"),\n    Markdown(f\"$f(1.5) = {PDF:.3f}$\"),\n    Markdown(f\"$z_{{0.933}} = \\Phi^{{-1}}(0.933) = {PPF:.3f}$\")\n)\n\n\n1\n\nІніціалізація класу norm з параметрами \\(\\mu = 0\\) та \\(\\sigma = 1\\).\n\n2\n\nГенерація випадкової вибірки з 50 спостережень.\n\n3\n\nОбчислення PDF для \\(x = 1.5\\).\n\n4\n\nОбчислення CDF для \\(x = 1.5\\).\n\n5\n\nОбчислення PPF для \\(q = 0.933\\).\n\n6\n\nВиведення результатів.\n\n\n\n\n\\(P(X \\leq 1.5) = 0.933\\)\n\n\n\\(f(1.5) = 0.130\\)\n\n\n\\(z_{0.933} = \\Phi^{-1}(0.933) = 1.499\\)\n\n\n\n\nВізуалізація методів класу norm показана на рисунку 3.2.\n\n\n\n\n\n\n\n\n\n\nРисунок 3.2: Демонстрація методів класу norm",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-normal-distribution-properties",
    "href": "z-test.html#sec-normal-distribution-properties",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.3 Властивості нормального розподілу",
    "text": "3.3 Властивості нормального розподілу\nНормальний розподіл має кілька важливих властивостей2:\n\nСума двох незалежних нормально розподілених випадкових величин також має нормальний розподіл:\n\n\\[\n\\begin{aligned}\n\\xi_1 &\\sim \\mathcal{N}(\\mu_1, \\sigma_1^2) \\\\\n\\xi_2 &\\sim \\mathcal{N}(\\mu_2, \\sigma_2^2) \\\\\n\\xi_1 + \\xi_2 &\\sim \\mathcal{N}(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\n\\end{aligned}\n\\tag{3.2}\\] де \\(\\xi_1\\) та \\(\\xi_2\\) — незалежні нормально розподілені випадкові величини з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\) та \\(\\mu_2\\), \\(\\sigma_2^2\\) відповідно.\n\nМноження нормально розподіленої випадкової величини на константу також дає нормально розподілену величину:\n\n\\[\na \\xi_1 \\sim \\mathcal{N}(a\\mu_1, a^2\\sigma_1^2)\n\\tag{3.3}\\] де \\(a\\) — константа, \\(\\xi_1\\) — нормально розподілена випадкова величина з параметрами \\(\\mu_1\\), \\(\\sigma_1^2\\).\n\n3.3.1 Перевірка властивостей в Python\nЗа допомогою мови Python ми можемо перевірити ці властивості. Почнемо з Рівняння 3.2. Для цього ми згенеруємо дві нормально розподілені випадкові величини \\(\\xi_1\\) та \\(\\xi_2\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та \\(\\mu_2 = 1\\), \\(\\sigma_2^2 = 4\\). Потім, ми обчислимо їхню суму та перевіримо, чи має вона нормальний розподіл з параметрами \\(\\mu_1 + \\mu_2\\) та \\(\\sigma_1^2 + \\sigma_2^2\\).\n\n\n\n1mean_one, mean_two = 3, -1\n2var_one, var_two = 4, 2\n\n3n = 10000\n\n4x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\nx2 = norm.rvs(loc=mean_two, scale=np.sqrt(var_two), size=n)\n\n5x_sum = x1 + x2\n6check_sum = norm(loc=mean_one + mean_two, scale=np.sqrt(var_one + var_two))\n\n7x_grid = np.linspace(-8, 12, 1000)\n\nfig, ax = plt.subplots()\n8sns.histplot(x_sum, kde=True, stat='density', color=turquoise,\n             label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_sum.pdf(x_grid), color=red_pink,\n         label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\mu_2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\) та \\(\\sigma_2^2\\).\n\n3\n\nКількість спостережень.\n\n4\n\nГенерація нормально розподілених випадкових величин \\(\\xi_1\\) та \\(\\xi_2\\).\n\n5\n\nСума двох нормально розподілених випадкових величин.\n\n6\n\nПараметри суми \\(\\xi_1 + \\xi_2\\).\n\n7\n\nСтандартне відхилення суми \\(\\xi_1 + \\xi_2\\).\n\n8\n\nЕмпіричний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n9\n\nТеоретичний розподіл суми \\(\\xi_1 + \\xi_2\\).\n\n\n\n\n\n\n\n\n\n\nРисунок 3.3: Перевірка властивостей нормального розподілу\n\n\n\n\n\nВидно, що розподіли приблизно збіглися! А значить ми переконалися, що формула правильна.\nДругу властивість Рівняння 3.3 можна перевірити аналогічно. Для цього ми згенеруємо нормально розподілену випадкову величину \\(\\xi_1\\) з параметрами \\(\\mu_1 = 0\\), \\(\\sigma_1^2 = 1\\) та помножимо її на константу \\(a = 2\\). Потім, ми перевіримо, чи має вона нормальний розподіл з параметрами \\(a\\mu_1\\) та \\(a^2\\sigma_1^2\\).\n\n\n\n1mean_one = 0\n2var_one = 1\n3a = 2\n4n = 10000\n5x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n)\n6x_mult = a * x1\n7check_mult = norm(loc=a * mean_one, scale=np.sqrt(a**2 * var_one))\n8x_grid = np.linspace(-8, 8, 1000)\n\nfig, ax = plt.subplots()\nsns.histplot(x_mult, kde=True, stat='density', color=turquoise,\n             label='Емпіричний розподіл', ax=ax)\n9plt.plot(x_grid, check_mult.pdf(x_grid), color=red_pink,\n         label='Теоретичний розподіл', alpha=0.8)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.show()\n\n\n1\n\nПараметри \\(\\mu_1\\) та \\(\\sigma_1^2\\).\n\n2\n\nПараметри \\(\\sigma_1^2\\).\n\n3\n\nКонстанта \\(a\\).\n\n4\n\nКількість спостережень.\n\n5\n\nГенерація нормально розподіленої випадкової величини \\(\\xi_1\\).\n\n6\n\nМноження нормально розподіленої випадкової величини \\(\\xi_1\\) на константу \\(a\\).\n\n7\n\nПараметри множення \\(\\xi_1\\) на константу \\(a\\).\n\n8\n\nСтандартне відхилення множення \\(\\xi_1\\) на константу \\(a\\).\n\n9\n\nЕмпіричний та теоретичний розподіл множення \\(\\xi_1\\) на константу \\(a\\).\n\n\n\n\n\n\n\n\n\n\nРисунок 3.4: Перевірка властивостей нормального розподілу\n\n\n\n\n\nЦього разу розподіли також збіглися. А значить ми переконалися, що формула правильна.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-central-limit-theorem",
    "href": "z-test.html#sec-central-limit-theorem",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.4 Центральна гранична теорема",
    "text": "3.4 Центральна гранична теорема\nДля початку пригадаємо теорему, яка є основоположною теоремою для всіх критеріїв, які ми розглянемо найближчим часом.\n\nТеорема 3.1 (Центральна гранична теорема, ЦГТ) Нехай \\(\\xi_1, ..., \\xi_n\\) — незалежно однаково розподілені випадкові величини, в яких існують математичне сподівання та дисперсія: \\(E [\\xi_i] = \\mu &lt; \\infty\\) і \\(Var[\\xi_i] = \\sigma^2 &lt; \\infty\\), тоді \\(\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}}\\) збігається за розподілом3 до \\(\\mathcal{N}(0, 1)\\).\n\nЦе означає, що якщо випадкові величини в експерименті незалежні й однаково розподілені й ваша вибірка досить велика, то можна вважати, що\n\\[\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1),\n\\tag{3.4}\\] де \\(\\overline \\xi\\) — середнє арифметичне вибірки, \\(n\\) — кількість спостережень, \\(\\mu\\) — математичне сподівання генеральної сукупності, \\(\\sigma^2\\) — дисперсія генеральної сукупності.\n\n\n\n\n\n\nПримітка\n\n\n\nВипадкові величини можуть бути слабко залежні одна від одної й злегка по-різному розподілені. Центральна гранична теорема все ще буде правильною, Gnedenko and Kolmogorov (2021).\n\n\n\n3.4.1 Візуалізація ЦГТ\nЩоб краще розуміти, як працює ЦГТ, я пропоную візуалізувати теорему: подивимося на розподіл середніх значень у різних вибірках. Як ми це зробимо?\n\nЩоб подивитися, що деяка випадкова величина з нормального розподілу, нам потрібна вибірка цих випадкових величин.\nУ цьому випадку нам потрібна вибірка статистик із ЦГТ. Тому нам потрібно згенерувати \\(N\\) вибірок по \\(M\\) елементів у кожній.\n\nПо кожній вибірці треба порахувати середнє за \\(M\\) елементами.\nУ підсумку ми отримаємо вибірку з \\(N\\) елементів.\nВона і має бути з нормального розподілу.\n\n\n\n\n\ndef visualize_CLT(sample_generator, expected_value, variance):\n    \"\"\"\n    Візуалізація ЦГТ\n    \n    sample_generator: функція, яка генерує вибірку\n    expected_value: математичне сподівання\n    variance: дисперсія\n    \"\"\"\n    np.random.seed(42)\n1    N = 5000\n2    clt_sample = []\n    for _ in range(N):\n3        sample = sample_generator()\n4        sample_size = len(sample)\n5        statistic = (\n            np.sqrt(sample_size)\n            * (np.mean(sample) - expected_value)\n            / np.sqrt(variance)\n         )\n6        clt_sample.append(statistic)\n\n7    x = np.linspace(-4, 4, 1000)\n    fig, ax = plt.subplots()\n    sns.histplot(clt_sample, kde=True, stat='density', color=turquoise,\n                 label='Емпіричний розподіл', ax=ax)\n    ax.plot(x, norm().pdf(x), color=red_pink,\n            label='$\\mathcal{N}(0, 1)$', alpha=0.8)\n    plt.legend()\n    plt.xlabel('X')\n    plt.ylabel('Щільність')\n    plt.show()\n\n\n1\n\nКількість вибірок.\n\n2\n\nПустий масив для зберігання статистик.\n\n3\n\nГенерація вибірки з \\(M\\) елементами.\n\n4\n\nКількість елементів у вибірці.\n\n5\n\nОбчислення статистики.\n\n6\n\nДодавання статистики до масиву.\n\n7\n\nВізуалізація емпіричного розподілу та теоретичного розподілу.\n\n\n\n\n\n\nТепер, давайте подивимося на біноміальний розподіл. Для цього ми згенеруємо вибірку з \\(N\\) елементів з біноміального розподілу з параметрами \\(n = 20\\) та \\(p = 0.01\\). Потім, ми обчислимо середнє за \\(M\\) елементами.\n\n\n\np = 0.01\nn = 20\nsize = 5000\n\n1visualize_CLT(lambda: np.random.binomial(n, p, size),\n2              expected_value = p * n,\n3              variance = n * p * (1 - p)\n)\n\n\n1\n\nГенерація вибірки з біноміального розподілу.\n\n2\n\nМатематичне сподівання біноміального розподілу.\n\n3\n\nДисперсія біноміального розподілу.\n\n\n\n\n\n\n\n\n\n\nРисунок 3.5: Візуалізація ЦГТ при великій вибірці з біноміального розподілу.\n\n\n\n\n\nЕмпірична щільність достатньо близько збігається з теоретичним розподілом.\nА що якщо зменшити вибірку, за якою рахується середнє? Для цього ми зменшимо \\(n\\) до 20, а \\(p\\) до 0.05. Тепер, ми згенеруємо вибірку з \\(N\\) елементів з біноміального розподілу з параметрами \\(n = 20\\) та \\(p = 0.05\\). Потім, ми обчислимо середнє за \\(M\\) елементами.\n\n\n\np = 0.05\nn = 20\nsize = 10\n\nvisualize_CLT(\n    lambda: np.random.binomial(n, p, size),\n    expected_value = p * n,\n    variance = n * p * (1 - p)\n)\n\n\n\n\n\n\n\nРисунок 3.6: Візуалізація ЦГТ при маленькій вибірці з біноміального розподілу.\n\n\n\n\n\nСтало значно гірше: з’явилися прогалини в розподілі, та й сама емпірична функція розподілу зміщена. Тож наш експеримент підтвердив важливість розміру вибірки для коректної роботи ЦГТ. Це означає, що якщо ми хочемо використовувати ЦГТ, то вибірка має бути досить великою. В іншому випадку, результати можуть бути ненадійними.\nТепер подивимось на експоненціальний розподіл. Для цього ми згенеруємо вибірку з \\(N\\) елементів з експоненціального розподілу з параметром \\(\\lambda = 5\\). Потім, ми обчислимо середнє за \\(M\\) елементами.\n\n\n\n1p = 5\n2size = 400\n\nvisualize_CLT(\n3    lambda: np.random.exponential(scale=1/p, size=size),\n4    expected_value = 1/p,\n5    variance = 1/(p**2)\n)\n\n\n1\n\nПараметр \\(\\lambda\\) експоненціального розподілу.\n\n2\n\nРозмір вибірки.\n\n3\n\nГенерація вибірки з експоненціального розподілу.\n\n4\n\nМатематичне сподівання експоненціального розподілу задається як \\(1/\\lambda\\).\n\n5\n\nДисперсія експоненціального розподілу задається як \\(1/\\lambda^2\\).\n\n\n\n\n\n\n\n\n\n\nРисунок 3.7: Візуалізація ЦГТ при великій вибірці з експоненціального розподілу.\n\n\n\n\n\nБачимо, що і тут усе добре працює!\n\n\n3.4.2 Інші формулювання ЦГТ\nНаступні формулювання є еквівалентними, тому що ми можемо перетворити одне в інше за допомогою простих алгебраїчних перетворень. Вони можуть бути корисними в різних ситуаціях, залежно від того, що ми хочемо перевірити.\n\\[\n\\begin{aligned}\n\\sqrt{n}\\dfrac{\\overline \\xi - \\mu}{\\sqrt{\\sigma^2}} &\\sim \\mathcal{N}(0, 1) {\\Leftrightarrow}\\\\\n\\overline \\xi - \\mu &\\sim \\mathcal{N}\\left(0, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\dfrac{\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i}{n} &\\sim \\mathcal{N}\\left(\\mu, \\dfrac{\\sigma^2}{n} \\right) \\Leftrightarrow\\\\\n\\underset{i=1}{\\overset{n}{\\sum}} \\xi_i &\\sim \\mathcal{N}\\left(n \\cdot \\mu, n \\cdot \\sigma^2 \\right)\n\\end{aligned}\n\\tag{3.5}\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#нормальна-апроксимація-й-застосування-z-критерію",
    "href": "z-test.html#нормальна-апроксимація-й-застосування-z-критерію",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.5 Нормальна апроксимація й застосування \\(Z\\)-критерію",
    "text": "3.5 Нормальна апроксимація й застосування \\(Z\\)-критерію\n\n3.5.1 Апроксимація нормальним розподілом\nЗгадайте задачу на самому початку розділу 1.1. У нас є вибірка користувачів \\(X_1,\\ X_2,\\ ...,\\ X_n,\\ X_i \\sim \\text{Bernoulli}(\\mu)\\) з параметром \\(\\mu\\), й ми хочемо перевірити гіпотезу:\n\\[\nH_0: \\mu =\\mu_0 = 0.5\\ \\text{проти} \\ H_1: \\mu &gt; 0.5\n\\] де \\(\\mu_0\\) — гіпотетичне значення параметра \\(\\mu\\).\nРаніше, ми вирішували цю задачу через біноміальний розподіл:\n\n\\(T(X^n) = \\underset{i=1}{\\overset{n}{\\sum}} X_i,\\ T \\overset{H_0}{\\sim} \\text{Binom} (n, \\mu_0)\\)\nНехай реалізація \\(T(X^n) = t\\). Тоді\n\\(p\\text{-значення} = P_{H_0}(T(X^n) \\geq t) = 1 - P_{H_0}(T(X^n) &lt; t)\\)\n\nЗгадаємо, як вирішити цю задачу за допомогою Python.\nА тепер подивимося, що нам говорить ЦГТ:\n\nЗа досить великого розміру вибірки \\(\\underset{i=1}{\\overset{n}{\\sum}} X_i \\sim \\mathcal{N}\\left(n \\cdot \\mu_0, n \\cdot \\sigma^2 \\right)\\),\n\\(X_i \\overset{H_0}{\\sim} \\text{Bernoulli} (\\mu_0)\\)\n\\(\\sigma^2 = \\mu_0 \\cdot (1 - \\mu_0)\\)\n\\(p\\text{-value} = P_{H_0}(T(X^n) \\geq t)\\).\n\nПри цьому цього разу ми дивимося статистику не в точці \\(t-1\\), як робили раніше, а в точці \\(t\\), оскільки у нас неперервний розподіл, то нам не потрібно віднімати 1:\n\nу разі нормального розподілу: \\(P(T(X^n) \\geq t) = P(T(X^n) &gt; t) = 1 - P(T(X^n) \\leq t)\\);\nу разі біноміального розподілу: \\(P(T(X^n) \\geq t) = 1 - P(T(X^n) \\leq t - 1)\\).\n\nПодивимось, як це виглядає в Python. Для цього створимо функцію get_pvalue_by_normal_approx, яка буде приймати на вхід параметри \\(n\\), \\(\\mu_0\\), \\(t\\) та повертати \\(p\\)-значення. Порівняємо результати за точним біноміальним тестом та нашим наближенням.\n\n\n\ndef get_pvalue_by_normal_approx(t, n, mu_0):\n    \"\"\"\n    Функція для обчислення p-значення за нормальною апроксимацією\n\n    t: реалізація статистики\n    n: кількість спостережень\n    mu_0: гіпотетичне значення параметра mu\n    \"\"\"\n1    mu = n * mu_0\n2    sigma = np.sqrt(n * mu_0 * (1 - mu_0))\n3    return 1 - norm(loc=mu, scale=sigma).cdf(t)\n\n4n = 30\n5mu_0 = 0.5\n6t = 19\n\n7p_value = get_pvalue_by_normal_approx(t, n, mu_0)\np_value = binomtest(t, n, mu_0, alternative='greater').pvalue\n\n8print(f\"p-значення за нормальною апроксимацією = {p_value:.4f}\")\n9print(f\"p-значення за точним біноміальним тестом = {p_value:.4f}\")\n\n\n1\n\nМатематичне сподівання біноміального розподілу.\n\n2\n\nСтандартне відхилення.\n\n3\n\nОбчислення \\(p\\)-значення.\n\n4\n\nКількість спостережень.\n\n5\n\nГіпотетичне значення параметра \\(\\mu\\).\n\n6\n\nРеалізація статистики.\n\n7\n\nОбчислення \\(p\\)-значення.\n\n8\n\nВиведення \\(p\\)-значення.\n\n9\n\nВиведення точного \\(p\\)-значення.\n\n\n\n\np-значення за нормальною апроксимацією = 0.1002\np-значення за точним біноміальним тестом = 0.1002\n\n\n\n\nМи бачимо, що значення не дуже-то й збіглися. Але, як ми пам’ятаємо, нормальна апроксимація працює тільки з деякого великого \\(n\\). Тому давайте спробуємо повторити експеримент із більшаимо кількість спостережень.\n\n\n\nn = 3000\nmu_0 = 0.5\nt = 1544\n\np_value = get_pvalue_by_normal_approx(t, n, mu_0)\np_value = binomtest(t, n, mu_0, alternative='greater').pvalue\n\nprint(f\"p-значення за нормальною апроксимацією = {p_value:.4f}\")\nprint(f\"p-значення за точним біноміальним тестом = {p_value:.4f}\")\n\np-значення за нормальною апроксимацією = 0.0561\np-значення за точним біноміальним тестом = 0.0561\n\n\n\n\nМи бачимо, що відмінність тепер тільки в 3 знаку після коми, а не в другому, як раніше. Що більше ми братимемо вибірку, то меншою буде помилка про що говорить ЦГТ.\n\n\n3.5.2 \\(Z\\)-критерій Фішера\n\\(Z\\)-критерій Фішера використовується для перевірки гіпотез про математичне сподівання випадкової величини з відомою дисперсією. Він є одним із найпоширеніших критеріїв у статистиці, оскільки дозволяє оцінити, чи є різниця між середніми значеннями двох груп статистично значущою.\nДля двостороннього критерію ми можемо використовувати \\(Z\\)-критерій Фішера, але з урахуванням того, що ми перевіряємо гіпотезу про те, що \\(\\mu\\) не дорівнює \\(\\mu_0\\). Тобто, ми хочемо перевірити, чи є різниця між середніми значеннями двох груп статистично значущою в обидва боки.\nНульова та альтернативна гіпотези для двостороннього \\(Z\\)-критерію Фішера мають вигляд:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{проти} \\quad H_1: \\mu \\neq \\mu_0\n\\tag{3.6}\\] де \\(\\mu_0\\) — гіпотетичне значення параметра \\(\\mu\\).\nСтатистика \\(Z\\)-критерію Фішера має вигляд:\n\\[\nZ = \\dfrac{\\overline X - \\mu_0}{\\sigma / \\sqrt{n}}\n\\tag{3.7}\\] де \\(\\overline X\\) — середнє арифметичне вибірки, \\(\\sigma\\) — відома дисперсія генеральної сукупності, \\(n\\) — кількість спостережень.\nПри достатньо великій вибірці згідно ЦГТ \\(Z\\)-критерій Фішера має нормальний розподіл:\n\\[\nZ(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\n\\tag{3.8}\\]\nДвосторонній критерій набуває вигляду:\n\\[\nP_{H_0}(Z(X) \\geq z) = 1 - P_{H_0}(Z(X) &lt; z) = 1 - \\Phi(z) = \\dfrac{\\alpha}{2}\n\\tag{3.9}\\] де \\(\\alpha\\) — рівень значущості.\nА \\(p\\)-значення для двостороннього критерію розраховується за формулою:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right]\n\\tag{3.10}\\]\nОдносторонній критерій перевіряє гіпотезу про те, що \\(\\mu\\) більше або менше \\(\\mu_0\\). Нульова та альтернативна гіпотези для одностороннього \\(Z\\)-критерію Фішера мають вигляд:\n\\[\nH_0: \\mu = \\mu_0 \\quad \\text{проти} \\quad H_1: \\mu &gt; \\mu_0\n\\tag{3.11}\\]\nТоді односторонній \\(Z\\)-критерій Фішера має вигляд:\n\\[\nP_{H_0}(Z(X) \\geq z) = 1 - P_{H_0}(Z(X) &lt; z) = 1 - \\Phi(z) = \\alpha\n\\tag{3.12}\\] де \\(\\Phi(z)\\) — функція розподілу стандартного нормального розподілу, \\(\\alpha\\) — рівень значущості, \\(z\\) — реалізація статистики \\(Z\\)-критерію Фішера.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#z-критерій-фішера-в-python",
    "href": "z-test.html#z-критерій-фішера-в-python",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.6 \\(Z\\)-критерій Фішера в Python",
    "text": "3.6 \\(Z\\)-критерій Фішера в Python\nНапишемо функцію z_test_pvalue, яка буде приймати на вхід параметри sample_mean (середнє арифметичне вибірки), sample_size (кількість спостережень), population_mean (гіпотетичне значення параметра \\(\\mu\\)), population_variance (дисперсія генеральної сукупності) та alternative (альтернативна гіпотеза). Функція буде повертати \\(p\\)-значення для двостороннього або одностороннього \\(Z\\)-критерію Фішера.\n\n\n\ndef z_test_pvalue(\n    sample_mean,\n    sample_size,\n    population_mean,\n    population_variance,\n    alternative='two-sided'\n):\n    \"\"\"\n    Функція для обчислення p-значення за Z-критерієм Фішера\n\n    sample_mean: середнє арифметичне вибірки\n    sample_size: кількість спостережень\n    population_mean: гіпотетичне значення параметра mu\n    population_variance: дисперсія генеральної сукупності\n    alternative: альтернативна гіпотеза\n    \"\"\"\n    standard_error = np.sqrt(population_variance) / np.sqrt(sample_size)\n1    z = (sample_mean - population_mean) / standard_error\n\n2    if alternative == 'two-sided':\n3        p_value = 2 * min(norm.cdf(z), 1 - norm.cdf(z))\n4    elif alternative == 'greater':\n5        p_value = 1 - norm.cdf(z)\n6    elif alternative == 'less':\n7        p_value = norm.cdf(z)\n    else:\n8        raise ValueError(\"Оберіть одну з альтернатив: ['two-sided', 'greater', 'less']\")\n\n9    return p_value\n\n\n1\n\nОбчислення статистики \\(Z\\)-критерію Фішера.\n\n2\n\nПеревірка двосторонньої гіпотези.\n\n3\n\nОбчислення \\(p\\)-значення для двостороннього \\(Z\\)-критерію Фішера.\n\n4\n\nПеревірка правосторонньої гіпотези.\n\n5\n\nОбчислення \\(p\\)-значення для правостороннього \\(Z\\)-критерію Фішера.\n\n6\n\nПеревірка лівосторонньої гіпотези.\n\n7\n\nОбчислення \\(p\\)-значення для лівостороннього \\(Z\\)-критерію Фішера.\n\n8\n\nВиклик помилки, якщо альтернативна гіпотеза не відповідає жодній з можливих.\n\n9\n\nПовернення \\(p\\)-значення.\n\n\n\n\n\n\nТепер ми можемо перевірити гіпотезу про те, що \\(\\mu\\) не дорівнює \\(\\mu_0\\), за допомогою \\(Z\\)-критерію Фішера. Для цього ми можемо використати функцію z_test_pvalue та порівняємо з результатами, які ми отримали раніше за допомогою біноміального тесту та нормальної апроксимації.\n\n\n\nn = 30\nmu_0 = 0.5\nt = 19\n1sample_mean = t / n\n2population_variance = mu_0 * (1 - mu_0)\n\np_value = z_test_pvalue(sample_mean, n, mu_0, population_variance, alternative='greater')\nprint(f\"p-значення за Z-критерієм Фішера = {p_value:.4f}\")\nprint(f\"p-значення за нормальною апроксимацією = {get_pvalue_by_normal_approx(t, n, mu_0):.4f}\")\nprint(f\"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}\")\n\n\n1\n\nОбчислення математичного сподівання вибірки.\n\n2\n\nДисперсія генеральної сукупності.\n\n\n\n\np-значення за Z-критерієм Фішера = 0.0721\np-значення за нормальною апроксимацією = 0.0721\np-значення за точним біноміальним тестом = 0.1002\n\n\n\n\nМи бачимо, що \\(p\\)-значення за \\(Z\\)-критерієм Фішера та нормальною апроксимацією збігаються, а точний біноміальний тест дає трохи інше значення. Залишається питання: чи можна уточнити результати \\(Z\\)-тесту при малих вибірках? Відповідь: так, можна. Для цього існує поправка на неперервність, яка дозволяє покращити точність апроксимації і її ми розглянемо далі.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-continuity-correction",
    "href": "z-test.html#sec-continuity-correction",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.7 Поправка на неперервність",
    "text": "3.7 Поправка на неперервність\nЗадля кращого розуміння, давайте спочатку візуалізуємо \\(p\\)-значення в залежності від величини успіхів експерименту \\(t\\) для біноміального тесту та \\(Z\\)-критерію Фішера. Для цього побудуємо три варіанти:\n\n\\(p\\)-значення за нормальною апроксимацією.\n\nРозрахунок в Python: 1 - norm.cdf(t).\n\n\\(p\\)-значення біноміального тесту за умови, що \\(t\\) — неціле число.\n\nРозглянемо на прикладі \\(t = 19.5\\), тоді \\(p\\)-значення буде дорівнювати \\[\\begin{aligned}P(T(X) \\geq t) &= P(T(X) \\geq 19.5) \\\\ &= 1 - P(T(X) &lt; 19.5) \\end{aligned}\\]\nРозрахунок в Python: 1 - binom.cdf(t, n, mu_0).\n\n\\(p\\)-значення біноміального тесту за умови, що \\(t\\) — ціле число.\n\nРозглянемо на прикладі \\(t = 19\\), тоді \\(p\\)-значення буде дорівнювати \\[\\begin{aligned}P(T(X) \\geq t) &= P(T(X) \\geq 19) \\\\ &= 1 - P(T(X) \\leq 18)\\end{aligned}\\]\nРозрахунок в Python: 1 - binom.cdf(t - 1, n, mu_0).\n\n\n\n\n\ndef cmp_pvalue_binom_and_norm(n, mu0, t, add_to_x=0):\n    \"\"\"\n    Функція для порівняння p-значення біноміального та нормального розподілів\n\n    n: кількість спостережень\n    mu0: гіпотетичне значення параметра mu\n    t: реалізація статистики\n    add_to_x: додатковий доданок до x-координати\n    \"\"\"\n    x_axis = np.linspace(0, n, 1000)\n    dots_to_show = np.arange(0, n + 1, 1)\n\n1    add_str = \"\" if add_to_x == 0 else f\"{add_to_x}\"\n\n2    sum_mu = n * mu0\n    sum_variance = n * mu0 * (1 - mu0)\n    sum_std = np.sqrt(sum_variance) # 2&gt;\n\n3    binom_dist = binom(n=n, p=mu0)\n    norm_dist = norm(loc=sum_mu, scale=sum_std)\n\n    plt.hlines(1 - binom_dist.cdf(x_axis[:-1]), x_axis[:-1], x_axis[1:],\n               color=turquoise, linestyle='-',linewidth=1)\n    plt.vlines(x_axis[:-1], 1 - binom_dist.cdf(x_axis[:-1]), \n               1 - binom_dist.cdf(x_axis[1:]),\n               color=turquoise, linestyle=':', linewidth=1)\n    \n4    plt.scatter(dots_to_show, 1 - binom_dist.cdf(dots_to_show-1), color=turquoise,\n                alpha=1, linewidths=0.5, s=25,\n                label=f'Binom pvalue = 1-binom.cdf(x-1)')\n\n5    plt.scatter(t, 1 - norm_dist.cdf(t + add_to_x), color=red_pink,\n                alpha=1, marker='o', s=50, label=f'norm p-value({t})')\n\n6    plt.scatter(t, 1 - binom_dist.cdf(t - 1), color=turquoise, marker='o',\n                alpha=1, s=50, label=f'binom p-value({t})')\n\n7    plt.plot(x_axis, 1 - norm_dist.cdf(x_axis + add_to_x), color=red_pink,\n             alpha=0.5, label=f'Normal pvalue = 1-norm.cdf(x{add_str})')\n\n    \n\n    plt.legend()\n    plt.xlabel('t')\n    plt.ylabel('$p$-значення')\n    plt.show()\n\n\n1\n\nДодатковий доданок до \\(x\\)-координати (про нього ми поговоримо пізніше).\n\n2\n\nПараметри нормального розподілу.\n\n3\n\nСтворення біноміального та нормального розподілів.\n\n4\n\n\\(p\\)-значення біноміального розподілу.\n\n5\n\n\\(p\\)-значення нормального розподілу.\n\n6\n\n\\(p\\)-значення біноміального розподілу у точці \\(t\\).\n\n7\n\n\\(p\\)-значення нормального розподілу у точці \\(t\\).\n\n\n\n\n\n\nТепер ми можемо порівняти \\(p\\)-значення біноміального та нормального розподілів. Для цього викличемо функцію cmp_pvalue_binom_and_norm з параметрами \\(n\\), \\(\\mu_0\\), \\(t\\).\n\n\n\nn = 30\nmu_0 = 0.5\nt = 15\n\nfig, ax = plt.subplots(figsize=(8, 2.5))\ncmp_pvalue_binom_and_norm(n, mu_0, t)\n\n\n\n\nПорівняння p-значення біноміального та нормального розподілів\n\n\n\n\nЯкщо порівняти різницю між \\(p\\)-значеннями біноміального та нормального розподілів, то ми отримаємо, що \\(p\\)-значення біноміального розподілу завжди більше за \\(p\\)-значення нормального розподілу. При цьому із збільшенням вибірки ця різниця зменшується. Давайте подивимось на ці різниці для різних значень \\(t\\).\nДля початку візьмемо \\(n = 20\\) та \\(t = 10\\).\n\n\n\nn = 20\nt = 10\nmu_0 = 0.5\n\n1binom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\n2norm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\n3diff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\n\n1\n\n\\(p\\)-значення біноміального розподілу.\n\n2\n\n\\(p\\)-значення нормального розподілу.\n\n3\n\nРізниця між \\(p\\)-значеннями.\n\n\n\n\np-значення біноміального розподілу = 0.5881\np-значення нормального розподілу = 0.5000\nРізниця між p-значеннями = 0.0881\n\n\n\n\nТепер візьмемо \\(n = 20\\) та \\(t = 16\\).\n\n\n\nn = 20\nt = 16\nmu_0 = 0.5\n\nbinom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\nnorm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\ndiff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\np-значення біноміального розподілу = 0.0059\np-значення нормального розподілу = 0.0036\nРізниця між p-значеннями = 0.0023\n\n\n\n\nІ накінці візьмемо \\(n = 200\\) та \\(t = 100\\).\n\nn = 200\nt = 100\nmu_0 = 0.5\n\nbinom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\nnorm_pvalue = 1 - norm(loc=n * mu_0, scale=np.sqrt(n * mu_0 * (1 - mu_0))).cdf(t)\ndiff = binom_pvalue - norm_pvalue\n\nprint(f\"p-значення біноміального розподілу = {binom_pvalue:.4f}\")\nprint(f\"p-значення нормального розподілу = {norm_pvalue:.4f}\")\nprint(f\"Різниця між p-значеннями = {diff:.4f}\")\n\np-значення біноміального розподілу = 0.5282\np-значення нормального розподілу = 0.5000\nРізниця між p-значеннями = 0.0282\n\n\n\n\nМи бачимо, що з ростом вибірки різниця між \\(p\\)-значеннями біноміального та нормального розподілів зменшується. Але як зробити так, щоб два \\(p\\)-значення збіглися? Для цього слід звернути увагу на точки перетину двох ліній: біноміального та нормального розподілів. Зауважимо, що вони перетинаються приблизно на середині відрізка: між \\(t-1\\) та \\(t\\). Тому спробуємо “змістити” графік нормального розподілу на \\(0.5\\) праворуч.\n\\[\nF_{\\text{new}}(x) = F_{\\text{old}}(x - 0.5)\n\\tag{3.13}\\]\nЦе означає, що ми повинні відняти \\(0.5\\) від \\(x\\)-координати точки перетину. Тобто, ми можемо використовувати поправку на неперервність, яка дозволяє покращити точність апроксимації. Тоді \\(p\\)-значення для біноміального розподілу буде дорівнювати:\n\\[\np\\text{-значення} = 1 - \\Phi(t - 0.5)\n\\tag{3.14}\\] де \\(\\Phi(t - 0.5)\\) — функція розподілу стандартного нормального розподілу.\nПодивимось на графік з поправкою на неперервність.\n\n\n\ncmp_pvalue_binom_and_norm(30, 0.5, 15, add_to_x=-0.5)\n\n\n\n\n\n\n\n\nМи бачимо, що \\(p\\)-значення біноміального та нормального розподілів тепер збігаються.\nПорівняємо \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність.\n\n\n\nn = 30\nt = 19\nmu_0 = 0.5\n\nmu = n * mu_0\nsigma = np.sqrt(mu * (1 - mu_0))\nnormal = norm(loc=mu, scale=sigma)\n\n1binom_pvalue = 1 - binom(n, mu_0).cdf(t - 1)\n2norm_pvalue = 1 - normal.cdf(t)\n3norm_pvalue_correct = 1 - normal.cdf(t - 0.5)\n\nprint(f\"p (біном) = {binom_pvalue:.4f}\")\nprint(f\"p (нормальне наближення) = {norm_pvalue:.4f}\")\nprint(f\"p (з поправкою на неперервність) = {norm_pvalue_correct:.4f}\")\n\n\n1\n\n\\(p\\)-значення біноміального розподілу.\n\n2\n\n\\(p\\)-значення нормального розподілу.\n\n3\n\n\\(p\\)-значення нормального розподілу з поправкою на неперервність.\n\n\n\n\np (біном) = 0.1002\np (нормальне наближення) = 0.0721\np (з поправкою на неперервність) = 0.1006\n\n\n\n\nМи бачимо, що \\(p\\)-значення біноміального та нормального розподілів з поправкою на неперервність тепер збігаються.\nДодамо поправку на неперервність до нашої функції z_test_pvalue.\n\n\n\ndef z_test_pvalue(\n    sample_mean, \n    sample_size, \n    population_mean, \n    population_variance, \n    alternative='two-sided', \n    continuity_correction=False\n):\n    \"\"\"\n    Функція для обчислення p-значення за Z-критерієм Фішера з поправкою на неперервність\n\n    sample_mean: середнє арифметичне вибірки\n    sample_size: кількість спостережень\n    population_mean: гіпотетичне значення параметра mu\n    population_variance: дисперсія генеральної сукупності\n    alternative: альтернативна гіпотеза\n    continuity_correction: поправка на неперервність\n    \"\"\"\n    if continuity_correction:\n        sample_mean = (sample_mean * sample_size - 0.5) / sample_size\n\n    se = np.sqrt(population_variance) / np.sqrt(sample_size)\n    z = (sample_mean - population_mean) / se\n\n    match alternative:\n        case 'two-sided':\n            p_value = 2 * min(norm.cdf(z), 1 - norm.cdf(z))\n        case 'greater':\n            p_value = 1 - norm.cdf(z)\n        case 'less':\n            p_value = norm.cdf(z)\n        case _:\n            raise ValueError(\"Оберіть альтернативу: ['two-sided', 'greater', 'less']\")\n\n    return p_value\n\n\nПеревірка наявності поправки на неперервність.\n\n\n\nТепер ми можемо використовувати функцію z_test_pvalue з параметром continuity_correction=True, щоб отримати \\(p\\)-значення з поправкою на неперервність.\n\n\n\nn = 30\nt = 19\nmu0 = 0.5\nvariance = mu0 * (1 - mu0)\n\np = z_test_pvalue(\n    t / n,\n    n,\n    mu0,\n    variance,\n     alternative='greater',\n     continuity_correction=True\n)\n\nprint(f\"p-значення (Z-критерій з поправкою) = {p:.4f}\")\n\np-значення (Z-критерій з поправкою) = 0.1006\n\n\n\n\nЧудово, тепер ми можемо використовувати \\(Z\\)-критерій Фішера з поправкою на неперервність для перевірки гіпотез про математичне сподівання випадкової величини з відомою дисперсією. Але що робити, якщо дисперсія невідома? Для цього існує \\(t\\)-критерій Стьюдента, який ми розглянемо далі.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#sec-questions-3",
    "href": "z-test.html#sec-questions-3",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "3.8 Питання для самоперевірки",
    "text": "3.8 Питання для самоперевірки\nЗагальне розуміння та Z-критерій\n\nЯка основна мета використання \\(Z\\)-критерію Фішера? Для перевірки яких гіпотез він призначений?\nЯка ключова вимога (припущення) щодо дисперсії генеральної сукупності для застосування \\(Z\\)-критерію?\nЧому знання про нормальний розподіл є необхідним для розуміння та застосування \\(Z\\)-критерію?\n\nНормальний розподіл\n\nЯкими двома параметрами характеризується нормальний розподіл \\(\\mathcal{N}(\\mu, \\sigma^2)\\)? Що кожен з них означає?\nНапишіть формулу щільності ймовірності (PDF) для нормального розподілу.\nУ бібліотеці scipy.stats для класу norm, що означають параметри loc та scale? Як scale пов’язаний з дисперсією \\(\\sigma^2\\)?\nПоясніть своїми словами, що обчислюють методи .pdf(x), .cdf(x) та .ppf(q) для об’єкта norm?\nЯкщо \\(\\xi_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)\\) та \\(\\xi_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\\) є незалежними, який розподіл матиме їх сума \\(\\xi_1 + \\xi_2\\)? Вкажіть параметри.\nЯкщо \\(\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) і \\(a\\) — константа, який розподіл матиме величина \\(a \\xi\\)? Вкажіть параметри.\n\nЦентральна гранична теорема (ЦГТ)\n\nСформулюйте Центральну граничну теорему. Про розподіл якої величини вона говорить?\nЯкі основні умови повинні виконуватися для випадкових величин \\(\\xi_1, ..., \\xi_n\\), щоб до них можна було застосувати ЦГТ?\nЗапишіть формулу статистики з ЦГТ, яка збігається до стандартного нормального розподілу \\(\\mathcal{N}(0, 1)\\).\nЧому ЦГТ є такою важливою в статистиці, особливо для перевірки гіпотез?\nЧи обов’язково початкові дані мають бути нормально розподілені, щоб вибіркове середнє (при великому \\(n\\)) було приблизно нормально розподіленим? Поясніть.\nЯк розмір вибірки (\\(n\\)) впливає на якість апроксимації розподілу вибіркового середнього нормальним розподілом згідно з ЦГТ?\n\nНормальна апроксимація та застосування Z-критерію\n\nЯк ЦГТ дозволяє використовувати нормальний розподіл для наближеного обчислення ймовірностей для біноміального розподілу при великому \\(n\\)?\nЯка формула для тестової статистики \\(Z\\) у \\(Z\\)-критерії Фішера? Поясніть кожну складову формули.\nЯкий теоретичний розподіл має статистика \\(Z\\) за умови істинності нульової гіпотези \\(H_0: \\mu = \\mu_0\\)?\nЯк обчислити \\(p\\)-значення для двостороннього \\(Z\\)-критерію (\\(H_1: \\mu \\neq \\mu_0\\)), знаючи реалізацію статистики \\(z\\)?\nЯк обчислити \\(p\\)-значення для правостороннього \\(Z\\)-критерію (\\(H_1: \\mu &gt; \\mu_0\\)), знаючи реалізацію статистики \\(z\\)?\nПорівняйте \\(Z\\)-критерій (де статистика базується на \\(\\overline{X}\\)) та нормальну апроксимацію біноміального розподілу (де статистика базується на сумі \\(\\sum X_i\\)). Чи є вони по суті еквівалентними? Чому?\n\nПоправка на неперервність\n\nУ яких ситуаціях виникає потреба у поправці на неперервність? Яку проблему вона допомагає вирішити?\nЯк зазвичай застосовується поправка на неперервність при обчисленні \\(P(T \\ge t)\\) за допомогою нормального розподілу, де \\(T\\) — дискретна випадкова величина (наприклад, біноміальна)? (Наприклад, як змінюється значення \\(t\\) у формулі?)\nЯк функція z_test_pvalue (у її покращеній версії) враховує поправку на неперервність?\n\nПідсумкові питання\n\nЗа яких умов ви б віддали перевагу точному біноміальному тесту перед Z-критерієм (з або без поправки) для аналізу даних типу успіх/невдача (Bernoulli)?\nЯке основне обмеження \\(Z\\)-критерію, згадане наприкінці розділу, мотивує перехід до \\(t\\)-критерію Стьюдента?\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "z-test.html#footnotes",
    "href": "z-test.html#footnotes",
    "title": "3  \\(Z\\)-критерій Фішера",
    "section": "",
    "text": "Документація доступна за посиланням https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html.↩︎\nДоведення цих властивостей можна знайти в роботі Lemons (2002).↩︎\nПослідовність випадкових величин \\(\\xi_n\\) збігається за розподілом до \\(\\xi\\), позначаємо \\(\\xi_n \\xrightarrow{d} \\xi\\), якщо \\(\\lim_{n \\to \\infty} F_{\\xi_n}(x) = F_{\\xi}(x)\\) для всіх \\(x\\), в яких \\(F_{\\xi}(x)\\) неперервна.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$Z$-критерій Фішера</span>"
    ]
  },
  {
    "objectID": "t-test.html",
    "href": "t-test.html",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "4.1 Основні положення\nСпробуємо розв’язати таке завдання.\nДля початку переформулюємо умову мовою математики. Є вибірка:\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\nprint(f\"Середнє значення: {np.mean(meeting_time):.2f} хвилин\")\n\nСереднє значення: 58.57 хвилин\nНаша гіпотеза звучить так:\n\\[\nH_0: E \\overline{X} \\geq 70 \\; \\text{проти} \\; H_1: E \\overline{X} &lt; 70\n\\]\nЗдається, що ми таке вже вміємо вирішувати: згадаємо про \\(Z\\)-критерій:\n\\[\nH_0: \\mu \\leq \\mu_0\\ \\; \\text{проти} \\; \\ H_1: \\mu &gt; \\mu_0\n\\]\nТоді треба лише порахувати таку статистику: \\(\\sqrt{n}\\dfrac{\\overline X - 70}{\\sqrt{\\sigma^2}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\).\nАле є суттєва проблема: ми не знаємо \\(\\sigma^2\\)! Тому ми не можемо використовувати \\(Z\\)-критерій.\nДавайте спробуємо оцінити \\(\\sigma^2\\) за допомогою вибірки. Для цього скористаємося формулою:\n\\[\n\\hat{\\sigma}^2 = S^2 = \\dfrac{1}{n - 1} \\sum_{i=1}^n (X_i - \\overline X)^2\n\\tag{4.1}\\]\nВона називається вибірковою дисперсією. Вибіркова дисперсія є незміщеною та консистентною оцінкою дисперсії генеральної сукупності.\nВибіркова дисперсія є незміщеною, оскільки ми ділимо на \\(n - 1\\), а не на \\(n\\). Це робиться для того, щоб уникнути систематичної помилки в оцінці дисперсії. Консистентність пояснюється тим, що з ростом вибірки \\(n\\) ми все ближче підходимо до істинної дисперсії генеральної сукупності.\nДля розрахунку вибіркової дисперсії в Python можна скористатися функцією np.var з параметром ddof=1, що означає, що ми ділимо на \\(n - 1\\).\nmeeting_time_var = np.var(meeting_time, ddof=1)\nprint(f\"Вибіркова дисперсія: {meeting_time_var:.2f} хвилин\")\n\nВибіркова дисперсія: 222.62 хвилин\nДавайте введемо новий критерій \\(t'\\)-тест, у якому ми підставимо:\nЗалишилося перевірити: Чи правда, що при \\(H_0\\) розподіл \\(t\\)-статистики — стандартний нормальний?\nДля цього пропонується подивитися, як насправді буде розподілена статистика \\(t(X) = \\sqrt{n}\\dfrac{\\overline{X}-\\mu_0}{\\sqrt{S^2}}\\) у завданні, яке було поставлено від початку.\nДля цього будемо вважати, що вибірка \\(X\\) складається з 7 елементів й \\(X \\sim \\mathcal{N}\\).\nДля цього ми напишемо функцію sample_statistics, яка зможе побудувати розподіл для будь-якої статистики, а не тільки для \\(t(X), Z(X)\\). Вона приймає на вхід:\ndef sample_statistics(\n    number_of_experiments,\n    statistic_function, \n    sample_size, \n    sample_distr\n):\n    \"\"\"\n    Генерує вибірку з розподілу та обчислює статистику для кожної вибірки.\n    \n    number_of_experiments: кількість експериментів\n    statistic_function: функція, яка обчислює статистику\n    sample_size: розмір вибірки\n    sample_distr: розподіл, з якого генеруємо вибірку\n    \"\"\"\n    statistic_sample = []\n    for _ in range(number_of_experiments):\n        sample = sample_distr.rvs(sample_size)\n        statistic = statistic_function(sample)\n        statistic_sample.append(statistic)\n    return statistic_sample\nТепер перевіримо, чи дійсно \\(t(X)\\) розподілена нормально. Для цього скористаємося функцією sample_statistics та побудуємо гістограму для \\(t(X)\\). Генерувати вибірку будемо з нормального розподілу \\(\\mathcal{N}(5, 3^2)\\).\n1sample_size = 7\nM = 100000\nsample_distr = norm(loc=5, scale=3)\n\n2T_X = lambda x: (\n    np.sqrt(sample_size) * (np.mean(x) - sample_distr.mean()) /\n    np.sqrt(np.var(x, ddof=1))\n)\n\nZ_X = lambda x: (\n    np.sqrt(sample_size) * (np.mean(x) - sample_distr.mean()) /\n    sample_distr.std()\n)\n\n3samples = {\n    \"T(X)\": sample_statistics(\n    number_of_experiments=M, statistic_function=T_X,\n    sample_size=sample_size, sample_distr=sample_distr),\n\n    \"Z(X)\": sample_statistics(\n    number_of_experiments=M, statistic_function=Z_X,\n    sample_size=sample_size, sample_distr=sample_distr)\n}\n\n4for i, name in enumerate([\"T(X)\", \"Z(X)\"]):\n    plt.subplot(1, 2, i + 1)\n    current_sample = samples[name]\n    l_bound, r_bound = np.quantile(current_sample, [0.001, 0.999])\n\n    x = np.linspace(l_bound, r_bound, 1000)\n    sns.distplot(current_sample, label='Емпіричний розподіл', color=turquoise)\n    plt.plot(x, norm(0, 1).pdf(x), label='$\\mathcal{N}(0, 1)$', color=red_pink)\n    plt.legend(loc='upper left')\n    plt.xlabel(f'{name}')\n    plt.xlim((l_bound, r_bound))\n    plt.ylabel('Щільність')\n    plt.grid(linewidth=0.2)\n\nplt.show()\n\n\n1\n\nФормування параметрів.\n\n2\n\nСтатистика \\(t(X)\\) та \\(Z(X)\\).\n\n3\n\nГенерація вибірки та обчислення статистики.\n\n4\n\nВізуалізація результатів.\n\n\n\n\n\n\n\n\n\n\nРисунок 4.1: Симуляція розподілу \\(t(X)\\) та \\(Z(X)\\)\nМи бачимо, що:\nДля того щоб стало зрозуміло, чому так сталося, розглянемо \\(t(X)\\) у деталях. При створенні критерію є два кроки:\nАле чому \\(t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}}\\) не розподілена нормально, хоча \\(\\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{\\sigma^2}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\)$? Чому при заміні \\(\\sigma^2\\) на \\(S^2\\) усе зіпсувалося?\nСправа в тому, що \\(S^2\\) — це випадкова величина! Згадаймо, як ми виводили \\(Z\\)-критерій:\nАле ми нічого не знаємо про \\(\\dfrac{\\overline{X}}{\\sqrt{\\eta}}\\), де \\(\\overline{X} \\sim \\mathcal{N}, S^2 := \\eta \\sim P\\), де \\(P\\) невідомо. Ми не знаємо поки що жодних теорем, які б хоч якось доводили, що тут також залишиться нормальний розподіл.\nДавайте подивимося на розподіл \\(\\sqrt{S^2}\\) на все тому ж нормальному розподілі.\n1S2 = lambda sample: np.std(sample, ddof=1)\n2S2_sample = sample_statistics(\n    number_of_experiments=M, statistic_function=S2,\n    sample_size=sample_size, sample_distr=sample_distr\n)\n\nsns.distplot(S2_sample, label='Емпіричний розподіл', color=turquoise)\nplt.legend()\nplt.xlabel('$\\sqrt{S^2}$')\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n1\n\nСтатистика \\(S^2\\).\n\n2\n\nГенерація вибірки та обчислення статистики.\n\n\n\n\n\n\n\n\n\n\nРисунок 4.2: Розподіл \\(\\sqrt{S^2}\\)\nРозподіл \\(\\sqrt{S^2}\\) несиметричний й незрозуміло як розподілений. Тому, коли ми якусь величину з нормального розподілу ділимо на несиметричний незрозумілий розподіл, ми й отримуємо, що наша статистика \\(t\\) не з нормального розподілу.\nТож давайте виведемо критерій, який допоможе розв’язати початкову задачу!",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#основні-положення",
    "href": "t-test.html#основні-положення",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "Приклад 4.1  \n\nМенеджмент компанії розглядає новий підхід до планування щотижневих нарад, щоб зменшити втрати часу співробітників. Раніше середня тривалість таких нарад складала 70 хвилин. Ідея полягає в тому, щоб перейти до нової структури нарад, яка, за задумом, дозволить зменшити тривалість нарад до 60 хвилин.\n\n\nПротягом одного тижня провели 7 нарад у новому форматі й зафіксували їх тривалість. Якщо з’ясується, що нові наради тривають довше, ніж у середньому 70 хвилин, новий формат вважатимуть неефективним.\n\n\nВаше завдання — перевірити, чи новий формат нарад дійсно ефективніший.\n\n\nВийшла вибірка середньої тривалості нарад (в хвилинах): [50, 55, 70, 45, 40, 70, 80].\n\n\n\n\n\\(X_1, X_2, ..., X_7\\) — значення середньої тривалості нарад у новому форматі;\nБудемо вважати, що \\(X\\) з нормального розподілу, тобто \\(X \\sim N(\\mu, \\sigma^2)\\).\n\n\n\n\n\n\n\n\n\nСтатистика \\(Z(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}}\\)\nЗа досить великого розміру вибірки \\(Z(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\) (за ЦГТ)\nОдносторонній критерій: \\(\\left\\{Z(X) \\geq z_{1 - \\alpha} \\right\\}\\)\n\n\\(p\\)-значення = \\(1 - \\Phi(z)\\), де \\(z\\) — реалізація статистики \\(Z(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\)\n\nДвосторонній критерій: \\(\\left\\{Z(X) \\geq z_{1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{Z(X) \\leq -z_{1 - \\frac{\\alpha}{2}} \\right\\}\\)\n\n\\(p\\)-значення = \\(2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right]\\), де \\(z\\) — реалізація статистики \\(Z(X)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(t(X) := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\)\n\\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\)\n\n\n\n\n\nМи \\(M\\) раз згенеруємо вибірку \\(X\\) та порахуємо щоразу статистику \\(t(X)\\).\nУ підсумку ми отримаємо вибірку розміру \\(M\\) для \\(t(X)\\) й зможемо побудувати гістограму розподілу. Окремо побудуємо розподіл \\(\\mathcal{N}(0, 1)\\). Якщо емпіричний розподіл візуально збіжиться з теоретичним нормальним, значить, усе добре. А якщо ні, то так просто ми не можемо замінити \\(\\sigma^2\\) на \\(S^2\\).\n\nДодатково подивимося, що буде, якщо замінити \\(t(X)\\) на \\(Z(X)\\). Добре, що на штучному прикладі ми знаємо дисперсію.\n\n\n\n\nnumber_of_experiments — кількість експериментів, які ми хочемо провести;\nstatistic_function — функція, яка обчислює статистику;\nsample_size — розмір вибірки;\nsample_distr — розподіл, з якого ми генеруємо вибірку.\n\n\n\n\n\n\n\n\n\n\\(Z\\)-тест тут працює: \\(\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1)\\).\nАле ось для \\(t(X)\\) це не так! Вони відрізняються, а значить \\(t'\\)-критерій не підходить для початкової задачі!\n\n\n\nПридумати статистику для критерію\n\nІз цим ми успішно впоралися, придумавши \\(t(X)\\).\n\nЗрозуміти розподіл статистики.\n\nІ ось це найскладніший крок, який не дозволяє використовувати будь-яку придуману статистику. Потрібно також розуміти її розподіл.\nІ з цим, як ми побачили, ми провалилися для \\(t(X)\\). Нормальний розподіл не підійшов.\n\n\n\n\n\nМи порахували, що \\(\\overline X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). З ЦГТ або, у випадку вище, з властивостей нормального розподілу.\nДалі, все також із властивостей цього розподілу випливає, що якщо ми віднімемо константу або поділимо на константу, то нормальний розподіл не перетвориться на інший: тому \\(\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\sim \\mathcal{N}(0, 1)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-стьюдента",
    "href": "t-test.html#t-тест-стьюдента",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.2 \\(t\\)-тест Стьюдента",
    "text": "4.2 \\(t\\)-тест Стьюдента\nДля того щоб вивести \\(t\\)-тест, нам потрібно зрозуміти, як розподіляється статистика \\(t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\). Для того, щоб це дізнатися, нам знадобиться кілька фактів:\n\nНехай \\(X_1 \\ldots X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\nНехай \\(\\xi_1 \\ldots \\xi_n \\sim \\mathcal{N}(0, 1)\\). Тоді \\(\\eta=\\xi_1^2 +\\ ... +\\xi_n^2 \\sim \\chi^2_n\\)1.\n\nТоді \\(\\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 \\sim \\chi^2_{n-1}\\) 2.\n\\(S^2_X = \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}(X_i - \\overline X)^2\\)\n\\(\\xi_i := \\dfrac{X_i - \\mu}{\\sigma} \\sim \\mathcal{N}(0, 1)\\). Тоді \\[\\begin{aligned}\nS^2_{\\xi} &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 =\n      \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i-\\mu}{\\sigma} - \\underset{i=1}{\\overset{n}{\\sum}}\\left[\\dfrac{X_i-\\mu}{n\\sigma}\\right] \\right)^2 = \\\\\n       &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i}{\\sigma} - \\dfrac{\\mu}{\\sigma} - \\underset{i=1}{\\overset{n}{\\sum}}\\left[\\dfrac{X_i}{n\\sigma}\\right] + \\dfrac{n\\mu}{n\\sigma} \\right)^2 =\\\\\n       &= \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}} \\left(\\dfrac{X_i}{\\sigma} -\\dfrac{\\overline X_i}{\\sigma} \\right)^2 = \\dfrac{1}{\\sigma \\cdot(n - 1)}\\underset{i=1}{\\overset{n}{\\sum}} \\left(X_i - \\overline X_i \\right)^2 = \\dfrac{1}{\\sigma}S^2_X\n\\end{aligned}\n\\]\nА значить \\(\\dfrac{(n - 1)\\cdot S^2_X}{\\sigma^2} = \\underset{i=1}{\\overset{n}{\\sum}}\\left(\\xi_i - \\overline \\xi \\right)^2 \\sim \\chi^2_{n-1}\\)\n\nНехай \\(\\xi \\sim \\mathcal{N}(0, 1), \\eta \\sim \\chi^2_k\\) і \\(\\xi\\) з \\(\\eta\\) незалежні. Тоді статистика \\(\\zeta = \\dfrac{\\xi}{\\sqrt{\\eta/k}} \\sim t_{k}\\) — з розподілу Стьюдента3 з \\(k\\) ступенями свободи.\n\n\\(\\xi := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sigma} \\sim \\mathcal{N}(0, 1)\\)\n\\(\\eta := \\dfrac{(n - 1)\\cdot S^2_X}{\\sigma^2} \\sim \\chi^2_{n-1}\\)\n\\(\\xi\\) и \\(\\eta\\) незалежні4.\nТоді \\[\n\\begin{aligned}\n  t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} = \\frac{\\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sigma}}{\\sqrt{\\dfrac{(n - 1)\\cdot S^2_X}{(n - 1)\\sigma^2}}} = \\dfrac{\\xi}{\\sqrt{\\dfrac{\\eta}{n-1}}} \\sim t_{n - 1}\n\\end{aligned}\n\\]\n\n\nУ підсумку, статистика \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} \\sim t_{n - 1}\\) — взята з розподілу Стьюдента з \\(n - 1\\) ступенем свободи. Але тільки в разі, якщо початкова вибірка з нормального розподілу!\nТепер нам достатньо даних, щоб побудувати \\(t\\)-тест:\n\\[\nH_0: \\mu =\\mu_0, \\ X \\sim \\mathcal{N}\\ проти\\ H_1: \\mu &gt; \\mu_0\n\\tag{4.2}\\]\nСтатистика \\(t(X)\\) буде виглядати так:\n\\[\nt(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} \\sim t_{n - 1}\n\\tag{4.3}\\]\nТоді односторонній критерій набуває вигляду: \\[\n\\left\\{t(X) \\geq t_{n-1, 1 - \\alpha} \\right\\}\n\\tag{4.4}\\]\nА \\(p\\)-значення для одностороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 1 - \\tau_{n-1}(z),\n\\tag{4.5}\\] де z — реалізація статистики \\(t(X)\\), \\(\\tau_{n-1}(z)\\) — функція розподілу \\(t_{n - 1}\\)\nДвосторонній критерій буде виглядати так: \\[\n\\left\\{t(X) \\geq t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{t(X) \\leq -t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\}\n\\tag{4.6}\\]\nПри цьому \\(p\\)-значення для двостороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\tau_{n-1}(z), 1 - \\tau_{n-1}(z)} \\right],\n\\tag{4.7}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\tau_{n-1}(z)\\) — функція розподілу \\(t_{n - 1}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-у-python",
    "href": "t-test.html#t-тест-у-python",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.3 \\(t\\)-тест у Python",
    "text": "4.3 \\(t\\)-тест у Python\nДавайте тепер протестуємо всі наші теоретичні дослідження на практиці. Для цього нам знадобляться наступні бібліотеки функції:\n\nscipy.stats.chii2 — для розподілу \\(\\chi^2\\);\nscipy.stats.t — для \\(t\\) розподілу Стюдента;\nscipy.stats.ttest_1samp — для \\(t\\)-тесту.\n\nПодивимось на розподіл \\(\\chi^2\\) та розподіл \\(\\eta\\).\n\n\n\n1sample_size = 7\nsample_distr = norm(loc=5, scale=3)\nsample = sample_distr.rvs(sample_size)\nM = 10000\n\n2eta_stat = lambda x: (\n    np.var(x, ddof=1) * (sample_size - 1) / sample_distr.var()\n)\n\n3eta_sample = sample_statistics(\n    number_of_experiments=M,\n    statistic_function=eta_stat,\n    sample_size=sample_size,\n    sample_distr=sample_distr\n)\n\n4chi2_dist = chi2(df=sample_size - 1)\n5l, r = np.quantile(eta_sample, [0.001, 0.999])\n\nx = np.linspace(l, r, 1000)\nsns.distplot(eta_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, chi2_dist.pdf(x), label='$\\chi^2$', color=red_pink)\n\nplt.legend()\nplt.xlabel('$\\eta$')\nplt.ylabel('Щільність')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n1\n\nФормування параметрів.\n\n2\n\nСтатистика \\(\\eta\\).\n\n3\n\nГенерація вибірки та обчислення статистики.\n\n4\n\nРозподіл \\(\\chi^2\\).\n\n5\n\nВізуалізація результатів.\n\n\n\n\n\n\n\n\n\n\nРисунок 4.3: Розподіл емпіричного \\(\\eta\\) та теоретичного \\(\\chi^2\\).\n\n\n\n\n\nМи бачимо, що емпіричний розподіл \\(\\eta\\) та теоретичний \\(\\chi^2\\) збігаються. Це означає, що ми можемо використовувати \\(t\\)-тест для перевірки гіпотези.\nТепер перевіримо, чи дійсно \\(t(X)\\) описується розподілом Стьюдента. Для цього скористаємося функцією sample_statistics та побудуємо гістограму для \\(t(X)\\). Генерувати вибірку будемо з нормального розподілу \\(\\mathcal{N}(5, 3^2)\\).\n\n\n\nsample_size = 7\nsample_distr = norm(loc=5, scale=3)\nsample = sample_distr.rvs(sample_size)\nM = 10_000\n\nT_X = lambda x: (\n    np.sqrt(sample_size) * (np.mean(x) - sample_distr.mean()) /\n    np.std(x, ddof=1)\n)\n\nT_sample = sample_statistics(\n    number_of_experiments=M,\n    statistic_function=T_X,\n    sample_size=sample_size,\n    sample_distr=sample_distr\n)\n\nT_dist = t(df=sample_size - 1)\nl, r = np.quantile(T_sample, [0.001, 0.999])\nx = np.linspace(l, r, 1000)\n\nsns.distplot(T_sample, color=turquoise, label='Емпіричний розподіл')\nplt.plot(x, T_dist.pdf(x), c=red_pink, label='$t_{n-1}$')\nplt.plot(x, norm(0, 1).pdf(x), c=slate, ls='--', label='$\\mathcal{N}(0, 1)$')\n\nplt.legend()\nplt.xlabel('$t(X)$')\nplt.ylabel('Щільність')\nplt.xlim(l, r)\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.4: Розподіл \\(t(X)\\)\n\n\n\n\n\nРозподіл Стьюдента практично ідеально описує дані, тоді як нормальний розподіл більш “центрований”.\nТепер, як викликати вбудований \\(t\\)-тест у Python? Для цього скористаємося функцією scipy.stats.ttest_1samp. Вона приймає на вхід:\n\na — вибірка;\npopmean — середнє значення генеральної сукупності, яке ми хочемо перевірити;\naxis — вздовж якої осі обчислювати тест. За замовчуванням 0;\nnan_policy — як обробляти NaN. Може приймати значення propagate, raise, omit. За замовчуванням propagate;\nalternative — альтернативна гіпотеза. Може приймати значення two-sided, less, greater. За замовчуванням two-sided.\n\n\n\n\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\n\nttest_result = ttest_1samp(meeting_time, 70, alternative='less')\nprint(f\"Статистика: {ttest_result.statistic:.2f}\")\nprint(f\"p-значення: {ttest_result.pvalue:.2f}\")\n\nСтатистика: -2.03\np-значення: 0.04\n\n\n\n\nОскільки \\(p\\)-значення менше 0.05, то ми відхиляємо нульову гіпотезу. Це означає, що середня тривалість нарад у новому форматі триває менше 70 хвилин. Відповідно до \\(t\\)-тесту, ми можемо стверджувати, що новий формат нарад дійсно скорочує їх тривалість.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчі-інтервали",
    "href": "t-test.html#довірчі-інтервали",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.4 Довірчі інтервали",
    "text": "4.4 Довірчі інтервали\nДавайте тепер розглянемо, як можна оцінити параметри генеральної сукупності за допомогою \\(t\\)-тесту. Розглянемо два виведення довірчого інтервалу.\n\n4.4.1 Перший метод\n\nНехай є статистика \\(Q\\) та критерій \\(\\psi(Q)\\) для перевірки гіпотези \\(H_0: \\theta = m\\) рівня значущості \\(\\alpha\\).\nТоді довірчий інтервал для \\(\\theta\\) рівня довіри \\(1 - \\alpha\\): множина таких \\(m\\), що критерій \\(\\psi(Q)\\) не відкидає для них \\(H_0\\).\n\nНехай \\(\\mu\\) — істинне середнє вибірки. Ми також знаємо, що за \\(H_0: \\sqrt{n}\\dfrac{\\overline X - m}{\\sqrt{S^2}} \\sim t_{n - 1}\\).\nНас цікавлять такі \\(m\\), що: \\(\\left\\{-t_{n-1, 1 - \\frac{\\alpha}{2}} &lt; \\sqrt{n}\\dfrac{\\overline X - m}{\\sqrt{S^2}} &lt; t_{n-1, 1 - \\frac{\\alpha}{2}} \\right\\}\\), у цьому разі критерій не відкинеться.\nРозпишемо, щоб у центрі залишилося тільки \\(m\\): \\(\\left\\{\\overline X - \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} &lt; m &lt; \\overline X + \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}}\\right\\}\\). А отже, наш довірчий інтервал:\n\\[\nCI_{\\mu} = \\left(\\overline X \\pm \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right),\n\\tag{4.8}\\] де \\(S^2 = \\dfrac{1}{n - 1}\\underset{i=1}{\\overset{n}{\\sum}}(X_i - \\overline X)^2\\)\n\n\n4.4.2 Другий метод\n\nДовірчим інтервалом для параметра \\(\\theta\\) рівня довіри \\(1 - \\alpha\\) є пара статистик \\(L(X), R(X)\\), таких, що \\(P(L(X) &lt; \\theta &lt; R(X)) = 1 - \\alpha\\).\n\nЦе класичне визначення довірчого інтервалу. Тобто, ми повинні знайти такі \\(L(X)\\) та \\(R(X)\\), що \\(P(L(X) &lt; \\mu &lt; R(X)) = 1 - \\alpha\\).\n\\[\n\\begin{aligned}\n    &t(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} \\sim t_{n - 1} \\Rightarrow \\\\\n    &P\\left(-t_{n - 1, 1-\\alpha/2} &lt; \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} &lt; t_{n - 1, 1-\\alpha/2} \\right) = 1 - \\alpha \\Leftrightarrow \\\\\n    &P\\left(\\overline X - \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}}  &lt; \\mu &lt; \\overline X + \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right) = 1 - \\alpha\n\\end{aligned}\n\\tag{4.9}\\]\nТоді\n\\[\nCI_{\\mu} = \\left(\\overline X \\pm \\dfrac{t_{n - 1, 1 - \\alpha/2} \\sqrt{S^2}}{\\sqrt{n}} \\right)\n\\tag{4.10}\\]\nЦей довірчий інтервал збігається з попереднім. Тобто, ми можемо використовувати обидва методи для побудови довірчого інтервалу.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчі-інтервали-у-python",
    "href": "t-test.html#довірчі-інтервали-у-python",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.5 Довірчі інтервали у Python",
    "text": "4.5 Довірчі інтервали у Python\nДавайте тепер побудуємо довірчий інтервал для середнього значення тривалості нарад у новому форматі. Для цього скористаємося функцією scipy.stats.t.interval. Вона приймає на вхід:\n\nconfidence — рівень значущості;\ndf — кількість ступенів свободи;\nloc — середнє значення, за замовчуванням 0;\nscale — стандартна девіація, за замовчуванням 1.\n\nДля побудови лівостороннього довірчого інтервалу візьмемо confidence на рівні 90%, оскільки ми хочемо перевірити, чи тривалість нарад у новому форматі менша 70 хвилин.\n\n\n\nmeeting_time = np.array([50, 55, 70, 45, 40, 70, 80])\n\n1confidence = 0.90\n2df = len(meeting_time) - 1\n3loc = np.mean(meeting_time)\n4scale = np.std(meeting_time, ddof=1) / np.sqrt(len(meeting_time))\n\n5interval = t.interval(confidence, df, loc, scale)\nprint(f\"Довірчий інтервал: {np.round(interval, 2)}\")\n\n\n1\n\nРівень значущості.\n\n2\n\nКількість ступенів свободи.\n\n3\n\nСереднє значення.\n\n4\n\nСтандартна девіація.\n\n5\n\nВиклик функції scipy.stats.t.interval.\n\n\n\n\nДовірчий інтервал: [47.61 69.53]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#t-тест-та-вимога-нормальності",
    "href": "t-test.html#t-тест-та-вимога-нормальності",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.6 \\(t\\)-тест та вимога нормальності",
    "text": "4.6 \\(t\\)-тест та вимога нормальності\nМи навчилися розв’язувати задачу оцінки середнього вибірки, коли дисперсія невідома, але вибірка з нормального розподілу. Тепер розглянемо, що буде, якщо вибірка не з нормального розподілу.\n\nПриклад 4.2  \n\nВи запускаєте онлайн-платформу з курсами програмування. Ви плануєте надавати доступ до курсів за фіксовану плату, але також інвестуєте в маркетинг та підтримку студентів. У середньому, прибуток від одного користувача (після вирахування витрат на платформу, рекламу тощо) становить \\(X\\) грн., але витрати на залучення кожного нового студента — 1000 грн.\n\n\nСтуденти можуть скористатися гарантією повернення грошей протягом 14 днів. Ви хочете перевірити, чи є прибуток від нових користувачів більшим за 0 грн. (тобто, чи є прибуток від нових користувачів більшим за витрати на залучення нових студентів). Тому іноді прибуток від користувача — позитивне число, а іноді — негативне.\n\n\nІнвестори готові профінансувати вашу платформу, якщо ви доведете, що вона буде прибутковою. У вас є дані про чистий прибуток або збиток від кожного користувача, який вже зареєструвався.\n\n\nЗгенеруємо штучні дані для цієї задачі. Для цього змішаємо логнормальний розподіл для позитивних значень (прибуток) та від’ємний \\(\\chi^2\\) для від’ємних значень (збиток).\n\n\n\nn = 5000\np_positive = 0.6\n\nn_pos = int(n * p_positive)\nprofits = np.random.lognormal(mean=2, sigma=0.8, size=n_pos) * 100\n\nn_neg = n - n_pos\nlosses = -np.random.chisquare(df=2, size=n_neg) * 100\n\nprofits = np.concatenate([profits, losses])\nnp.random.shuffle(profits)\n\nsns.histplot(profits, bins=100, kde=True, color=turquoise)\n\nplt.xlabel('Прибуток або збиток')\nplt.ylabel('Кількість користувачів')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.5: Візуалізація штучних до задачі.\n\n\n\n\n\nПорахуємо середній прибуток.\n\n\n\nprint(f\"Середній прибуток: {profits.mean():.2f}\")\n\nСередній прибуток: 547.45\n\n\n\n\nНа відміну від попереднього завдання тут 2 відмінності:\n\nПочаткова вибірка не з нормального розподілу\nВибірка досить велика: не 7 елементів, а вже 5000.\n\n\n4.6.1 \\(t'\\)-тест\nЗгадаймо, що в нас від початку була ідея в \\(Z\\)-тесті замість статистики \\(Z\\), у якій дисперсія відома, використовувати критерій \\(t\\), де дисперсія оцінена на даних. І використовувати нормальний розподіл. Тільки в першому завданні цей критерій нам не допоміг. Але що, якби вибірка була великою? Чи могли б ми використовувати нормальний розподіл для наближення?\n\nБудемо розглядати ту саму статистику \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\\)\n\\(\\xi := \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{\\sigma^2}} \\stackrel{d}{\\rightarrow} \\mathcal{N}(0, 1)\\). За ЦГТ збіжність є тільки за розподілом.\nтоді \\(t = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}} = \\xi \\cdot \\sqrt{\\dfrac{\\sigma^2}{S^2}}\\). Позначимо \\(\\phi := \\sqrt{\\dfrac{\\sigma^2}{S^2}}\\)\n\nПам’ятаєте, раніше було сказано, що \\(S^2\\) — найкраща оцінка для дисперсії? Річ у тім, що вона є консистентною оцінкою для \\(\\sigma^2\\). Тобто \\(S^2\\) збігається за ймовірністю до \\(\\sigma^2\\). Тобто \\(S^2 \\stackrel{p}{\\rightarrow} \\sigma^2\\).\nА в цьому випадку існує теорема, яка стверджує, що \\(\\phi = \\dfrac{\\sigma^2}{S^2}  \\stackrel{p}{\\rightarrow} 1\\).\n\n\\(t = \\xi \\cdot \\phi\\).\n\n\\(\\xi \\stackrel{d}{\\rightarrow} \\mathcal{N}(0, 1)\\)\n\\(\\phi \\stackrel{p}{\\rightarrow} 1\\)\nІ тут набуває чинності ще одна теорема: \\(t = \\xi \\cdot \\phi \\stackrel{d}{\\rightarrow} 1\\cdot \\mathcal{N}(0, 1)\\). Та сама збіжність, що й у ЦПТ!\nТобто статистика \\(t\\) так само буде з нормального розподілу.\n\n\nОтже, якщо вибірка велика, то ми можемо вважати, що \\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\).\n\n\n\n\n\n\nПримітка\n\n\n\nЗауважимо, що у випадку “нормальний розподіл, велика вибірка” працюють одразу 2 критерії: \\(t\\)-тест та \\(t'\\)-тест. Це означає, що якщо \\(t(X) \\overset{H_0}{\\sim} t_{n - 1}\\) та \\(t(X) \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\\), то \\(t_{n - 1} \\approx \\mathcal{N}(0, 1)\\).\nФормально ж, якщо ступінь свободи в \\(t\\)-розподілі дорівнює нескінченності, то це нормальний розподіл! \\(\\lim_{n\\rightarrow \\infty}t_{n} = \\mathcal{N}(0, 1)\\)\nА якщо \\(t_{n - 1} \\approx \\mathcal{N}(0, 1)\\), то ми замість \\(t'\\)-критерію ми можемо використовувати \\(t\\)-критерій!\n\n\nВ такому випадку критерій \\(t\\)-тесту буде виглядати так:\n\\[\nH_0: \\mu =\\mu_0\\ проти\\ H_1: \\mu &gt; \\mu_0\n\\tag{4.11}\\]\nСтатистика \\(t(X)\\) буде виглядати так:\n\\[\nt(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu_0}{\\sqrt{S^2}}\n\\tag{4.12}\\]\nПри достатньо великій вибірці \\(t(X) \\sim \\mathcal{N}(0, 1)\\).\nТоді односторонній критерій набуває вигляду:\n\\[\n\\left\\{t(X) \\geq z_{1 - \\alpha} \\right\\}\n\\tag{4.13}\\]\nА \\(p\\)-значення для одностороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 1 - \\Phi(z),\n\\tag{4.14}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\).\nДвосторонній критерій буде виглядати так:\n\\[\n\\left\\{t(X) \\geq z_{1 - \\frac{\\alpha}{2}} \\right\\} \\bigcup \\left\\{t(X) \\leq -z_{1 - \\frac{\\alpha}{2}} \\right\\}\n\\tag{4.15}\\]\nПри цьому \\(p\\)-значення для двостороннього критерію можна обчислити так:\n\\[\np\\text{-значення} = 2\\cdot \\min \\left[{\\Phi(z), 1 - \\Phi(z)} \\right],\n\\tag{4.16}\\] де \\(z\\) — реалізація статистики \\(t(X)\\), \\(\\Phi(z)\\) — функція розподілу \\(\\mathcal{N}(0, 1)\\).\nПеревіримо наш критерій на великій вибірці. Для цього згеренуємо вибірку з експоненційного розподілу \\(\\mathcal{E}(300)\\), де \\(X \\sim \\mathcal{E}(\\lambda)\\), \\(\\lambda = 1/\\mu\\). Вибірка буде згенерована з параметром \\(\\lambda = 1/300\\). Тобто, середнє значення вибірки буде \\(300\\).\n\n\n\nsample_size = 2000\nM = 10_000\nsample_distr = expon(loc=5, scale=300)\n\nT_X = lambda x: (\n    np.sqrt(sample_size) * (np.mean(x) - sample_distr.mean()) /\n    np.std(x, ddof=1)\n)\n\nT_sample = sample_statistics(\n    number_of_experiments=M,\n    statistic_function=T_X,\n    sample_size=sample_size,\n    sample_distr=sample_distr\n)\n\nl, r = np.quantile(T_sample, [0.001, 0.999])\nx = np.linspace(l, r, 1000)\n\nsns.distplot(T_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, norm(0, 1).pdf(x),\n         label='$\\mathcal{N}(0, 1)$', color=red_pink)\n\nplt.legend()\nplt.xlabel('$T(X)$')\nplt.ylabel('Щільність')\nplt.xlim(l, r)\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.6: Розподіл \\(t'(X)\\) для великої вибірки.\n\n\n\n\n\nМи бачимо, що емпіричний розподіл \\(t'(X)\\) та теоретичний \\(\\mathcal{N}(0, 1)\\) збігаються. Це означає, що ми можемо використовувати \\(t'\\)-тест для перевірки гіпотези. Якщо ж перевірити на великих вибірках з нормального розподілу, то \\(t\\)-тест та \\(t'\\)-тест будуть давати доволі схожі результати.\n\n\n\nsample_size = 2000\nM = 30_000\nsample_distr = norm(loc=5, scale=300)\n\nT_X = lambda x: (\n    np.sqrt(sample_size) * (np.mean(x) - sample_distr.mean()) /\n    np.std(x, ddof=1)\n)\n\nT_sample = sample_statistics(\n    number_of_experiments=M,\n    statistic_function=T_X,\n    sample_size=sample_size,\n    sample_distr=sample_distr\n)\n\nl, r = np.quantile(T_sample, [0.001, 0.999])\nx = np.linspace(l, r, 1000)\n\nsns.distplot(T_sample, label='Емпіричний розподіл', color=turquoise)\nplt.plot(x, norm(0, 1).pdf(x),\n         label='$\\mathcal{N}(0, 1)$', color=red_pink)\n\nplt.legend()\nplt.xlabel('$T(X)$')\nplt.ylabel('Щільність')\nplt.xlim(l, r)\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.7: Розподіл \\(t(X)\\) для великої вибірки.\n\n\n\n\n\nВиходить, що статистика \\(t'(X)\\) при великій вибірці з нормального розподілу також буде з нормального розподілу.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#довірчий-інтервал",
    "href": "t-test.html#довірчий-інтервал",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.7 Довірчий інтервал",
    "text": "4.7 Довірчий інтервал\nДовірчий інтревал виводиться аналогічно до \\(t\\)-тесту.\n\\[\n\\begin{aligned}\n    &t'(X) = \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} \\sim \\mathcal{N}(0, 1) \\Rightarrow \\\\\n    &P\\left(-z_{1 - \\frac{\\alpha}{2}} &lt; \\sqrt{n}\\dfrac{\\overline X - \\mu}{\\sqrt{S^2}} &lt; z_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha \\Leftrightarrow \\\\\n    &P\\left(\\overline X - \\dfrac{z_{1 - \\frac{\\alpha}{2}} S^2}{\\sqrt{n}}  &lt; \\mu &lt; \\overline X + \\dfrac{z_{1 - \\frac{\\alpha}{2}} S^2}{\\sqrt{n}} \\right) = 1 - \\alpha\n\\end{aligned}\n\\tag{4.17}\\]\nПереглнемо на практиці, як це виглядає у Python.\n\n\n\nsample = expon(scale=300).rvs(2000)\nci = norm.interval(confidence=0.95, loc=np.mean(sample), scale=sem(sample))\nprint(f\"CI = {np.round(ci, 2)}\")\n\nCI = [293.89 319.75]\n\n\n\n\nТепер ми можемо повернутися до нашої задачі з прибутком.\n\n\n\nci_profit = norm.interval(confidence=0.95, loc=np.mean(profits), scale=sem(profits))\nprint(f\"CI = {np.round(ci_profit, 2)}\")\n\nCI = [520.19 574.72]\n\n\n\n\nЦе означає, що ми можемо стверджувати, що прибуток від нових користувачів більший за 0 грн.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#вибір-критерію",
    "href": "t-test.html#вибір-критерію",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.8 Вибір критерію",
    "text": "4.8 Вибір критерію\nДля початку визначимося, коли який критерій краще використовувати?\n\nЯкщо вибірка розміру 60, то вже \\(t_{59} \\approx \\mathcal{N}(0, 1)\\).\n\nПодивимося на розподіли Стьюдента і нормального:\n\n\n\n\n\ndf = 59\nt_dist = t(df=df)\nz_dist = norm(loc=0, scale=1)\n\nx = np.linspace(-3, 3, 100)\n\nfig, ax = plt.subplots(figsize=(8, 2.5))\nplt.plot(x, z_dist.pdf(x), label='$\\mathcal{N}(0, 1)$', color=red_pink)\nplt.plot(x, t_dist.pdf(x), label='$t_{59}$', color=turquoise)\nplt.legend()\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.8: Розподіл \\(t(X)\\) та \\(N(0, 1)\\).\n\n\n\n\n\n\nМи бачимо, що ці два розподіли візуально повністю збігаються, тому неважливо, як порахувати: статистика \\(t\\sim \\mathcal{N}(0, 1)\\) або \\(t\\sim t_n\\).\nАле це не означає, що з \\(N=60\\) \\(t\\)-тест або \\(t'\\)-тест працюють коректно! Якщо вибірка не з нормального розподілу, вони обидва можуть усе ще помилятися.\n\n\nЯкщо вибірка менше 60, то безпечніше використовувати \\(t\\)-тест, ніж \\(t'\\)-тест.\n\nУ \\(t\\)-тест FPR завжди буде меншим, ніж у \\(t'\\)-тест.\n\nНа FPR впливає відсоток випадків pvalue &lt; alpha. У \\(t\\)-тест \\(p\\)-значення \\(\\geq\\) \\(t'\\)-тест \\(p\\)-значення.\npvalue = t_distr.cdf(x) або pvalue = norm_dist.cdf(x). Тож чим важчий хвіст у розподілу, тим більше \\(p\\)-значення.\n\n\n\nПодивимось на прикладі.\n\n\n\ndf_array = [2, 5, 10, 20]\nx = np.linspace(-3, 3, 100)\n\nfor df in df_array:\n    t_dist = t(df=df)\n    plt.plot(x, t_dist.cdf(x), label=f't(df={df})')\n\nz_dist = norm(loc=0, scale=1)\nplt.plot(x, z_dist.cdf(x), c=red_pink, label='$\\mathcal{N}(0, 1)$')\nplt.legend()\nplt.xlabel('X')\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 4.9: Куртки розподілів \\(t\\) та \\(N(0, 1)\\).\n\n\n\n\n\nЯк видно на графіку, що менший ступінь свободи, то вищою є лінія на графіку (за x &lt; 0), а отже \\(P(X &lt; x)\\) буде більшим, ніж у нормальному розподілі. Тобто, \\(t\\)-тест буде давати менше \\(p\\)-значення, ніж \\(t'\\)-тест. А отже, \\(t\\)-тест буде відкидати нульову гіпотезу частіше, ніж \\(t'\\)-тест.\n\n\n\n\n\n\nПримітка\n\n\n\nРозподіл Стьюдента з нескінченністю ступенів свободи — це нормальний розподіл: \\(t_{\\infty} = \\mathcal{N}(0, 1)\\). Тому norm(0, 1).cdf(x) = t_distr(df=infinity).cdf(x) &lt; t_distr(df=N).cdf(x).\n\n\nТому, якщо вибірка невелика, безпечніше використовувати \\(t\\)-тест. Але все ще не факт, що ваш критерій буде валідний!\nМи бачимо, що ми скрізь можемо використовувати \\(t\\)-тест (а \\(t'\\)-тест не завжди), і в разі маленьких вибірок він безпечніший. Тому \\(t\\)-тест і став набагато популярнішим, ніж \\(t'\\)-тест. Але \\(t'\\)-тест на практиці може бути теж корисний:\n\nНе треба думати під час реалізації про ступені свободи.\nНаписати такий критерій на SQL буде набагато простіше: ви можете використовувати табличні значення в коді, щоб зрозуміти, чи відкинувся критерій.\nРобити різні теоретичні обчислення простіше.\nУ ньому складніше помилитися під час реалізації.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#мінімальний-ефект",
    "href": "t-test.html#мінімальний-ефект",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.9 Мінімальний ефект",
    "text": "4.9 Мінімальний ефект\nПовернемося до завдання зі стартапом. Уявімо, що ми хочемо запустити наш стартап на новому ринку, наприклад у іншій країні. Питання: чи можемо ми зменшити розмір вибірки?\nЩо взагалі нам заважає взяти занадто маленьку вибірку? Наприклад, якщо ми перевіряємо наш стартап на 1-2 користувачів, то ми нічого не можемо сказати про наш істинний ефект, він може бути як більшим за 0, так і меншим. Буде занадто широкий довірчий інтервал (через велику дисперсію у вибірці), і нам потрібен величезний ефект, щоб його виявити.\nЩе, можливо, ми не можемо використовувати критерій на такій маленькій вибірці. А якщо вибірка складалася б із нескінченної кількості користувачів, то ми могли б абсолютно точно сказати справжній прибуток від користувача, навіть якщо він дорівнює 1 копійці. При цьому обидва випадки нас не влаштовують. У першому — ми не зможемо запустити стартап через занадто великий шум, а в другому — нам потрібна вічність, щоб перевірити нашу гіпотезу.\nІ тут нам допоможе MDE (minimum detectable effect). Це таке істинне значення ефекту, що наш шанс його виявити дорівнює \\(1-\\beta\\) при використанні нашого критерію.\nМи можемо подивитись, який ефект ми зможемо зафіксувати під меншої кількості користувачів, і від цього вирішити, чи підходить нам така вибірка, чи ні. Наприклад:\n\nМи бачимо, що MDE 100 гривень. Тобто з ймовірністю \\(1-\\beta\\) (на практиці 80%) ми його виявимо, якщо такий ефект буде. І з імовірністю 80% стартап запуститься на новому ринку. Чудово, це нас влаштовує, ми перевіряємо гіпотезу на меншій вибірці.\nМи бачимо, що MDE 10000 гривень. Це, навпаки, занадто багато: у нас 99% послуг коштують менше 1000 гривень. Ми не наберемо такого прибутку, стартап невиграшний, потрібно брати вибірку більшого розміру.\n\nТому слід чітко визначити від чого залежить MDE. Це може бути:\n\nПомилка першого роду, або \\(\\alpha\\). Наприклад, за \\(\\alpha = 1\\) ми знайдемо ефект і за розміру вибірки, що дорівнює одиниці (ми просто завжди відкидатимемо \\(H_0\\)). А за \\(\\alpha = 0\\) ми ніколи не зафіксуємо ефект.\nПотужність, або \\(1 - \\beta\\). Випливає із самого визначення.\nВід шуму в даних, або від дисперсії. Що більш шумні дані, як ми знаємо, то ширший довірчий інтервал. А отже, складніше точно передбачити межі для істинного ефекту, тому й MDE буде більшим.\nВід розміру вибірки. Нас цікавить не просто дисперсія в даних, а дисперсія середнього значення: вона за тією самою логікою має бути якомога меншою. А що таке дисперсія середнього? Це \\(\\dfrac{\\sigma^2}{N}\\), тому MDE також залежить від розміру вибірки.\n\nТепер давайте виведемо формулу виходячи з того, що ми знаємо всі ці чотири параметри. Для початку визначимося з гіпотезою, що перевіряється:\n\\[\nH_0: \\mu_0 = 0\\ проти. \\ H_1: \\mu_0 &gt; 0\n\\tag{4.18}\\]\nПозначимо оцінку дисперсії середнього значення:\n\\[\nS^2_{\\mu} := \\frac{S^2}{N}\n\\tag{4.19}\\]\nА також стандартне відхилення середнього значення:\n\\[\nS_{\\mu} = \\sqrt{\\frac{S^2}{N}}\n\\tag{4.20}\\]\nТепер ми знаємо, що\n\\[\n\\overline X \\sim \\mathcal{N}(\\mu, S^2_{\\mu})\n\\tag{4.21}\\]\nНам треба знайти \\(\\text{MDE}=m\\), таке, що:\n\nякщо \\(\\overline X \\sim \\mathcal{N}(m, S^2_{\\mu})\\), то в \\(1-\\beta\\) відсотку випадків для нього відкинеться критерій. Перевіряємо потужність (ціанова площа на графіку).\nякщо \\(\\overline X \\sim \\mathcal{N}(0, S^2_{\\mu})\\), то критерій відкинеться для нього в \\(\\alpha\\) відсотків випадків. Перевіряємо FPR (рожева площа на графіку).\n\n\n\n\n\n\n\n\n\n\n\nРисунок 4.10: Графік MDE.\n\n\n\n\n\nНехай\n\\[\nB(X): P_{H_0}(\\overline X &gt; B(X)) = \\alpha,\n\\tag{4.22}\\] де \\(B(X)\\) — межа відхилення нульової гіпотези.\nТоді\n\\[\nP_{H_1}(\\overline X &gt; B(X)) = 1-\\beta\n\\tag{4.23}\\]\nАбо\n\\[\nP_{H_1}(\\overline X - m &gt; B(X) - m) = 1-\\beta\n\\tag{4.24}\\]\nПозначимо \\(\\xi := \\overline X - m\\). Тоді\n\\[\nP_{H_0}(\\xi &gt; B(X) - m) = 1-\\beta,\n\\tag{4.25}\\] де \\(B(X) - m\\) — межа відхилення нульової гіпотези з урахуванням істинного ефекту.\nТреба розв’язати ці 2 рівняння й ми отримаємо вираз \\(m\\) через усі чотири параметри.\nЗа \\(H_0\\) наш критерій має такий вигляд:\n\\[\n\\left\\{T(X) \\geq z_{1 - \\alpha} \\right\\} \\Leftrightarrow  \\left\\{\\sqrt{N}\\dfrac{\\overline X}{\\sqrt{S^2}} \\geq z_{1 - \\alpha} \\right\\} \\Leftrightarrow B(X) = z_{1 - \\alpha}\\sqrt{\\frac{S^2}{N}} = z_{1 - \\alpha}S_{\\mu}\n\\tag{4.26}\\]\nТоді\n\\[\nP_{H_0}(\\xi &gt; z_{1 - \\alpha}S_{\\mu} - m) = 1-\\beta\n\\tag{4.27}\\]\nАле працювати з розподілом \\(\\mathcal{N}(0, S^2_{\\mu})\\) не дуже зручно, набагато простіше з \\(\\mathcal{N}(0, 1)\\). Для цього переходу достатньо перейти від \\(\\xi \\rightarrow \\dfrac{\\xi}{S_{\\mu}}\\) за властивостями нормального розподілу.\nПозначимо \\(\\eta := \\dfrac{\\xi}{S_{\\mu}}\\). Тоді\n\\[\n\\begin{aligned}\n    &P_{H_0}(\\xi &gt; z_{1 - \\alpha}S_{\\mu} - m) =\\\\\n    &P_{H_0}(\\dfrac{\\xi}{S_{\\mu}} &gt; \\dfrac{z_{1 - \\alpha}S_{\\mu} - m}{S_{\\mu}}) =\\\\\n    & P_{\\mathcal{N}(0, 1)}(\\eta &gt; z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}}) = 1-\\beta\n\\end{aligned}\n\\tag{4.28}\\]\nЗа умови \\(\\Phi(C) = P(\\eta &lt; C)\\), тоді\n\\[\n\\begin{aligned}\n&1 - \\Phi \\left(z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}} \\right) = 1-\\beta \\Leftrightarrow\\\\ &z_{1 - \\alpha} - \\dfrac{m}{S_{\\mu}} = z_{\\beta},\n\\end{aligned}\n\\tag{4.29}\\] де \\(z_{\\beta} = \\Phi^{-1}(\\beta)\\) — квантиль \\(\\beta\\) нормального розподілу.\nТепер згадаємо, що \\(\\eta \\sim \\mathcal{N}(0, 1)\\), тоді\n\\[\nm = (z_{1 - \\alpha} - z_{\\beta}) \\cdot S_{\\mu} = (z_{1 - \\alpha} + z_{1 - \\beta}) \\cdot \\sqrt{\\frac{S^2}{N}}\n\\tag{4.30}\\]\nОтже, ми отримали формулу для MDE:\n\\[\n\\text{MDE} = (z_{1 - \\alpha} + z_{1 - \\beta}) \\cdot \\sqrt{\\frac{S^2}{N}}\n\\tag{4.31}\\] де \\(z_{1 - \\alpha}\\) — квантиль \\(\\alpha\\) нормального розподілу, \\(z_{1 - \\beta}\\) — квантиль \\(\\beta\\) нормального розподілу, \\(S^2\\) — оцінка дисперсії, \\(N\\) — розмір вибірки.\nПовернемося до стартапу. Припустимо, що \\(N = 1000\\), \\(\\alpha=5\\)%, \\(1-\\beta=80\\)%, а як дізнатися \\(S^2\\)?\nНа практиці є 3 способи:\n\nОцінити на історичних даних. У цьому випадку це не підходить, тому що раніше стартапу на новому ринку не було.\nОцінити за схожими даними. Наприклад, у нашому випадку, оцінити дисперисію на початковому ринку.\nЯкось теоретично оцінити. Найгірший спосіб, який працює, якщо перші два не допомагають.\n\nПодивимося тепер MDE у нашому завданні.\n\n\n\nN = 1000\nS2 = np.var(profits)\nalpha = 0.05\nbeta = 1 - 0.8\n\nMDE = (norm().ppf(1-alpha) + norm().ppf(1 - beta)) * np.sqrt(S2/N)\nprint(f\"MDE при N = {N}: {np.round(MDE, 2)}\")\n\nMDE при N = 1000: 77.33\n\n\n\n\nА отже, ми можемо розраховувати на точність лише в 77.33 грн. Але дня нас це може бути занадто великий MDE: хочеться, щоб він був \\(\\leq\\) 50 грн, ми припускаємо, що це ймовірніший істинний ефект, виходячи з поперелднього досвіду.\nДавайте тепер розв’яжемо зворотну задачу: Ми знаємо \\(MDE=50\\) грн., \\(\\alpha=5\\)%, \\(1-\\beta=80\\)%, \\(S^2\\), чому дорівнює \\(N\\)? Виведемо його з формули MDE:\n\\[\nN = \\left(\\dfrac{z_{1 - \\alpha} + z_{1 - \\beta}}{\\text{MDE}}\\right)^2 S^2\n\\tag{4.32}\\]\n\n\n\nS2 = np.var(profits)\nalpha = 0.05\nbeta = 1 - 0.8\nmde = 50\n\nN = ((norm().ppf(1-alpha) + norm().ppf(1 - beta)) / mde)**2 * S2\nN = int(N) + 1\nprint(f\"Мінімальний розмір вибірки: {N}\")\n\nМінімальний розмір вибірки: 2392\n\n\n\n\nТепер ми знаємо, що нам потрібно 2392 користувачів, щоб перевірити нашу гіпотезу з MDE 50 грн.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#двовибірковий-t-тест",
    "href": "t-test.html#двовибірковий-t-тест",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.10 Двовибірковий \\(t\\)-тест",
    "text": "4.10 Двовибірковий \\(t\\)-тест\n\nПриклад 4.3  \n\nНа нашому онлайн-сервісі з розміщення оголошень є платні послуги просування. Ми плануємо запровадити знижки на ці послуги, щоб залучити більше користувачів і збільшити дохід. Для перевірки ефективності було вирішено провести A/B тест: одній половині нових користувачів ми не надавали знижки, а другій половині — надавали знижки на просування. Потрібно визначити, чи призвело це до зростання доходу.\n\n\nДля вирішення цього завдання ми не можемо використовувати одновибірковий \\(t\\)-тест. Цього разу в нас дві вибірки \\(A\\) — контроль, та \\(B\\) — тест.\nНаша гіпотеза звучить так:\n\\[\nH_0: E A = E B \\; проти \\; H_1: E A &lt; E B\n\\]\nДалі в нас може бути кілька варіантів:\n\nОбидві вибірки нормальні.\n\nТоді у випадку рівних дисперсій \\(\\sigma^2_A = \\sigma^2_B\\), спільна дисперсія \\(S^2_{pooled}\\) обчислюється за формулою:\n\\[\nS^2_{pooled} = \\dfrac{(N - 1)S^2_A + (M - 1)S^2_B}{N + M - 2},\n\\tag{4.33}\\] де \\(N\\), \\(M\\) — розмір контролю і тесту відповідно.\nА критерій має такий вигляд:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{S^2_{pooled}\\sqrt{1/N + 1/M}} \\overset{H_0}{\\sim} t_{n + m - 2}\n\\tag{4.34}\\] де \\(n + m - 2\\) — ступені свободи.\nУ випадку, якщо дисперсії не рівні \\(\\sigma^2_A \\neq \\sigma^2_B\\)5, то:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{\\sqrt{S^2_{A}/N + S^2_{B}/M}} \\overset{H_0}{\\sim} t_{v}\n\\tag{4.35}\\] де \\(v\\) — ступені свободи, які обчислюються за формулою:\n\\[\nv = \\frac{\\left(\\frac{S^2_{A}}{N} + \\frac{S^2_{B}}{M} \\right)^2}{\\left(\\frac{(S^2_{A})^2}{N^2(N - 1)} + \\frac{(S^2_{B})^2}{M^2(M-1)} \\right)}\n\\tag{4.36}\\]\n\nХоча б одна вибірка не нормальна.\n\nТоді ми можемо використовувати нормальну апроксимація при великій вибірці:\n\\[\nt(A, B) = \\dfrac{\\overline A - \\overline B}{\\sqrt{S^2_{A}/N + S^2_{B}/M}} \\overset{H_0}{\\sim} \\mathcal{N}(0, 1)\n\\tag{4.37}\\] де \\(S^2_{A}\\), \\(S^2_{B}\\) — вибіркові дисперсії.\n\n4.10.1 Двовибірковий \\(t\\)-тест у Python\nДля реалізації двовибіркового \\(t\\)-тесту в Python ми можемо використовувати ttest_ind6 з бібліотеки scipy.stats.\nПодивимось на приклад з двома вибірками, перша вибірка — з експоненційного розподілу, а друга — з нормального розподілу.\n\n\n\nX = expon(scale=1100).rvs(1000)\nY = norm(loc=980, scale=30).rvs(1000)\n\nt_results = ttest_ind(X, Y, equal_var=False, alternative='greater')\nci_t_results = t_results.confidence_interval(confidence_level=0.95)\n\nprint(f\"t-статистика = {np.round(t_results.statistic, 2)}\")\nprint(f\"p-значення = {np.round(t_results.pvalue, 5)}\")\nprint(f\"Довірчий інтервал = {np.round(ci_t_results, 2)}\")\n\nt-статистика = 3.62\np-значення = 0.00015\nДовірчий інтервал = [68.38   inf]\n\n\n\n\n\n\n\n\n\n\nПопередження\n\n\n\nПри використанні \\(t\\)-тесту, як одновибіркового, так і двовибіркового, важливо пам’ятати, що:\n\nЕлементи вибірок мають бути незалежні.\n\nНаприклад, ваша вибірка не може містити кілька замовлень одного користувача. Вони мають бути агреговані, інакше критерії будуть невалідні!\n\nУ двовибірковому критерії вибірки тесту і контролю повинні бути незалежні!.\n\nІнакше критерії так само будуть невалідними.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#sec-questions-4",
    "href": "t-test.html#sec-questions-4",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "4.11 Питання для самоперевірки",
    "text": "4.11 Питання для самоперевірки\nЗагальні питання та Мотивація\n\nУ якій ситуації ми не можемо використовувати \\(Z\\)-критерій для перевірки гіпотези про середнє значення, навіть якщо припускаємо нормальність даних?\nЯка основна проблема виникає при спробі замінити невідому дисперсію генеральної сукупності (\\(\\sigma^2\\)) на її оцінку у формулі \\(Z\\)-статистики?\nЧому вибіркова дисперсія \\(S^2\\) розраховується з дільником \\(n-1\\), а не \\(n\\)? Які властивості цієї оцінки важливі?\nЧи є вибіркова дисперсія (\\(S^2\\)) константою чи випадковою величиною? Чому це важливо для розподілу статистики \\(t(X)\\)?\n\n\\(t\\)-статистика та \\(t\\)-розподіл\n\nНапишіть формулу для \\(t\\)-статистики Стьюдента для однієї вибірки.\nЯкий розподіл має \\(t\\)-статистика за нульовою гіпотезою (\\(H_0: \\mu = \\mu_0\\)) за умови, що вихідна вибірка взята з нормального розподілу? Вкажіть параметри цього розподілу.\nЯкі два типи випадкових величин (та їх розподіли) використовуються для теоретичного визначення змінної, що має \\(t\\)-розподіл Стьюдента? Яка умова щодо їх взаємозв’язку?\nЯк візуально відрізняється \\(t\\)-розподіл від стандартного нормального розподілу (\\(\\mathcal{N}(0, 1)\\)), особливо при малих значеннях ступенів свободи? Як він змінюється зі збільшенням ступенів свободи?\n\nЗастосування \\(t\\)-тесту\n\nСформулюйте типові нульову (\\(H_0\\)) та альтернативну (\\(H_1\\)) гіпотези для одностороннього (правостороннього) \\(t\\)-тесту.\nЯк виглядає критична область для одностороннього (лівостороннього) \\(t\\)-тесту з рівнем значущості \\(\\alpha\\)?\nЯк розраховується \\(p\\)-значення для двостороннього \\(t\\)-тесту, якщо відоме значення \\(t\\)-статистики (\\(z\\)) та функція розподілу \\(t_{n-1}\\) (\\(\\tau_{n-1}(z)\\))?\nЯку функцію в scipy.stats використовують для проведення одновибіркового \\(t\\)-тесту? Які основні параметри вона приймає?\n\nДовірчі інтервали\n\nНаведіть формулу для розрахунку \\((1-\\alpha)\\) довірчого інтервалу для середнього значення \\(\\mu\\), використовуючи \\(t\\)-розподіл.\nЯк пов’язане поняття довірчого інтервалу з перевіркою гіпотез? (Поясніть перший метод виведення ДІ, згаданий у тексті).\nЯку функцію в scipy.stats можна використати для побудови довірчого інтервалу на основі \\(t\\)-розподілу?\n\nПрипущення \\(t\\)-тесту та великі вибірки\n\nЯке ключове припущення щодо розподілу вихідних даних лежить в основі точного \\(t\\)-розподілу статистики \\(t(X)\\)?\nЩо відбувається з розподілом \\(t\\)-статистики, коли розмір вибірки (\\(n\\)) стає великим, навіть якщо вихідні дані не розподілені нормально? Яка теорема це пояснює?\nЯкий розподіл використовується для апроксимації розподілу \\(t\\)-статистики при великих вибірках (\\(t'\\)-тест)?\nЗа яких умов результати “класичного” \\(t\\)-тесту (з \\(t_{n-1}\\)) та “апроксимованого” \\(t'\\)-тесту (з \\(\\mathcal{N}(0, 1)\\)) будуть дуже схожими?\nЧому \\(t\\)-тест часто вважають “безпечнішим” або більш консервативним, ніж \\(t'\\)-тест, особливо при невеликих або помірних розмірах вибірки?\n\nМінімально виявлений ефект (MDE)\n\nЩо таке мінімально виявлений ефект (MDE)? У яких ситуаціях корисно його розраховувати?\nНазвіть чотири основні фактори, від яких залежить MDE.\nНапишіть формулу для розрахунку MDE для одностороннього тесту при заданих \\(\\alpha\\), \\(\\beta\\), \\(N\\) та \\(S^2\\).\nЯк можна використати формулу MDE для визначення необхідного розміру вибірки (\\(N\\))?\n\nДвовибірковий \\(t\\)-тест\n\nДля вирішення якого типу завдань призначений двовибірковий \\(t\\)-тест? Сформулюйте типову нульову гіпотезу.\nНазвіть два варіанти двовибіркового \\(t\\)-тесту залежно від припущення про дисперсії двох вибірок. Який варіант називають тестом Уелча?\nЯку статистику та розподіл використовують для двовибіркового тесту при великих вибірках, якщо не припускати нормальність?\nЯкі ключові припущення щодо незалежності повинні виконуватись при використанні двовибіркового \\(t\\)-тесту? (Вкажіть два типи незалежності).\nЯка функція в scipy.stats використовується для проведення двовибіркового \\(t\\)-тесту?\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "t-test.html#footnotes",
    "href": "t-test.html#footnotes",
    "title": "4  \\(t\\)-критерій Стьюдента",
    "section": "",
    "text": "Розподіл \\(\\chi^2\\) — це розподіл суми квадратів \\(k\\) незалежних нормальних випадкових величин з нульовим математичним сподіванням. Тобто, якщо \\(X_1, X_2, \\ldots, X_k \\sim \\mathcal{N}(0, 1)\\), то \\(Y = X_1^2 + X_2^2 + \\ldots + X_k^2 \\sim \\chi^2_k\\).↩︎\nДоведення Cochran (1934).↩︎\nРозподіл Стьюдента — це розподіл, який виникає при нормальному розподілі з невідомою дисперсією. Якщо \\(X_1, X_2, \\ldots, X_n \\sim \\mathcal{N}(\\mu, \\sigma^2)\\), то \\(t = \\dfrac{\\overline{X} - \\mu}{S/\\sqrt{n}} \\sim t_{n-1}\\), де \\(\\overline{X}\\) — вибіркове середнє, \\(S\\) — вибіркова стандартна девіація.↩︎\nДоведення Basu (1955).↩︎\nТакий підхід називається \\(t\\)-тестом Уелча.↩︎\nДокументація: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.htm↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>$t$-критерій Стьюдента</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html",
    "href": "monte-carlo.html",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "",
    "text": "5.1 Перевірка критерію\nУ цій частині ми розглянемо метод Монте-Карло, який є потужним інструментом для чисельного моделювання та статистичного аналізу. Метод Монте-Карло дозволяє оцінювати ймовірності, інтеграли та інші статистичні характеристики шляхом випадкового вибору з певного розподілу. Ключовим моментом, на котрому ми зупинимось, це пошук відповідей на питання:\nЗа допомогою методу Монте-Карло ми в загальному випадку зможемо відповісти на запитання:\nУвесь цей розділ насамперед буде присвячено AB-тестам і як можна перевіряти критерії для них. Основним критерієм для перевірки в цьому розділі стане \\(t\\)-тест, оскільки навколо нього обертається доволі багато міфів та непорозумінь. Ми з вами:\nЯк ми пам’ятаємо з минулої глави (див. 4), \\(t\\)-тест працює теоретично для вибірок з будь-якого розподілу, якщо вибірка досить велика. Але що значить, що критерій “коректний”? Давайте підемо від визначення:\nЦі визначення дозволяють нам визначити процедуру перевірки критерію:\nТепер давайте розглянемо процедуру більш детально:\nРозглянемо процедуру на прикладі: перевіримо, чи можна використовувати \\(t\\)-тест для вибірок із нормального розподілу?\nnp.random.seed(42)\n\nbad_cnt = 0\nN = 10000\nalpha = 0.05\n\nsample_dist = norm(loc=2, scale=3)\nmu0=sample_dist.expect()\nfor i in range(N):\n    test    = sample_dist.rvs(5)\n    control = sample_dist.rvs(5)\n    pvalue = ttest_ind(test, control, alternative='two-sided').pvalue\n    bad_cnt += (pvalue &lt; alpha)\n\nprint(f\"FPR: {bad_cnt/N:.3f}\")\n\nFPR: 0.052\nЗверніть увагу, що \\(FPR=\\) 0.052, хоча він мав дорівнювати 5%. Чи правда, що критерій некоректний? Ні, ми просто не врахували шум: ми навряд чи зможемо отримати на кінцевому числі експериментів точну рівність \\(\\text{FPR} = \\alpha\\).\nТому пункт 4 процедури перевірки критерію можна уточнити:\nДовірчий інтервал можна побудувати різними способами (див. 2.4). Але можна зробити простіше: у Python є функція, яка будує довірчий інтервал Вілсона1: він не такий точний, як ми виводили раніше, зате він швидший й працює швидше. Давайте спробуємо його реалізувати:\nci = proportion_confint(count = bad_cnt, nobs = N, alpha=0.05, method='wilson')\nprint(f\"FPR: {bad_cnt/N:.3f}\\nДовірчий інтервал: ({ci[0]:.3f}, {ci[1]:.3f})\")\n\nFPR: 0.052\nДовірчий інтервал: (0.048, 0.056)\nЯк бачимо, що 5% потрапили в довірчий інтервал, а отже, ми можемо вважати, що критерій є валідним для нашого завдання.\nА що, якби розподіл був складнішим?\nРозглянемо приклад, коли магматичне сподівання в тесті й контролі рівні, але вибірки з різних розподілів. Тобто \\(H_0\\) правильна, але розподіли різні. Для цього ми можемо взяти два експоненціальних розподіли з різними параметрами. Наприклад, раніше в середньому виручка від користувача була приблизно 10 гривень, а після введення ефекту впливу (нове ціноутворення) частина користувачів стала менше платити, але середній чек залишився таким самим: 10 гривень.\nnp.random.seed(42)\n\ntest_dist = expon(scale = 10)\ncontrol_dist = expon(loc=5, scale = 5)\n\nx = np.linspace(0, 100, 1000)\n\nfig, ax = plt.subplots(figsize=(8, 2))\nplt.plot(x, test_dist.pdf(x), label='Тест', color=turquoise)\nplt.plot(x, control_dist.pdf(x), label='Контроль', color=slate)\nplt.xlabel('x')\nplt.ylabel('Щільність')\nplt.legend()\nplt.grid(linewidth=0.2)\nplt.show()\n\n\n\n\n\n\n\nРисунок 5.1: Приклад, коли \\(H_0\\) правильна, але розподіли різні\nНапишемо функцію check_criterion(), яка буде перевіряти критерій на коректність. Вона приймає на вхід розподіли для тесту й контролю, розмір вибірки, кількість експериментів, а також вміє виводити довірчий інтервал.\ndef check_criterion(\n    test_dist,\n    control_dist, \n    sample_size, \n    N_exps=10000, \n    to_print=True\n):\n    \"\"\"\n    Функція перевіряє критерій на коректність.\n    test_dist: розподіл для тесту\n    control_dist: розподіл для контролю\n    sample_size: розмір вибірки\n    N_exps: кількість експериментів\n    to_print: чи виводити довірчий інтервал\n    \"\"\"\n    np.random.seed(35)\n    bad_cnt=0\n    alpha=0.05\n\n    for i in range(N_exps):\n        test    = test_dist.rvs(sample_size)\n        control = control_dist.rvs(sample_size)\n        pvalue = ttest_ind(test, control, equal_var=False,\n                           alternative='two-sided').pvalue\n        bad_cnt += (pvalue &lt; alpha)\n\n    ci = proportion_confint(count = bad_cnt, nobs = N_exps,\n                            alpha=0.05, method='wilson')\n\n    if to_print:\n        print(f\"FPR: {bad_cnt/N_exps:.3f}\")\n        print(f\"Довірчий інтервал: ({ci[0]:.3f}, {ci[1]:.3f})\")\n    else:\n        return ci\nТепер перевіримо, чи працює \\(t\\)-тест для вибірок з різних експоненціальних розподілів. Одразу спробуємо перевірити відомий міф про достатність вибірки 302. Чи дійсно \\(t\\)-тест працює, якщо вибірка більша за 30?\ncheck_criterion(test_dist, control_dist, sample_size=40)\n\nFPR: 0.061\nДовірчий інтервал: (0.057, 0.066)\nЯк бачимо, \\(t\\)-тест не спрацював, хоча вибірка більша за 30. Істинне \\(\\alpha\\) не лежить у довірчому інтервалі. Але з якого розміру вибірки \\(t\\)-тест почне працювати правильно?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#sec-check-criterion",
    "href": "monte-carlo.html#sec-check-criterion",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "",
    "text": "Чи можна використовувати цей критерій для нашого завдання?\nЧи правильно взагалі реалізовано критерій?\n\n\n\nПокажемо на практиці, що \\(t\\)-тест працює для вибірок не тільки з нормального розподілу.\nПодивимося, як визначити, з якого розміру вибірки можна застосовувати \\(t\\)-тест.\n\n\n\nКритерій рівня значущості \\(\\alpha\\) означає, що ймовірність невірно відкинути нульову гіпотезу \\(\\le \\alpha\\).\nА це зі свого боку означає, що якщо нескінченно багато разів повторити один й той самий експеримент, у якому правильна нульова гіпотеза, генеруючи наново експеримент, то кількість хибнопозитивних спрацьовувань буде меншою за \\(\\alpha\\) відсотків.\n\n\n\nСтворюємо код критерію, який ми будемо перевіряти.\nГенеруємо якомога більше експериментів, де вірна \\(H_0\\).\nДосліджуємо на них придуманий критерій.\nПеревіряємо, чи правда, що тільки в \\(\\alpha\\) відсотків випадків критерій відкидається?\n\n\n\nНасамперед треба вибрати розподіл, який буде описувати наші дані. Наприклад, якщо у нас метрика конверсії, то це розподіл Бернуллі, а якщо метрика — виторг, то краще використовувати експоненціальний розподіл як найпростіше наближення.\nЗавести лічильник bad_cnt, який буде рахувати кількість разів, коли критерій помилився. Ініціалізувати його нулем.\nДалі в циклі розміру \\(N\\), де \\(N\\) — натуральне число від 1000 до нескінченності (чим воно більше, тим краще):\n\nСимулюємо створення вибірки з розподілу, обраного на першому кроці. Так, щоб вірною була \\(H_0\\). У випадку AB-тесту симулювати треба не одну вибірку, а дві: для тесту і контролю.\nДосліджуємо на згенерованих даних критерій, що перевіряється.\nДалі перевірити, чи критерій відкинув нульову гіпотезу. Якщо так, то збільшуємо bad_cnt на одиницю.\n\nПорахувати частку помилок. Це буде ймовірність того, що критерій помиляється.\n\nЯкщо вона приблизно збігається з \\(\\alpha\\), то все добре.\nЯкщо вона менша за \\(\\alpha\\), то в принципі це адекватний критерій на практиці, просто він буде менш потужний, ніж критерій, що помиляється рівно у \\(\\alpha\\) відсотку випадків. Але на практиці варто перевірити: а теоретично така ситуація можлива? Чи це помилка в коді критерію?\nЯкщо критерій помиляється більше, ніж у \\(\\alpha\\), то значить він некоректний і ним не можна користуватися. Використовуючи такий критерій, ви будете помилятися частіше, ніж треба, і це може призвести до серйозних помилок у бізнес-рішеннях.\n\n\n\n\n\n\n\n\n\nПорахувати частку помилок й побудувати довірчий інтервал для нього. Якщо \\(\\alpha\\) лежить у ньому, значить усе добре, а інакше розбираємося, що пішло не так.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#sec-size",
    "href": "monte-carlo.html#sec-size",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "5.2 Визначення розміру вибірки",
    "text": "5.2 Визначення розміру вибірки\nВизначити розмір вибірки, з якого \\(t\\)-тест почне працювати, можна за допомогою методу Монте-Карло. Для цього ми будемо перевіряти \\(t\\)-тест на вибірках різного розміру, поки не знайдемо такий розмір, при якому \\(t\\)-тест почне працювати. Для цього ми будемо перевіряти \\(t\\)-тест на вибірках від 20 до 100 з кроком 10.\n\n\n\nscale = np.arange(20, 110, 10)\nfor N in scale:\n    left, right = check_criterion(test_dist=test_dist,\n                                  control_dist=control_dist,\n                                  sample_size=N, \n                                  N_exps=10000, \n                                  to_print=False)\n    if left &lt; alpha &lt; right:\n        print(f\"Розмір вибірки {N} достатній для t-тесту\")\n        break\n\nРозмір вибірки 60 достатній для t-тесту\n\n\n\n\nЯк бачимо, \\(t\\)-тест починає працювати з вибірки розміром 60.\n\n\n\ncheck_criterion(test_dist=test_dist, control_dist=control_dist, sample_size=60)\n\nFPR: 0.053\nДовірчий інтервал: (0.048, 0.057)\n\n\n\n\nАле це доволі умовна межа, бо якщо у цьому випадку ми візьмемо вибірку розміром 61, то \\(t\\)-тест не спрацює.\n\n\n\ncheck_criterion(test_dist=test_dist, control_dist=control_dist, sample_size=61)\n\nFPR: 0.057\nДовірчий інтервал: (0.052, 0.061)\n\n\n\n\nЦе може бути пов’язано з тим, що ми взяли недостатню велику кількість експериментів, або з дисперсією, або з обома факторами. Тому, якщо потрібна більша точність — необхідно проводити більше експериментів.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#sec-simulate",
    "href": "monte-carlo.html#sec-simulate",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "5.3 Моделювання експерименту",
    "text": "5.3 Моделювання експерименту\nРозберемо два сценарії моделювання експерименту:\n\nГенерація тестової та контрольної групи через імітаційне моделювання. За допомогою різних розподілів можна спробувати наблизити реальний розподіл на даних. Наприклад:\n\nДля генерації виручки використовувати експоненціальний розподіл. Чим більша виручка від користувача — тим менше таких людей.\nДля генерації конверсійних вибірок (наприклад, клікне/не клінкет) використовувати бернулліївську вибірку.\nІноді можна брати суміш розподілів: нехай 90% користувачів нашого сайту приносять нульову виручку. Тоді можна перемножити бернуллівський розподіл на експоненціальний для моделювання виручки від користувача.\nТакож для перевірки критерію рівності середніх не обов’язково мають збігатися розподіли в тесті та в контролі. Вони можуть бути різними, але математичне сподівання має збігатися.\n\nВикористати історичні дані компанії. У багатьох компаній є логування подій. Тоді ми зможемо прямо на реальних даних оцінити правильність критерію! І не потрапити в пастку того, що на штучних вибірках критерій валідний, а на реальних даних ні. Наприклад, у нас є дані про транзакції користувачів за кілька років. Це вже один готовий набір даних: ви ділите всіх користувачів на тестову та контрольну групи й отримуєте один “експеримент” для перевірки вашого критерію.\n\nЗалишилося зрозуміти, як з одного великого набору даних зробити \\(N\\) маленьких. Покажемо на прикладі сервісу з оголошень: наші користувачі розміщують оголошення, кожне оголошення відноситься тільки до однієї категорії товарів і розміщено тільки в одному регіоні. Звідси виникає нехитрий алгоритм:\n\nРозіб’ємо всі оголошення користувачів на чотири (або \\(N\\) у загальному випадку) категорії: автомобілі, спецтехніка, послуги та нерухомість. Тепер наш набір даних можна розбити на ці підкатегорії: наприклад, в одному наборі даних дивитися виручку користувача тільки в цій підкатегорії.\nПоділимо набір даних за місяцями: витрат користувача за листопад, за грудень тощо.\nЩе всі метрики можна поділити за адміністративно-територіальними одиницями: місто, громада, район, область тощо.\nОб’єднаємо всі три правила в одне. Наприклад: набір даних витрат користувача в сервісі оголошень за жовтень у Києві.\nТепер у нас є велика кількість наборів даних і в кожному з них є користувачі. Поділимо користувачів випадково на тест і контроль й отримаємо фінальні набір даних для валідації придуманих статистичних критеріїв.\n\nЯкщо порівнювати два підходи, то головні переваги штучних даних у тому, що їх скільки завгодно, вони генеруються швидко, й ви повністю контролюєте розподіл. Можна створити нескінченно багато наборів даних й дуже точно оцінити помилку першого роду вашого критерію. На початкових етапах дослідження нового критерію штучні дані значно кращі за реальні. Головний мінус — ви отримали коректність вашого критерію тільки на штучних даних! На реальних же даних критерій може працювати некоректно.\nУ наборів даних, отриманих на справжніх даних, усе навпаки: зібрати їх велику кількість складно, та й не завжди нормально побудований процес їх збору. Але адекватна оцінка коректності критерію для перевірки гіпотез у вашій компанії можлива тільки в такий спосіб. Завжди можна реалізувати такий критерій, який буде правильно працювати на штучних даних. Але, зіткнувшись у реальності з більш шумними даними, він може почати помилятися частіше, ніж у 5% випадків. Тому важливо переконатися, що саме на справжніх даних метод працюватиме правильно.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#sec-additional",
    "href": "monte-carlo.html#sec-additional",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "5.4 Додаткові питання",
    "text": "5.4 Додаткові питання\n\n5.4.1 \\(t\\)-тест та мала вибірка не з нормального розподілу\nУ попередньому розділі ми розглянули \\(t\\)-тест для вибірок з нормального розподілу. Розглянемо екстремальний випадок, коли вибірка мала, а розподіл не нормальний. Ми знову використаємо метод Монте-Карло, щоб перевірити, чи працює \\(t\\)-тест у цьому випадку.\n\n\n\ntest_dist    = expon(scale=20)\ncontrol_dist = expon(scale=20)\n\ncheck_criterion(test_dist=test_dist, control_dist=control_dist, sample_size=10)\n\nFPR: 0.040\nДовірчий інтервал: (0.036, 0.044)\n\n\n\n\nТут FPR статистично значущо менше 5%, а отже, використовувати \\(t\\)-тест можна. Тільки треба бути готовим, що він буде не дуже потужним.\n\n\n5.4.2 Як обрати критерій\nНехай у вас є два критерії, й обидва валідні на наших даних. Як зрозуміти на практиці, який із них кращий?\nПравильна відповідь — треба порівняти потужність 2 критеріїв! Але як її дізнатися?\nПропонується повторити ту саму процедуру, що ми робили вище, тільки замість генерації експерименту, коли вірна \\(H_0\\), генерувати експеримент, коли вірна альтернатива. У разі порівняння середніх — треба додати ефект до тесту. І замість FPR рахувати TPR — частка правильно відхилених нульових гіпотез. Чим більше — тим краще.\nПеревіримо на прикладі \\(t\\)-тесту, як це працює.\n\n\n\nrej_cnt = 0\nN = 10000\nalpha=0.05\n\nsample_dist = norm(loc=2, scale=3)\nmu=sample_dist.expect()\n\nfor i in range(N):\n    test    = sample_dist.rvs(15)\n    control = sample_dist.rvs(15) * 2\n    pvalue = ttest_ind(test, control,\n                       equal_var=False, alternative='two-sided').pvalue\n    rej_cnt += (pvalue &lt; alpha)\n\nprint(f\"TPR: {rej_cnt/N:.3f}\")\n\nTPR: 0.194\n\n\n\n\nБачимо, що потужність критерію в цьому випадку дорівнює 0.19. Якщо є другий критерій — треба запустити таку перевірку для 2го критерію й оцінити, який критерій кращий чи гірший, не забувши про статичну значущість.\nЩе є питання: ви оцінили 2 критерії лише при додаванні одного ефекту, наприклад у випадку вище, коли \\(\\mu_T = \\mu_C \\times 2\\). А якби була інша зміна, збереглися б результати, що цей критерій кращий? Не факт, тому треба підбирати такий ефект, який найчастіше зустрінеться на практиці. Ваше завдання ще правильно зімітувати ефект, схожий на справжній.\nЛогіка тут точно така сама, як і чому краще генерувати експерименти на історичних даних, а не на справжніх.\nТобто, ваше завдання для оцінки потужності критерію полягає в:\n\nСтворенні 1000 експериментів, на історичних даних, або на симульованих\nПідборі ефекту, який буде найкраще імітувати істинний ефект, що перевіряється, в гіпотезі.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#sec-questions-5",
    "href": "monte-carlo.html#sec-questions-5",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "5.5 Питання для самоперевірки",
    "text": "5.5 Питання для самоперевірки\nЗагальні питання про метод Монте-Карло\n\nЩо таке метод Монте-Карло в контексті статистики, як описано в цій главі? Яка його основна ідея?\nДля відповіді на які три ключові питання автори пропонують використовувати метод Монте-Карло в задачах статистики (особливо AB-тестування)?\n\nПеревірка коректності критерію (FPR)\n\nОпишіть покрокову процедуру перевірки коректності (валідності) статистичного критерію за допомогою методу Монте-Карло, як викладено в розділі “Перевірка критерію”.\nЩо означає, що критерій є “коректним” з точки зору помилки першого роду (рівня значущості α)? Як це пов’язано з симуляціями, де нульова гіпотеза (\\(H_0\\)) є істинною?\nЧому при перевірці критерію недостатньо просто порівняти отриману частку помилок (FPR - False Positive Rate) з рівнем значущості α? Яку роль відіграє довірчий інтервал і як його інтерпретувати в цьому контексті?\nЯкі висновки можна зробити, якщо обчислений довірчий інтервал для FPR:\n\nМістить α?\nПовністю лежить нижче α?\nПовністю лежить вище α?\n\nЯкі приклади розподілів наводяться для симуляції даних для різних типів метрик (конверсії, виторг)?\n\nВизначення розміру вибірки та специфіка t-тесту\n\nЯк за допомогою методу Монте-Карло можна визначити мінімальний розмір вибірки, за якого певний критерій (наприклад, t-тест) починає працювати коректно для заданих (можливо, ненормальних) розподілів?\nЯкі поширені уявлення про t-тест (стосовно нормальності даних та розміру вибірки &gt; 30) були перевірені та продемонстровані за допомогою Монте-Карло в цій главі? Які висновки було зроблено?\nЧи можна використовувати t-тест, якщо дані не розподілені нормально, особливо при малих вибірках? Який результат показало моделювання для експоненціального розподілу? Який недолік може мати такий тест у цьому випадку?\n\nМоделювання експерименту\n\nЯкі два основні підходи до моделювання експериментів (генерації даних для перевірки критеріїв) розглядаються в главі?\nНазвіть переваги та недоліки використання штучно згенерованих даних (з теоретичних розподілів) для перевірки критеріїв.\nНазвіть переваги та недоліки використання історичних (реальних) даних компанії для перевірки критеріїв. Чому перевірка на реальних даних вважається важливою?\nЯкі способи пропонуються для створення множини експериментів з одного великого набору історичних даних?\n\nВибір між критеріями (Потужність/TPR)\n\nЯкщо два статистичні критерії виявилися валідними (тобто коректно контролюють помилку першого роду), як метод Монте-Карло допомагає обрати кращий з них?\nЯку характеристику критеріїв потрібно порівнювати для вибору кращого? Як вона називається і що означає? (Підказка: TPR - True Positive Rate)\nУ чому ключова відмінність процедури Монте-Карло для оцінки потужності критерію від процедури для перевірки його валідності (контролю FPR)?\nНа що важливо звернути увагу при симуляції ефекту (різниці між групами) для оцінки потужності критерію? Чому це важливо?\n\n\n\n\n\nAgresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd ed. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient Statistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical Statistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical Inference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a Normal System, with Applications to the Analysis of Covariance. Mathematical Proceedings of the Cambridge Philosophical Society. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in Python. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of Theoretical Statistics.” Philosophical Transactions of the Royal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007. Statistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit Distributions for Sums of Independent Random Variables. Martino Fine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with Python. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python: With Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018. Introduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015. Probability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical Hypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in Physics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly Media.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of Experiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974. Introduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and Related Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most Efficient Tests of Statistical Hypotheses.” Philosophical Transactions of the Royal Society of London. Series A 231 (694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo Statistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual: Statistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical Methods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels: Statistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential Tools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in Statistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’ Problem When Several Different Population Variances Are Involved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession, and Statistical Inference.” Journal of the American Statistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson Prentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і Математична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична Статистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика. Основні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "monte-carlo.html#footnotes",
    "href": "monte-carlo.html#footnotes",
    "title": "5  Монте-Карло в задачах статистики",
    "section": "",
    "text": "Wilson (1927)↩︎\nHogg, Tanis, and Zimmerman (2015)↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Монте-Карло в задачах статистики</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Рекомендована література",
    "section": "",
    "text": "Agresti, Alan. 2012. Categorical Data Analysis. 3rd ed. Wiley.\n\n\n———. 2018. An Introduction to Categorical Data Analysis. 3rd\ned. Wiley.\n\n\nBasu, D. 1955. On Statistics Independent of a Complete Sufficient\nStatistic. Sankhya. Vol. 15.\n\n\nBruce, Peter, Andrew Bruce, and Peter Gedeck. 2020. Practical\nStatistics for Data Scientists. 2nd ed. O’Reilly Media.\n\n\nCasella, George, and Roger L. Berger. 2002. Statistical\nInference. 2nd ed. Duxbury Press.\n\n\nCochran, William G. 1934. The Distribution of Quadratic Forms in a\nNormal System, with Applications to the Analysis of Covariance.\nMathematical Proceedings of the Cambridge Philosophical\nSociety. Vol. 30. 3. Cambridge University Press. https://doi.org/10.1017/S0305004100016595.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. Lawrence Erlbaum Associates.\n\n\nDowney, Allen B. 2014. Think Stats: Exploratory Data Analysis in\nPython. 2nd ed. O’Reilly Media. https://greenteapress.com/wp/think-stats-2e/.\n\n\nEfron, Bradley, and Robert J. Tibshirani. 1993. An Introduction to\nthe Bootstrap. Chapman; Hall/CRC.\n\n\nFisher, R. A. 1922. “On the Mathematical Foundations of\nTheoretical Statistics.” Philosophical Transactions of the\nRoyal Society of London. Series A 222 (594-604): 309–68. https://doi.org/10.1098/rsta.1922.0009.\n\n\nFreedman, David, Robert Pisani, and Roger Purves. 2007.\nStatistics. 4th ed. W. W. Norton & Company.\n\n\nGnedenko, Boris V., and Alexander N. Kolmogorov. 2021. Limit\nDistributions for Sums of Independent Random Variables. Martino\nFine Books.\n\n\nGrus, Joel. 2019. Data Science from Scratch: First Principles with\nPython. 2nd ed. O’Reilly Media.\n\n\nHaslwanter, Thomas. 2016. An Introduction to Statistics with Python:\nWith Applications in the Life Sciences. Springer.\n\n\nHogg, Robert V., Joseph W. McKean, and Allen T. Craig. 2018.\nIntroduction to Mathematical Statistics. 8th ed. Pearson.\n\n\nHogg, Robert V., Elliott A. Tanis, and Dale L. Zimmerman. 2015.\nProbability and Statistical Inference. 9th ed. Pearson.\n\n\nLehmann, Erich L., and Joseph P. Romano. 2005. Testing Statistical\nHypotheses. 3rd ed. Springer.\n\n\nLemons, Don S. 2002. An Introduction to Stochastic Processes in\nPhysics. The Johns Hopkins University Press.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis. 3rd ed. O’Reilly\nMedia.\n\n\nMontgomery, Douglas C. 2017. Design and Analysis of\nExperiments. 9th ed. Wiley.\n\n\nMood, Alexander M., Franklin A. Graybill, and Duane C. Boes. 1974.\nIntroduction to the Theory of Statistics. 3rd ed. McGraw-Hill.\n\n\nNewcombe, Robert G. 2012. Confidence Intervals for Proportions and\nRelated Measures of Effect Size. Chapman; Hall/CRC.\n\n\nNeyman, J., and E. S. Pearson. 1933. “On the Problem of the Most\nEfficient Tests of Statistical Hypotheses.” Philosophical\nTransactions of the Royal Society of London. Series A 231\n(694-706): 289–337. https://doi.org/10.1098/rsta.1933.0009.\n\n\nNumPy community. 2023. NumPy V1.25 Manual. https://numpy.org/doc/stable/.\n\n\nRobert, Christian P., and George Casella. 2004. Monte Carlo\nStatistical Methods. 2nd ed. Springer.\n\n\nSciPy community. 2023. SciPy V1.11.2 Manual:\nStatistical Functions (‘Scipy.stats‘). https://docs.scipy.org/doc/scipy/reference/stats.html.\n\n\nSnedecor, George W., and William G. Cochran. 1989. Statistical\nMethods. 8th ed. Iowa State University Press.\n\n\nStatsmodels development team. 2023. Statsmodels:\nStatistics in Python. https://www.statsmodels.org/stable/index.html.\n\n\nStudent. 1908. “The Probable Error of a Mean.”\nBiometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nThe pandas development team. 2023. pandas 2.1.1 Documentation. https://pandas.pydata.org/pandas-docs/stable/.\n\n\nVanderPlas, Jake. 2017. Python Data Science Handbook: Essential\nTools for Working with Data. O’Reilly Media. https://jakevdp.github.io/PythonDataScienceHandbook/.\n\n\nWasserman, Larry. 2004. All of Statistics: A Concise Course in\nStatistical Inference. New York: Springer.\n\n\nWelch, B. L. 1947. “The Generalization of ‘Student’s’\nProblem When Several Different Population Variances Are\nInvolved.” Biometrika 34 (1-2): 28–35. https://doi.org/10.1093/biomet/34.1-2.28.\n\n\nWilson, Edwin B. 1927. “Probable Inference, the Law of Succession,\nand Statistical Inference.” Journal of the American\nStatistical Association 22 (158): 209–12. https://doi.org/10.1080/01621459.1927.10502953.\n\n\nZar, Jerrold H. 2010. Biostatistical Analysis. 5th ed. Pearson\nPrentice Hall.\n\n\nЖлуктенко, В. І., and С. І. Наконечний. 2001. Теорія Ймовірностей і\nМатематична Статистика: Навч.-Метод. Посібник. У 2 ч. Ч. II. Математична\nСтатистика. Київ: КНЕУ.\n\n\nТурчин, В. М. 2014. Теорія Ймовірностей і Математична Статистика.\nОсновні Поняття, Приклади, Задачі. Дніпропетровськ: ІМА-прес.",
    "crumbs": [
      "Рекомендована література"
    ]
  }
]