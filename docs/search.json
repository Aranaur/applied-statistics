[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладний статистичний аналіз",
    "section": "",
    "text": "Передмова",
    "crumbs": [
      "Передмова"
    ]
  },
  {
    "objectID": "binom.html",
    "href": "binom.html",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "1.1 Генеральна сукупність та вибірка\nВи вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.\nПроте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.\nЩоб це перевірити, ви проводите експеримент: залучаєте 30 нових студентів. 20 із них проходять курс й оплачують доступ, а 11 відмовляються. 20 — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?\nРозв’язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають генеральною сукупністю. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як \\(\\mu\\). Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та досліджувати результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо вибірку з генеральної сукупності та аналізуємо частку успішних випадків.\nЗгідно з результатами нашого експерименту, спостережувана ймовірність оплати становить \\(\\hat{\\mu} = 20/30 = 0.67\\)1. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?\nРозгляньмо, чому отримане значення може не бути переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює \\(\\mu = 0.5\\), і змоделюємо можливі результати для 30 студентів.\nДавайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для 30 спроб:\n1rng = np.random.default_rng(18)\n\n2n = 30\n3results = rng.integers(0, 1, size = 30, endpoint = True)\n4success = np.sum(results) / n\n\n5print(f\"Кількість успішних випадків: {round(success, 3) * 100}%\")\n\n\n1\n\nІніціалізуємо генератор випадкових чисел з фіксованим seed.\n\n2\n\nКількість студентів.\n\n3\n\nГенеруємо випадкові числа2 для кожного студента.\n\n4\n\nОбчислюємо частку успішних випадків.\n\n5\n\nВиводимо результат.\n\n\n\n\nКількість успішних випадків: 70.0%\nМи бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.\nТому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення \\(\\mu\\) у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#генеральна-сукупність-та-вибірка",
    "href": "binom.html#генеральна-сукупність-та-вибірка",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "Якщо монетка випаде орлом, студент оплачує доступ.\nЯкщо монетка випаде решкою, студент відмовляється від курсу.\nВикористаємо метод integers() до класу Generator, яка генерує випадкові цілі числа в заданому діапазоні.\nПідкинемо монетку 30 разів та порахуємо кількість успішних випадків.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-гіпотези",
    "href": "binom.html#статистичні-гіпотези",
    "title": "1  Біноміальний критерій",
    "section": "1.2 Статистичні гіпотези",
    "text": "1.2 Статистичні гіпотези\n\n1.2.1 Постановка задачі\nМи з’ясували, що навіть за ймовірності \\(\\mu = 0.5\\) можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали seed для отримання такого результату. Якщо повторити цей експеримент з іншим значенням seed або збільшити кількість спостережень, результат може виявитися іншим.\n\n\n\n\n\n\nПорада\n\n\n\nСпробуйте змінити seed (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.\n\n\nТож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту статистично значущими необхідно отримати відповідь на питання:\n\nЧи можна вважати, що спостережуване значення \\(\\hat{\\mu}\\) є більшим від \\(\\mu = 0.5\\)?\n\nЗвернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину \\(\\xi\\), яка підпорядковується розподілу Бернуллі3. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.\n\\[\n\\xi \\sim \\text{Bernoulli}(\\mu)\n\\]\nде \\(\\mu\\) — ймовірність успіху.\nНас цікавить підтвердження того, що \\(\\mu &gt; 0.5\\). У статистиці для перевірки гіпотез розглядають дві можливості:\n\nНульова гіпотеза (\\(H_0\\)) формулюється як твердження, яке ми прагнемо спростувати.\nАльтернативна гіпотеза (\\(H_1\\)) висловлює припущення, яке ми хочемо довести.\n\nСкорочено це записують як:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 0.5 \\\\\nH_1 &: \\mu &gt; 0.5\n\\end{aligned}\n\\]\nЗауважимо, що якщо в нашому експерименті з 30 студентами можна дивитися не на частку успіхів, а на їх кількість.\nТоді питання можна переформулювати так:\n\nЗа умови вірності \\(H_0\\) наскільки ймовірно отримати 20 або більше успішних випадків з 30?\n\nЯкщо ми проводимо \\(n\\) незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу4.\n\\[\nS_n = \\sum_{i=1}^{n} \\xi_i \\sim \\text{Binomial}(n, \\mu)\n\\]\nде \\(\\xi_i\\) — випадкова величина, яка показує успіх у \\(i\\)-му спостереженні, \\(S_n\\) — кількість успішних випадків у \\(n\\) спостереженнях, \\(n\\) — кількість спостережень, \\(\\mu\\) — ймовірність успіху.\nДавайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\).\n\nn = 30\nmu = 0.5\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, mu)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= 20], y[x &gt;= 20], color=red_pink)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.1 -  Функція щільності ймовірностей при \\(H_0\\)\n\n\n\n\n\nРисунок 1.1 демонструє функцію щільності ймовірностей для біноміального розподілу з параметрами \\(n = 30\\) та \\(\\mu = 0.5\\). Ціановим5 кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює 20.\n\n\n1.2.2 Критерій\nЩойно ми розробили алгоритм, який на основі вибірки \\(\\xi\\) або визнає наявність доказів на користь \\(H_1\\), або повідомляє, що таких доказів немає. Відповідно, він або відхиляє \\(H_0\\), або не відхиляє її.\nТакий алгоритм називається критерієм. Його можна подати у вигляді функції \\(S\\), яка приймає реалізацію вибірки та повертає \\(1\\), якщо слід відхилити \\(H_0\\), та \\(0\\) в іншому випадку.\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо відхиляємо } H_0 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nДавайте припустимо, що ми вирішили відхилити \\(H_0\\), якщо кількість успішних випадків перевищує або дорівнює 21. Тоді критерій набуде вигляду:\n\\[\nS(\\xi) = \\begin{cases}\n    1, \\text{ якщо } \\sum \\xi_i \\geqslant 21 \\\\\n    0, \\text{ в іншому випадку}\n\\end{cases}\n\\]\nЗазвичай скорочують запис і пишуть просто правило, за яким відхиляємо \\(H_0\\)\n\\[\nS = \\{\\sum \\xi_i \\geqslant 21\\}\n\\]\nПозначимо \\(Q = \\sum \\xi_i\\), \\(C = 21\\), тоді критерій набуває вигляду:\n\\[\nS = \\{Q(\\xi) \\geqslant C\\}\n\\]\nТак влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. \\(Q\\) називається статистикою критерію, \\(C\\) — критичним значенням.\n\\(Q\\) може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх \\(\\xi_i\\). Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.\n\n\n1.2.3 Критична область\nЗнову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію \\(S\\):\n\nНаскільки часто може бути таке, що за справедливості \\(H_0\\) критерій \\(S\\) відхиляє гіпотезу?\n\nВідповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним 21, побачивши на картинці, що великі відхилення відбуваються при \\(H_0\\) рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення \\(C\\), виходячи з частоти помилок нашого критерію.\nВибираючи \\(C\\), ми можемо або часто відхиляти нульову гіпотезу, коли \\(C\\) мале, або можемо робити це рідше, коли \\(C\\) велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.\n\n\\(C = 16\\). Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із 30, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає \\(1\\), тобто це помилка хибно позитивна (false positive, FP).\n\\(C = 29\\). У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб’ємося цього. Не відхилити гіпотезу \\(H_0\\), коли вона неправильна — це теж помилка. Вона називається хибно негативна (false negative, FN), оскільки критерій повернув 0 помилково.\n\n\\[ \\text{FP} - H_0\\ відхиляється,\\ коли\\ вона\\ вірна \\] \\[ \\text{FN} - H_0\\ не\\ відхиляється,\\ коли\\ вона\\ не вірна \\]\nУ нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.\nТому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж частота хибнопозитивних спрацьовувань (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності \\(H_0\\).\nТепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.\n\nЯкий FPR у критерію \\(S\\) для перевірки гіпотези \\(H_0\\) проти \\(H_1\\)?\n\nКоли \\(H_0\\) є вірною, щоб порахувати кількість успіхів ми проводили 30 разів підкидання монетки з ймовірністю орла \\(0.5\\). Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при \\(\\mu = 0.5\\) наша статистика має біноміальний розподіл \\(Q \\sim Binom(0.5, 30)\\).\nОбчислимо FPR для \\(C = 21\\)\n\\[\n\\begin{aligned}\nFPR &= P(S(\\xi) = 1\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ H_0) \\\\\n&= P(Q \\geqslant 21\\ |\\ \\mu = 0.5) = \\\\\n&= P(Q \\geqslant 21\\ |\\ Q \\sim Binom(0.5, 30))\n\\end{aligned}\n\\]\nЦе вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.\n\n\n1.2.4 Обчислення FPR\nДавайте порахуємо суму ймовірностей для кількостей успіхів від 21 до 30 включно. Покажемо графічно, як це виглядає на Рисунку 1.2.\n\nx = np.arange(0, n + 1)\ny = binom.pmf(x, n, 0.5)\n\nplt.bar(x, y, color=turquoise)\nplt.bar(x[x &gt;= crit_subs], y[x &gt;= crit_subs], color=red_pink)\nfor i in range(crit_subs - 2, crit_subs + 4):\n    plt.text(i + 0.5, y[i] + 0.001, f\"{round(y[i] * 100, 1)}%\",\n    ha='center', va='bottom', size=8, rotation = 30)\nplt.xlabel(\"Кількість успішних випадків\")\nplt.ylabel(\"Ймовірність\")\nplt.show()\n\n\n\n\n\n\n\nРисунок 1.2 -  Ймовірність хибно відхилити \\(H_0\\) за умови її вірності\n\n\n\n\n\nЗалишається лише обчислити суму ймовірностей для кількостей успіхів від 21 до 30 включно. Це і буде нашим FPR.\n\\[\nFPR_{21} = \\sum_{i = 21}^{30} P(Q = i) \\approx 0.021\n\\]\nУ нашому випадку це буде 2.1%. Якщо FPR не перевищує деякої константи \\(\\alpha\\), то критерій називається критерієм рівня значущості \\(\\alpha\\). Статистичний критерій з \\(\\alpha\\) = 100% створити тривіально — достатньо завжди відхиляти \\(H_0\\) — тому така постановка не має сенсу.\nРівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть \\(\\alpha = 0.05\\), але якщо потрібне більш точне ухвалення рішення, можуть вибрати \\(0.01\\), \\(0.005\\), \\(0.001\\). Якщо ж рішення не таке критичне, можуть вибрати \\(0.1\\).\nПрипустимо, вибрали значення \\(\\alpha = 0.05\\), скористаємося критерієм \\(S\\): тобто якщо кількість успішних випадків перевищує або дорівнює 21, то відхиляємо \\(H_0\\).\nЯкщо уважно подивитись на Рисунок 1.2, то можна помітити, що ми можемо відхиляти \\(H_0\\) при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати \\(\\alpha = 0.05\\):\n\\[\nFPR_{20} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.049\n\\]\nЯкщо ж обрати 19, то FPR буде більше \\(\\alpha\\): \\[\nFPR_{19} = \\sum_{i = 20}^{30} P(Q = i) \\approx 0.1002\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#статистичні-функції-в-python",
    "href": "binom.html#статистичні-функції-в-python",
    "title": "1  Біноміальний критерій",
    "section": "1.3 Статистичні функції в Python",
    "text": "1.3 Статистичні функції в Python",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  },
  {
    "objectID": "binom.html#footnotes",
    "href": "binom.html#footnotes",
    "title": "1  Біноміальний критерій",
    "section": "",
    "text": "У статистиці \\(\\hat{\\mu}\\) позначається як оцінка параметра \\(\\mu\\).↩︎\nМетод integers() генерує випадкові цілі числа в заданому діапазоні. Аргумент endpoint вказує, що верхня межа включається у діапазон.↩︎\nРозподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.↩︎\nБіноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума \\(n\\) незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.↩︎\nАнгл. cyan, від грец. κυανoῦς — “блакитний”, “лазуровий”.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Біноміальний критерій</span>"
    ]
  }
]