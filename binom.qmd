# Біноміальний критерій {#sec-binom}

```{python}
#| include: false

with open("_common.py") as f:
    exec(f.read())
```


```{python}
#| include: false
#| label: case-variables

subs = 20
crit_subs = 21
n = 30
```

## Генеральна сукупність та вибірка

Ви вирішили створити платформу онлайн-курсів з програмування. Ви записали навчальні відео та запропонували користувачам доступ за передплатою. Вартість курсу для студента становить 1000 гривень, а витрати на підтримку платформи та індивідуальні консультації коштують вам 500 гривень з кожного студента.

Проте ви помічаєте, що деякі люди відмовляються від курсу після першого заняття, якщо матеріал їм здається складним або нецікавим. Інвестори готові підтримати ваш проєкт, якщо рівень відмов буде нижче 50%.

Щоб це перевірити, ви проводите експеримент: залучаєте `{python} n` нових студентів. `{python} subs` із них проходять курс й оплачують доступ, а 11 відмовляються. `{python} subs` — це більше половини, але чи достатньо цього, щоб довести перспективність проєкту?

Розв'язуючи таку задачу, ми припускаємо, що існує певна аудиторія, яка користуватиметься нашим сервісом. Цю групу називають **генеральною сукупністю**. Якщо запустити сервіс для всіх потенційних користувачів, у ньому буде певна частка успішних випадків, позначимо її як $\mu$. Це невідомий параметр, який ми не можемо визначити безпосередньо. Натомість ми можемо проводити експерименти та **досліджувати** результати. Оскільки протестувати продукт на всій аудиторії неможливо, ми беремо **вибірку** з генеральної сукупності та аналізуємо частку успішних випадків.

Згідно з результатами нашого експерименту, спостережувана ймовірність оплати становить $\hat{\mu} = `{python} subs`/`{python} n` = `{python} np.round(subs / n, 2)`$[^mu-hat]. Це означає, що 67% студентів оплатили доступ. Чи можемо ми зробити висновок, що справжня частка успішних випадків перевищує 50%?

[^mu-hat]: У статистиці $\hat{\mu}$ позначається як оцінка параметра $\mu$.

Розгляньмо, чому отримане значення *може не бути* переконливим доказом. Припустимо, що ймовірність успішної оплати дорівнює $\mu = 0.5$, і змоделюємо можливі результати для `{python} n` студентів.

Давайте спростимо цю задачу до прикладу з підкиданням монетки та змоделюємо результати для `{python} n` спроб:

- Якщо монетка випаде орлом, студент оплачує доступ.
- Якщо монетка випаде решкою, студент відмовляється від курсу.
- Використаємо метод `integers()` до класу `Generator`,  яка генерує випадкові цілі числа в заданому діапазоні.
- Підкинемо монетку `{python} n` разів та порахуємо кількість успішних випадків.

```{python}
rng = np.random.default_rng(18) # <1>

n = 30 # <2>
results = rng.integers(0, 1, size = 30, endpoint = True) # <3>
success = np.sum(results) / n # <4>

print(f"Кількість успішних випадків: {round(success, 3) * 100}%") # <5>
```

1. Ініціалізуємо генератор випадкових чисел з фіксованим `seed`.
2. Кількість студентів.
3. Генеруємо випадкові числа[^integers] для кожного студента.
4. Обчислюємо частку успішних випадків.
5. Виводимо результат.

[^integers]: Метод `integers()` генерує випадкові цілі числа в заданому діапазоні. Аргумент `endpoint` вказує, що верхня межа включається у діапазон.

Ми бачимо, що в експерименті частка успішних випадків навіть перевищила 63%, тоді як у симуляції була закладена ймовірність 50%.

Тому, на жаль, ми не можемо з абсолютною точністю визначити, яким є справжнє значення $\mu$ у генеральній сукупності та чи перевищує воно 50%, незалежно від того, скільки спостережень ми проводимо. Однак, застосовуючи методи прикладної статистики, ми зможемо використати інструменти, які допоможуть ухвалити правильне рішення, зокрема й у цьому випадку.

## Статистичні гіпотези

### Постановка задачі

Ми з'ясували, що навіть за ймовірності $\mu = 0.5$ можна отримати значну кількість успішних випадків. Насправді ми спеціально підбирали `seed` для отримання такого результату. Якщо повторити цей експеримент з іншим значенням `seed` або збільшити кількість спостережень, результат може виявитися іншим.

::: {.callout-tip}
Спробуйте змінити `seed` (наприклад 22) або кількість спостережень та перевірте, як змінюється результат.
:::

Тож велика кількість успішних випадків може бути результатом випадковості. Щоб вирішити, чи можна вважати результати експерименту **статистично значущими** необхідно отримати відповідь на питання:

> Чи можна вважати, що спостережуване значення $\hat{\mu}$ є більшим від $\mu = 0.5$?

Звернімося до теорії ймовірностей. Факт підписки на наш сервіс для кожного окремого студента можна розглядати як випадкову величину $\xi$, яка підпорядковується розподілу Бернуллі[^bern]. Параметр цього розподілу, а саме ймовірність успіху, нам невідомий.

[^bern]: Розподіл Бернуллі — це дискретний розподіл ймовірностей, який моделює випадковий експеримент з двома можливими результатами: успіхом або невдачею.

$$
\xi \sim \text{Bernoulli}(\mu)
$$

де $\mu$ — ймовірність успіху. 

Нас цікавить підтвердження того, що $\mu > 0.5$. У статистиці для перевірки гіпотез розглядають дві можливості:

- **Нульова гіпотеза** ($H_0$) формулюється як твердження, яке ми прагнемо спростувати.
- **Альтернативна гіпотеза** ($H_1$) висловлює припущення, яке ми хочемо довести.

Скорочено це записують як:

$$
\begin{aligned}
H_0 &: \mu \leq 0.5 \\
H_1 &: \mu > 0.5
\end{aligned}
$$

Зауважимо, що якщо в нашому експерименті з `{python} n` студентами можна дивитися не на частку успіхів, а на їх **кількість**.

Тоді питання можна переформулювати так:

> За умови вірності $H_0$ наскільки ймовірно отримати `{python} subs` або більше успішних випадків з `{python} n`?

Якщо ми проводимо $n$ незалежних спостережень, то сума цих випадкових величин також підпорядковується біноміальному розподілу[^binom].

[^binom]: Біноміальний розподіл моделює кількість успішних випадків у послідовності незалежних випробувань. Сума $n$ незалежних випадкових величин з розподілу Бернуллі підпорядковується біноміальному розподілу.

$$
S_n = \sum_{i=1}^{n} \xi_i \sim \text{Binomial}(n, \mu)
$$

де $\xi_i$ — випадкова величина, яка показує успіх у $i$-му спостереженні, $S_n$ — кількість успішних випадків у $n$ спостереженнях, $n$ — кількість спостережень, $\mu$ — ймовірність успіху.

Давайте подивимось, як це виглядає графічно. Для цього побудуємо графік функції щільності ймовірностей для біноміального розподілу з параметрами $n = `{python} n`$ та $\mu = 0.5$.

```{python}
#| label: fig-binom-pmf
#| fig-cap: Функція щільності ймовірностей при $H_0$

n = 30
mu = 0.5

x = np.arange(0, n + 1)
y = binom.pmf(x, n, mu)

plt.bar(x, y, color=turquoise)
plt.bar(x[x >= 20], y[x >= 20], color=red_pink)
plt.xlabel("Кількість успішних випадків")
plt.ylabel("Ймовірність")
plt.show()
```

@fig-binom-pmf демонструє функцію щільності ймовірностей для біноміального розподілу з параметрами $n = `{python} n`$ та $\mu = 0.5$. Ціановим[^cyan] кольором позначено ймовірності для кожної кількості успішних випадків. Рожевими виділено ймовірності для кількості успішних випадків, яка перевищує або дорівнює `{python} subs`.

[^cyan]: Англ. *cyan*, від грец. κυανoῦς — "блакитний", "лазуровий".

### Критерій

Щойно ми розробили алгоритм, який на основі вибірки $\xi$ або визнає наявність доказів на користь $H_1$, або повідомляє, що таких доказів немає. Відповідно, він або відхиляє $H_0$, або не відхиляє її.

Такий алгоритм називається **критерієм**. Його можна подати у вигляді функції $S$, яка приймає реалізацію вибірки та повертає $1$, якщо слід відхилити $H_0$, та $0$ в іншому випадку.

$$
S(\xi) = \begin{cases}
    1, \text{ якщо відхиляємо } H_0 \\
    0, \text{ в іншому випадку}
\end{cases}
$$

Давайте припустимо, що ми вирішили відхилити $H_0$, якщо кількість успішних випадків перевищує або дорівнює `{python} crit_subs`. Тоді критерій набуде вигляду:

$$
S(\xi) = \begin{cases}
    1, \text{ якщо } \sum \xi_i \geqslant `{python} crit_subs` \\
    0, \text{ в іншому випадку}
\end{cases}
$$

Зазвичай скорочують запис і пишуть просто правило, за яким відхиляємо $H_0$

$$
S = \{\sum \xi_i \geqslant `{python} crit_subs`\} 
$$

Позначимо $Q = \sum \xi_i$, $C = `{python} crit_subs`$, тоді критерій набуває вигляду:

$$
S = \{Q(\xi) \geqslant C\} 
$$

Так влаштована більшість класичних критеріїв у прикладній статистиці, тому величинам у ньому дано спеціальні назви. $Q$ називається **статистикою критерію**, $C$ --- **критичним значенням**.

$Q$ може бути будь-якою функцією від вибірки, яку ви вважаєте логічною для перевірки гіпотези. У нашому випадку це кількість успіхів, або сума всіх $\xi_i$. Але ви можете вибрати й інші: максимальне значення, суму перших 5 значень або навіть просто перший елемент.

### Критична область

Знову перепишемо наше основне запитання, тільки тепер з використанням нашого критерію $S$:

> Наскільки часто може бути таке, що за справедливості $H_0$ критерій $S$ відхиляє гіпотезу?

Відповідь на це запитання залежить від критичного значення. Зараз ми взяли його рівним `{python} crit_subs`, побачивши на картинці, що великі відхилення відбуваються при $H_0$ рідко. Але що означає рідко й наскільки рідко, не сказали. Тепер наша мета зрозуміти, як вибрати критичне значення $C$, виходячи з **частоти помилок** нашого критерію.

Вибираючи $C$, ми можемо або часто відхиляти нульову гіпотезу, коли $C$ мале, або можемо робити це рідше, коли $C$ велике. Щоб вибрати правильне значення, потрібно визначитися, коли наш критерій помиляється.

- $C = 16$. Якщо відхиляти гіпотезу при отриманні хоча б 16 успішних підписок із `{python} n`, то це навряд чи влаштує інвесторів. Так, успіхів більше половини. Але якщо в генеральній сукупності ймовірність 0.5, то майже в половині випадків ми будемо відхиляти гіпотезу. Критерій помилково повертає $1$, тобто це помилка **хибно позитивна** (false positive, **FP**).

- $C = 29$. У такому разі будемо відхиляти гіпотезу тільки за 29 або 30 успіхів. Ці значення, звісно, говорять про те, що відхилення від 50% успіхів сильне. Але якщо в генеральній сукупності ймовірність, наприклад, 60%, то такі значення будуть виходити рідко. Але ж такі ймовірності теж влаштували б інвесторів, й ми б змогли відкрити стартап! А з таким критерієм ми навряд чи доб'ємося цього. Не відхилити гіпотезу $H_0$, коли вона неправильна --- це теж помилка. Вона називається **хибно негативна** (false negative, **FN**), оскільки критерій повернув 0 помилково.

$$ \text{FP} - H_0\ відхиляється,\ коли\ вона\ вірна $$
$$ \text{FN} - H_0\ не\ відхиляється,\ коли\ вона\ не вірна $$

У нашому завданні інвесторам важливіше хибно позитивна помилка. Їм дуже не хочеться потрапити в ситуацію, коли їм показали доказ успішності бізнесу, а виявилося, більшість користувачів відмовляється оформлювати підписку й компанія не отримує прибуток. Це призведе до збитків. Хибно негативна помилка призведе до того, що ви втратите успішний бізнес, але інвестори грошей не втратять.

Тому виберемо поріг, щоб ймовірність хибно позитивної помилки була задовільною, або ж **частота хибнопозитивних спрацьовувань** (False Positive Rate, FPR). Для цього треба зрозуміти, як часто ми будемо відхиляти гіпотезу, за умови вірності $H_0$.

Тепер знову переформулюємо основне питання, повністю з використанням нових термінів, й врешті-решт відповімо на нього.

> Який FPR у критерію $S$ для перевірки гіпотези $H_0$ проти $H_1$?

Коли $H_0$ є вірною, щоб порахувати кількість успіхів ми проводили `{python} n` разів підкидання монетки з ймовірністю орла $0.5$. Кількість орлів (тобто успіхів) у такому експерименті має розподіл, який називається біноміальним, тобто при $\mu = 0.5$ наша статистика має біноміальний розподіл $Q \sim Binom(0.5, `{python} n`)$.

Обчислимо FPR для $C = `{python} crit_subs`$

$$
\begin{aligned}
FPR &= P(S(\xi) = 1\ |\ H_0) \\
&= P(Q \geqslant `{python} crit_subs`\ |\ H_0) \\
&= P(Q \geqslant `{python} crit_subs`\ |\ \mu = 0.5) = \\
&= P(Q \geqslant `{python} crit_subs`\ |\ Q \sim Binom(0.5, `{python} n`))
\end{aligned}
$$

Це вже ймовірність події за конкретного розподілу випадкової величини. Його можна подивитися за таблицею або, що зручніше, обчислити з використанням мов програмування.

### Обчислення FPR

Давайте порахуємо суму ймовірностей для кількостей успіхів від `{python} crit_subs` до `{python} n` включно. Покажемо графічно, як це виглядає на [Рисунку -@fig-binom-pmf-fpr].

```{python}
#| label: fig-binom-pmf-fpr
#| fig-cap: Ймовірність хибно відхилити $H_0$ за умови її вірності

x = np.arange(0, n + 1)
y = binom.pmf(x, n, 0.5)

plt.bar(x, y, color=turquoise)
plt.bar(x[x >= crit_subs], y[x >= crit_subs], color=red_pink)
for i in range(crit_subs - 2, crit_subs + 4):
    plt.text(i + 0.5, y[i] + 0.001, f"{round(y[i] * 100, 1)}%",
    ha='center', va='bottom', size=8, rotation = 30)
plt.xlabel("Кількість успішних випадків")
plt.ylabel("Ймовірність")
plt.show()
```

Залишається лише обчислити суму ймовірностей для кількостей успіхів від `{python} crit_subs` до `{python} n` включно. Це і буде нашим FPR.

$$
FPR_{21} = \sum_{i = `{python} crit_subs`}^{`{python} n`} P(Q = i) \approx `{python} np.round(np.sum(y[crit_subs:]), 3)`
$$

У нашому випадку це буде `{python} np.round(np.sum(y[crit_subs:]), 3) * 100`%. Якщо FPR не перевищує деякої константи $\alpha$, то критерій називається критерієм **рівня значущості** $\alpha$. Статистичний критерій з $\alpha$ = 100% створити тривіально --- достатньо завжди відхиляти $H_0$ --- тому така постановка не має сенсу.

Рівень значущості зазвичай обирають на основі бізнес-міркувань. Він позначає те, який ризик неправильного прийняття позитивного рішення ми вважаємо прийнятним. Зазвичай беруть $\alpha = 0.05$, але якщо потрібне більш точне ухвалення рішення, можуть вибрати $0.01$, $0.005$, $0.001$. Якщо ж рішення не таке критичне, можуть вибрати $0.1$.

Припустимо, вибрали значення $\alpha = 0.05$, скористаємося критерієм $S$: тобто якщо кількість успішних випадків перевищує або дорівнює `{python} crit_subs`, то відхиляємо $H_0$.

Якщо уважно подивитись на @fig-binom-pmf-fpr, то можна помітити, що ми можемо відхиляти $H_0$ при кількості успіхів від 20, а не 21, оскільки такий все ще буде відповідати $\alpha = 0.05$:

$$
FPR_{20} = \sum_{i = 20}^{30} P(Q = i) \approx `{python} np.round(np.sum(y[20:]), 3)`
$$

Якщо ж обрати 19, то FPR буде більше $\alpha$:
$$
FPR_{19} = \sum_{i = 20}^{30} P(Q = i) \approx `{python} np.round(np.sum(y[19:]), 4)`
$$



## Статистичні функції в Python

