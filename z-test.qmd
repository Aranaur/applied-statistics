# $Z$-критерій Фішера {#sec-z-test}

```{python}
#| include: false

with open("_common.py") as f:
    exec(f.read())
```

У цьому розділі ми розглянемо $Z$-критерій Фішера, який використовується для перевірки гіпотез про середнє значення генеральної сукупності з відомою дисперсією.

Далі, для виведення критеріїв нам потрібен нормальний розподіл. *Потому що саме цьому розподілу підпорядковується середнє вибірок*. Тож давайте подивимося, що це взагалі таке, як з ним працювати в Python й які в нього є властивості.

## Нормальний розподіл {#sec-normal-distribution}

Нормальний розподіл $\mathcal{N}(\mu, \sigma^2)$ --- неперервний розподіл, у якому щільність спадає зі збільшенням відстані від математичного сподівання $\mu$ за швидкістю, пропорційною квадрату відстані (див. [формулу -@eq-normal-density]).

$$
f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2},
$$ {#eq-normal-density}
де $x$ --- випадкова величина, $\mu$ --- математичне сподівання, $\sigma^2$ --- дисперсія.

На графіку нижче показано, як виглядає нормальний розподіл з різними параметрами $\mu$ та $\sigma^2$.

::: {#lst-normal-distribution}

```{python}
#| eval: false

x = np.linspace(-5, 5, 1000)
params = [(0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (2, 2)]

for mu, sigma in params:
    plt.plot(x, norm.pdf(x, mu, sigma), label=f'μ={mu}, σ={sigma}')

plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()
plt.show()
```

Візуалізація нормального розподілу з різними параметрами $\mu$ та $\sigma^2$.
:::

```{python}
#| label: fig-normal-distribution
#| fig-cap: Нормальний розподіл з різними параметрами
#| echo: false

x = np.linspace(-5, 5, 1000)
params = [(0, 1), (0, 2), (1, 1), (1, 2), (2, 1), (2, 2)]

for mu, sigma in params:
    plt.plot(x, norm.pdf(x, mu, sigma), label=f'μ={mu}, σ={sigma}')

plt.xlabel('x')
plt.ylabel('f(x)')
plt.legend()
plt.show()
```

## Нормальний розподіл у Python {#sec-normal-distribution-python}

Нехай ми хочемо задати розподіл $\mathcal{N}(\mu, \sigma^2)$. Для цього є клас `norm`[^py-norm].

[^py-norm]: Документація доступна за посиланням <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html>.

Параметри класу:

- `loc` --- це $\mu$
- `scale` --- це $\sigma$, або **стандартне відхилення**. Не дисперсія!

Методи класу:

- `rvs()` --- згенерувати випадкові числа з розподілу $\mathcal{N}(\mu, \sigma^2)$
- `cdf(x)` --- кумулятивна функція розподілу (cumulative distribution function, CDF) в точці $x$, ймовірність того, що випадкова величина $X$ менша або дорівнює $x$.
- `ppf(q)` --- квантиль функції розподілу (percent-point function, PPF) для ймовірності $q$, ймовірність того, що випадкова величина $X$ менша або дорівнює $q$.
- `pdf(x)` --- щільність ймовірності (probability density function, PDF) в точці $x$, ймовірність того, що випадкова величина $X$ дорівнює $x$.

CDF та PPF --- це функції, які пов'язані між собою. CDF визначає ймовірність того, що випадкова величина $X$ менша або дорівнює $x$, а PPF визначає значення $x$, для якого ймовірність $X$ менша або дорівнює $q$.

Ініціалізуємо клас `norm` з параметрами $\mu = 0$ та $\sigma = 1$ (стандартний нормальний розподіл). Далі, згенеруємо випадкову вибірку з 50 спостережень, а також обчислимо PDF, CDF та PPF для $x = 1.5$.

::: {#lst-normal-distribution-2}

```{python}
std_norm = norm(loc=0, scale=1) # <1>

rnorm = std_norm.rvs(size=50, random_state=42) # <2>

CDF = std_norm.cdf(1.5) # <3>
PDF = std_norm.pdf(1.5) # <4>
PPF = std_norm.ppf(0.933) # <5>

display(
    Markdown(f"$P(X \\leq 1.5) = {CDF:.3f}$"), # <6>
    Markdown(f"$f(1.5) = {PDF:.3f}$"), # <7>
    Markdown(f"$z_{{0.933}} = \Phi^{{-1}}(0.933) = {PPF:.3f}$") # <8>
)
```
1. Ініціалізація класу `norm` з параметрами $\mu = 0$ та $\sigma = 1$.
2. Генерація випадкової вибірки з 50 спостережень.
3. Обчислення PDF для $x = 1.5$.
4. Обчислення CDF для $x = 1.5$.
5. Обчислення PPF для $q = 0.933$.
6. Ймовірність того, що випадкова величина $X$ менша або дорівнює $1.5$.
7. Ймовірність того, що випадкова величина $X$ дорівнює $1.5$.
8. Значення $x$, для якого ймовірність $X$ менша або дорівнює $0.933$.

Нормальний розподіл у Python.
:::

Візуалізація методів класу `norm` показана на [рисунку -@fig-normal-distribution-2].

```{python}
#| label: fig-normal-distribution-2
#| fig-cap: Демонстрація методів класу `norm`
#| echo: false

mu, sigma = 0, 1
q = 1.5


# Генерація випадкової вибірки
rnorm = norm.rvs(loc=mu, scale=sigma, size=50, random_state=42)

# Щільність розподілу (PDF)
x = np.linspace(-4, 4, 1000)
dnrom = norm.pdf(q, loc=mu, scale=sigma)
pnorm = norm.cdf(q, loc=mu, scale=sigma)
qnorm = norm.ppf(0.933, loc=mu, scale=sigma)

# PDF for x
plt.plot(x, norm.pdf(x, loc=mu, scale=sigma), label='PDF', color = turquoise)

# Random sample
plt.scatter(rnorm, np.random.normal(0, 0.005, size=rnorm.shape), color=red_pink, alpha=0.5, s=10)
plt.annotate('norm.rvs(50)', xy=(-1, 0), xytext=(-3, 0.2), color=red_pink, ha = 'center',
             arrowprops=dict(facecolor=red_pink, shrink=0.05))

# CDF for 2
plt.fill_between(x, norm.pdf(x, loc=mu, scale=sigma), where=(x <= q), color=turquoise, alpha=0.2)
plt.annotate('norm.cdf(1.5) = 0.933', xy=(1, 0.15), xytext=(1.5, 0.3), color=turquoise,
             arrowprops=dict(facecolor=turquoise, shrink=0.05))

# PDF for 2
plt.scatter(q, norm.pdf(q, loc=mu, scale=sigma), color=orange, s=15, zorder=5)
plt.plot([q, q], [0, dnrom], color=orange, linewidth=1, linestyle='--')
plt.annotate('norm.pdf(1.5) = 0.129', xy=(q, dnrom), xytext=(2, 0.2), color=orange, ha = 'left',
             arrowprops=dict(facecolor=orange, shrink=0.05))

# PPF for 0.977
plt.scatter(q, 0, color=purple, label='qnorm(0.977)', s=15, zorder=5)
plt.annotate('norm.ppf(0.933) = 1.5', xy=(q, 0), xytext=(2, 0.1), color=purple, ha = 'left',
             arrowprops=dict(facecolor=purple, shrink=0.05))


plt.xlabel('x')
plt.ylabel('Щільність')
plt.show()
```

## Властивості нормального розподілу {#sec-normal-distribution-properties}

Нормальний розподіл має кілька важливих властивостей[^normal-properties]:

[^normal-properties]: Доведення цих властивостей можна знайти в роботі @lemons2002.

1. **Сума двох незалежних нормально розподілених випадкових величин також має нормальний розподіл**:

$$
\begin{aligned}
\xi_1 &\sim \mathcal{N}(\mu_1, \sigma_1^2) \\
\xi_2 &\sim \mathcal{N}(\mu_2, \sigma_2^2) \\
\xi_1 + \xi_2 &\sim \mathcal{N}(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)
\end{aligned}
$$ {#eq-normal-sum}
де $\xi_1$ та $\xi_2$ --- незалежні нормально розподілені випадкові величини з параметрами $\mu_1$, $\sigma_1^2$ та $\mu_2$, $\sigma_2^2$ відповідно.

2. **Множення нормально розподіленої випадкової величини на константу також дає нормально розподілену величину**:

$$
a \xi_1 \sim \mathcal{N}(a\mu_1, a^2\sigma_1^2)
$$ {#eq-normal-multiply}
де $a$ --- константа, $\xi_1$ --- нормально розподілена випадкова величина з параметрами $\mu_1$, $\sigma_1^2$.

### Перевірка властивостей в Python {#sec-normal-distribution-properties-python}

За допомогою мови Python ми можемо перевірити ці властивості. Почнемо з @eq-normal-sum. Для цього ми згенеруємо дві нормально розподілені випадкові величини $\xi_1$ та $\xi_2$ з параметрами $\mu_1 = 0$, $\sigma_1^2 = 1$ та $\mu_2 = 1$, $\sigma_2^2 = 4$. Потім, ми обчислимо їхню суму та перевіримо, чи має вона нормальний розподіл з параметрами $\mu_1 + \mu_2$ та $\sigma_1^2 + \sigma_2^2$.

::: {#lst-normal-distribution-properties}
```{python}

mean_one, mean_two = 3, -1 # <1>
var_one, var_two = 4, 2 # <2>

n = 10000 # <3>

x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n) # <4>
x2 = norm.rvs(loc=mean_two, scale=np.sqrt(var_two), size=n) # <4>

x_sum = x1 + x2 # <5>
check_sum = norm(loc=mean_one + mean_two, scale=np.sqrt(var_one + var_two)) # <6>

x_grid = np.linspace(-8, 12, 1000) # <7>

fig, ax = plt.subplots()
sns.histplot(x_sum, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax) # <8>
plt.plot(x_grid, check_sum.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8) # <9>
plt.xlabel('x')
plt.ylabel('Щільність')
plt.legend()
plt.show()
```
1. Параметри $\mu_1$ та $\mu_2$.
2. Параметри $\sigma_1^2$ та $\sigma_2^2$.
3. Кількість спостережень.
4. Генерація нормально розподілених випадкових величин $\xi_1$ та $\xi_2$.
5. Сума двох нормально розподілених випадкових величин.
6. Параметри суми $\xi_1 + \xi_2$.
7. Стандартне відхилення суми $\xi_1 + \xi_2$.
8. Емпіричний розподіл суми $\xi_1 + \xi_2$.
9. Теоретичний розподіл суми $\xi_1 + \xi_2$.

Візуалізація нормального розподілу суми двох нормально розподілених випадкових величин.
:::

Видно, що розподіли приблизно збіглися! А значить ми переконалися, що формула правильна.

Другу властивість @eq-normal-multiply можна перевірити аналогічно. Для цього ми згенеруємо нормально розподілену випадкову величину $\xi_1$ з параметрами $\mu_1 = 0$, $\sigma_1^2 = 1$ та помножимо її на константу $a = 2$. Потім, ми перевіримо, чи має вона нормальний розподіл з параметрами $a\mu_1$ та $a^2\sigma_1^2$.

::: {#lst-normal-distribution-properties-2}
```{python}
mean_one = 0 # <1>
var_one = 1 # <2>
a = 2 # <3>
n = 10000 # <4>
x1 = norm.rvs(loc=mean_one, scale=np.sqrt(var_one), size=n) # <5>
x_mult = a * x1 # <6>
check_mult = norm(loc=a * mean_one, scale=np.sqrt(a**2 * var_one)) # <7>
x_grid = np.linspace(-8, 8, 1000) # <8>

fig, ax = plt.subplots()
sns.histplot(x_mult, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax) # <8>
plt.plot(x_grid, check_mult.pdf(x_grid), color=red_pink, label='Теоретичний розподіл', alpha=0.8) # <9>
plt.xlabel('x') # <9>
plt.ylabel('Щільність') # <9>
plt.legend() # <9>
plt.show() # <9>
```
1. Параметри $\mu_1$ та $\sigma_1^2$.
2. Параметри $\sigma_1^2$.
3. Константа $a$.
4. Кількість спостережень.
5. Генерація нормально розподіленої випадкової величини $\xi_1$.
6. Множення нормально розподіленої випадкової величини $\xi_1$ на константу $a$.
7. Параметри множення $\xi_1$ на константу $a$.
8. Стандартне відхилення множення $\xi_1$ на константу $a$.
9. Емпіричний та теоретичний розподіл множення $\xi_1$ на константу $a$.

Візуалізація нормального розподілу множення нормально розподіленої випадкової величини на константу.
:::

Цього разу розподіли також збіглися. А значить ми переконалися, що формула правильна.

## Центральна гранична теорема {#sec-central-limit-theorem}

Для початку пригадаємо теорему, яка є основоположною теоремою для всіх критеріїв, які ми розглянемо найближчим часом.

::: {#thm-central-limit-theorem}

## Центральна гранична теорема, ЦГТ

Нехай $\xi_1, ..., \xi_n$ --- **незалежно** однаково розподілені випадкові величини, в яких існують математичне сподівання та дисперсія: $E [\xi_i] = \mu < \infty$ і $Var[\xi_i] = \sigma^2 < \infty$, тоді $\sqrt{n}\dfrac{\overline \xi - \mu}{\sqrt{\sigma^2}}$ збігається за розподілом[^convergence-in-distribution] до $\mathcal{N}(0, 1)$.

[^convergence-in-distribution]: Послідовність випадкових величин $\xi_n$ збігається за розподілом до $\xi$, позначаємо $\xi_n \xrightarrow{d} \xi$, якщо $\lim_{n \to \infty} F_{\xi_n}(x) = F_{\xi}(x)$ для всіх $x$, в яких $F_{\xi}(x)$ неперервна.

:::

Це означає, що якщо випадкові величини в експерименті **незалежні й однаково розподілені** й ваша вибірка **досить велика**, то можна вважати, що

$$
\sqrt{n}\dfrac{\overline \xi - \mu}{\sqrt{\sigma^2}} \sim \mathcal{N}(0, 1),
$$ {#eq-central-limit-theorem}
де $\overline \xi$ --- середнє арифметичне вибірки, $n$ --- кількість спостережень, $\mu$ --- математичне сподівання генеральної сукупності, $\sigma^2$ --- дисперсія генеральної сукупності.

::: {.callout-note}
Випадкові величини можуть бути слабко залежні одна від одної й злегка по-різному розподілені. Центральна гранична теорема все ще буде правильною, @Gnedenko2021.
:::

### Візуалізація ЦГТ {#sec-visualization-central-limit-theorem}

Щоб краще розуміти, як працює ЦГТ, я пропоную візуалізувати теорему: подивимося на розподіл середніх значень у різних вибірках. Як ми це зробимо?

- Щоб подивитися, що деяка випадкова величина з нормального розподілу, нам потрібна вибірка цих випадкових величин.
- У цьому випадку нам потрібна вибірка статистик із ЦГТ. Тому нам потрібно згенерувати $N$ вибірок по $M$ елементів у кожній.
    - По кожній вибірці треба порахувати середнє за $M$ елементами.
    - У підсумку ми отримаємо вибірку з $N$ елементів.
    - Вона і має бути з нормального розподілу.

::: {#lst-visualization-central-limit-theorem}
```{python}
def visualize_CLT(sample_generator, expected_value, variance):
    np.random.seed(42)
    N = 5000 # <1>
    clt_sample = [] # <2>
    for _ in range(N):
        sample = sample_generator() # <3>
        sample_size = len(sample) # <4>
        statistic = np.sqrt(sample_size) * (np.mean(sample) - expected_value) / np.sqrt(variance) # <5>
        clt_sample.append(statistic) # <6>

    x = np.linspace(-4, 4, 1000) # <7>
    fig, ax = plt.subplots()
    sns.histplot(clt_sample, kde=True, stat='density', color=turquoise, label='Емпіричний розподіл', ax=ax) # <7>
    ax.plot(x, norm().pdf(x), color=red_pink, label='$\mathcal{N}(0, 1)$', alpha=0.8) # <7>
    plt.legend() # <7>
    plt.xlabel('X') # <7>
    plt.ylabel('Щільність') # <7>
    plt.show() # <7>


p = 0.01
n = 20
size = 5000

visualize_CLT(lambda: np.random.binomial(n, p, size), # <8>
              expected_value = p * n, # <9>
              variance = n * p * (1 - p) # <10>
)
```

1. Кількість вибірок.
2. Пустий масив для зберігання статистик.
3. Генерація вибірки з $M$ елементами.
4. Кількість елементів у вибірці.
5. Обчислення статистики.
6. Додавання статистики до масиву.
7. Візуалізація емпіричного розподілу та теоретичного розподілу.
8. Генерація вибірки з біноміального розподілу.
9. Математичне сподівання біноміального розподілу.
10. Дисперсія біноміального розподілу.

Візуалізація ЦГТ при великій вибірці з біноміального розподілу.
:::

Емпірична щільність достатньо близько збігається з теоретичним розподілом. А що якщо зменшити вибірку, за якою рахується середнє?

::: {#lst-visualization-central-limit-theorem-2}
```{python}
p = 0.05
n = 20
size = 10

visualize_CLT(lambda: np.random.binomial(n, p, size),
              expected_value = p * n,
              variance = n * p * (1 - p)
)
```

Візуалізація ЦГТ при малій вибірці з біноміального розподілу.
:::

Стало значно гірше: з'явилися прогалини в розподілі, та й сама емпірична функція розподілу зміщена. Тож наш експеримент підтвердив важливість розміру вибірки для коректної роботи ЦГТ.

Тепер подивимось на експоненціальний розподіл.

::: {#lst-visualization-central-limit-theorem-3}
```{python}
p = 5 # <1>
size = 400 # <2>
visualize_CLT(lambda: np.random.exponential(scale=1/p, size=size), # <3>
              expected_value = 1/p, # <4>
              variance = 1/(p**2) # <5>
)
```
1. Параметр $\lambda$ експоненціального розподілу.
2. Розмір вибірки.
3. Генерація вибірки з експоненціального розподілу.
4. Математичне сподівання експоненціального розподілу задається як $1/\lambda$.
5. Дисперсія експоненціального розподілу задається як $1/\lambda^2$.

Візуалізація ЦГТ при великій вибірці з експоненціального розподілу.
:::

Бачимо, що і тут усе добре працює!

### Інші формулювання ЦГТ {#sec-other-forms-central-limit-theorem}

Наступні формулювання є еквівалентними, тому що ми можемо перетворити одне в інше за допомогою простих алгебраїчних перетворень. Вони можуть бути корисними в різних ситуаціях, залежно від того, що ми хочемо перевірити.

$$
\begin{aligned}
\sqrt{n}\dfrac{\overline \xi - \mu}{\sqrt{\sigma^2}} &\sim \mathcal{N}(0, 1) {\Leftrightarrow}\\
\overline \xi - \mu &\sim \mathcal{N}\left(0, \dfrac{\sigma^2}{n} \right) \Leftrightarrow\\
\dfrac{\underset{i=1}{\overset{n}{\sum}} \xi_i}{n} &\sim \mathcal{N}\left(\mu, \dfrac{\sigma^2}{n} \right) \Leftrightarrow\\
\underset{i=1}{\overset{n}{\sum}} \xi_i &\sim \mathcal{N}\left(n \cdot \mu, n \cdot \sigma^2 \right)
\end{aligned}
$$ {#eq-other-forms-central-limit-theorem}

## Нормальна апроксимація й застосування $Z$-критерію

### Апроксимація нормальним розподілом {#sec-normal-approximation}

Згадайте задачу на самому початку [розділу -@sec-population]. У нас є вибірка користувачів $X_1,\ X_2,\ ...,\ X_n,\ X_i \sim \text{Bernoulli}(\mu)$ з параметром $\mu$, й ми хочемо перевірити гіпотезу:

$$
H_0: \mu =\mu_0 = 0.5\ \text{проти} \ H_1: \mu > 0.5
$$ 
де $\mu_0$ --- гіпотетичне значення параметра $\mu$.

Раніше, ми вирішували цю задачу через біноміальний розподіл:

- $T(X^n) = \underset{i=1}{\overset{n}{\sum}} X_i,\ T \overset{H_0}{\sim} \text{Binom} (n, \mu_0)$
- Нехай реалізація $T(X^n) = t$. Тоді
- $p\text{-значення} = P_{H_0}(T(X^n) \geq t) = 1 - P_{H_0}(T(X^n) < t)$

Згадаємо, як вирішити цю задачу за допомогою Python (-@lst-python-binomtest).

А тепер подивимося, що нам говорить ЦГТ:

- За досить великого розміру вибірки $\underset{i=1}{\overset{n}{\sum}} X_i \sim \mathcal{N}\left(n \cdot \mu_0, n \cdot \sigma^2 \right)$,
- $X_i \overset{H_0}{\sim} \text{Bernoulli} (\mu_0)$
- $\sigma^2 = \mu_0 \cdot (1 - \mu_0)$
- $p\text{-value} = P_{H_0}(T(X^n) \geq t)$. 

При цьому цього разу ми дивимося статистику не в точці $t-1$, як робили раніше, а в точці $t$, **оскільки у нас неперервний розподіл, то нам не потрібно віднімати 1**:

- у разі нормального розподілу: $P(T(X^n) \geq t) = P(T(X^n) > t) = 1 - P(T(X^n) \leq t)$;
- у разі біноміального розподілу: $P(T(X^n) \geq t) = 1 - P(T(X^n) \leq t - 1)$.

Подивимось, як це виглядає в Python. Для цього створимо функцію `get_pvalue_by_normal_approx`, яка буде приймати на вхід параметри $n$, $\mu_0$, $t$ та повертати $p$-значення. Порівняємо результати за точним біноміальним тестом та нашим наближенням.

::: {#lst-norm-approx}
```{python}
def get_pvalue_by_normal_approx(t, n, mu_0):
    mu = n * mu_0 # <1>
    sigma = np.sqrt(n * mu_0 * (1 - mu_0)) # <2>
    return 1 - norm(loc=mu, scale=sigma).cdf(t) # <3>

n = 30 # <4>
mu_0 = 0.5 # <5>
t = 19 # <6>

p_value = get_pvalue_by_normal_approx(t, n, mu_0) # <7>

print(f"p-значення за нормальною апроксимацією = {p_value:.4f}") # <8>
print(f"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}") # <9>
```
1. Математичне сподівання біноміального розподілу.
2. Стандартне відхилення.
3. Обчислення $p$-значення.
4. Кількість спостережень.
5. Гіпотетичне значення параметра $\mu$.
6. Реалізація статистики.
7. Обчислення $p$-значення.
8. Виведення $p$-значення.
9. Виведення точного $p$-значення.

Порівняння точного біноміального тесту та нормальної апроксимації при малій кількості спостережень.
:::

Ми бачимо, що значення не дуже-то й збіглися. Але, як ми пам'ятаємо, нормальна апроксимація працює тільки з деякого великого $n$. Тому давайте спробуємо повторити експеримент із більшаимо кількість спостережень.

::: {#lst-norm-approx-2}
```{python}
n = 3000
mu_0 = 0.5
t = 1544

p_value = get_pvalue_by_normal_approx(t, n, mu_0)

print(f"p-значення за нормальною апроксимацією = {p_value:.4f}")
print(f"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}")
```

Порівняння точного біноміального тесту та нормальної апроксимації при великій кількості спостережень.
:::

Ми бачимо, що відмінність тепер тільки в 3 знаку після коми, а не в другому, як раніше. Що більше ми братимемо вибірку, то меншою буде помилка про що говорить ЦГТ.

### $Z$-критерій Фішера

$Z$-критерій Фішера використовується для перевірки гіпотез про математичне сподівання випадкової величини з відомою дисперсією. Він є одним із найпоширеніших критеріїв у статистиці, оскільки дозволяє оцінити, чи є різниця між середніми значеннями двох груп статистично значущою.

Для **двостороннього** критерію ми можемо використовувати $Z$-критерій Фішера, але з урахуванням того, що ми перевіряємо гіпотезу про те, що $\mu$ не дорівнює $\mu_0$. Тобто, ми хочемо перевірити, чи є різниця між середніми значеннями двох груп статистично значущою в обидва боки.

Нульова та альтернативна гіпотези для двостороннього $Z$-критерію Фішера мають вигляд:

$$
H_0: \mu = \mu_0 \quad \text{проти} \quad H_1: \mu \neq \mu_0
$$ {#eq-z-test-hyp}
де $\mu_0$ --- гіпотетичне значення параметра $\mu$.

Статистика $Z$-критерію Фішера має вигляд:

$$
Z = \dfrac{\overline X - \mu_0}{\sigma / \sqrt{n}}
$$ {#eq-z-test-stat}
де $\overline X$ --- середнє арифметичне вибірки, $\sigma$ --- відома дисперсія генеральної сукупності, $n$ --- кількість спостережень.

При достатньо великій вибірці згідно ЦГТ $Z$-критерій Фішера має нормальний розподіл:

$$
Z(X) \overset{H_0}{\sim} \mathcal{N}(0, 1)
$$ {#eq-z-test-normal}

Двосторонній критерій набуває вигляду:

$$
P_{H_0}(Z(X) \geq z) = 1 - P_{H_0}(Z(X) < z) = 1 - \Phi(z) = \dfrac{\alpha}{2}
$$ {#eq-z-test-two-side}
де $\alpha$ --- рівень значущості.

А $p$-значення для двостороннього критерію розраховується за формулою:

$$
p\text{-значення} = 2\cdot \min \left[{\Phi(z), 1 - \Phi(z)} \right]
$$ {#eq-z-test-p-value}

**Односторонній** критерій перевіряє гіпотезу про те, що $\mu$ більше або менше $\mu_0$. Нульова та альтернативна гіпотези для одностороннього $Z$-критерію Фішера мають вигляд:

$$
H_0: \mu = \mu_0 \quad \text{проти} \quad H_1: \mu > \mu_0
$$ {#eq-z-test-hyp-one-side}

Тоді односторонній $Z$-критерій Фішера має вигляд:

$$
P_{H_0}(Z(X) \geq z) = 1 - P_{H_0}(Z(X) < z) = 1 - \Phi(z) = \alpha
$$ {#eq-z-test-one-side}
де $\Phi(z)$ --- функція розподілу стандартного нормального розподілу, $\alpha$ --- рівень значущості, $z$ --- реалізація статистики $Z$-критерію Фішера.

## $Z$-критерій Фішера в Python

Напишемо функцію `z_test_pvalue`, яка буде приймати на вхід параметри `sample_mean` (середнє арифметичне вибірки), `sample_size` (кількість спостережень), `population_mean` (гіпотетичне значення параметра $\mu$), `population_variance` (дисперсія генеральної сукупності) та `alternative` (альтернативна гіпотеза). Функція буде повертати $p$-значення для двостороннього або одностороннього $Z$-критерію Фішера.

::: {#lst-z-test}
```{python}
def z_test_pvalue(sample_mean, sample_size, population_mean, population_variance, alternative='two-sided'):
    z = (sample_mean - population_mean) / (np.sqrt(population_variance) / np.sqrt(sample_size)) # <1>
    if alternative == 'two-sided': # <2>
        p_value = 2 * min(norm.cdf(z), 1 - norm.cdf(z)) # <3>
    elif alternative == 'greater': # <4>
        p_value = 1 - norm.cdf(z) # <5>
    elif alternative == 'less': # <6>
        p_value = norm.cdf(z) # <7>
    else:
        raise ValueError("alternative must be one of ['two-sided', 'greater', 'less']") # <8>
    return p_value # <9>
```
1. Обчислення статистики $Z$-критерію Фішера.
2. Перевірка двосторонньої гіпотези.
3. Обчислення $p$-значення для двостороннього $Z$-критерію Фішера.
4. Перевірка правосторонньої гіпотези.
5. Обчислення $p$-значення для правостороннього $Z$-критерію Фішера.
6. Перевірка лівосторонньої гіпотези.
7. Обчислення $p$-значення для лівостороннього $Z$-критерію Фішера.
8. Виклик помилки, якщо альтернативна гіпотеза не відповідає жодній з можливих.
9. Повернення $p$-значення.

Реалізація $Z$-критерію Фішера в Python.
:::

Тепер ми можемо перевірити гіпотезу про те, що $\mu$ не дорівнює $\mu_0$, за допомогою $Z$-критерію Фішера. Для цього ми можемо використати функцію `z_test_pvalue` та порівняємо з результатами, які ми отримали раніше за допомогою біноміального тесту та нормальної апроксимації.

::: {#lst-z-test-example}

```{python}
n = 30
mu_0 = 0.5
t = 19
sample_mean = t / n # <1>
population_variance = mu_0 * (1 - mu_0) # <2>

p_value = z_test_pvalue(sample_mean, n, mu_0, population_variance, alternative='greater')
print(f"p-значення за Z-критерієм Фішера = {p_value:.4f}")
print(f"p-значення за нормальною апроксимацією = {get_pvalue_by_normal_approx(t, n, mu_0):.4f}")
print(f"p-значення за точним біноміальним тестом = {binomtest(t, n, mu_0, alternative='greater').pvalue:.4f}")
```

1. Обчислення математичного сподівання вибірки.
2. Дисперсія генеральної сукупності.

Порівняння $p$-значення за $Z$-критерієм Фішера, нормальною апроксимацією та точним біноміальним тестом.
:::

Ми бачимо, що $p$-значення за $Z$-критерієм Фішера та нормальною апроксимацією збігаються, а точний біноміальний тест дає трохи інше значення. Залишається питання: чи можна уточнити результати $Z$-тесту при малих вибірках? Відповідь: так, можна. Для цього існує поправка на неперервність, яка дозволяє покращити точність апроксимації і її ми розглянемо далі.

## Поправка на неперервність {#sec-continuity-correction}

Задля кращого розуміння, давайте спочатку візуалізуємо $p$-значення в залежності від величини успіхів експерименту $t$ для біноміального тесту та $Z$-критерію Фішера. Для цього побудуємо три варіанти:

- $p$-значення *за нормальною апроксимацією*.
    + Розрахунок в Python: `1 - norm.cdf(t)`.
- $p$-значення *біноміального тесту за умови, що $t$ --- неціле число*.
    + Розглянемо на прикладі $t = 19.5$, тоді $p$-значення буде дорівнювати $$\begin{aligned}P(T(X) \geq t) &= P(T(X) \geq 19.5) \\ &= 1 - P(T(X) < 19.5) \end{aligned}$$
    + Розрахунок в Python: `1 - binom.cdf(t, n, mu_0)`.
- $p$-значення *біноміального тесту за умови, що $t$ --- ціле число*.
    + Розглянемо на прикладі $t = 19$, тоді $p$-значення буде дорівнювати $$\begin{aligned}P(T(X) \geq t) &= P(T(X) \geq 19) \\ &= 1 - P(T(X) \leq 18)\end{aligned}$$
    + Розрахунок в Python: `1 - binom.cdf(t - 1, n, mu_0)`.

::: {#lst-continuity-correction}
```{python}
def cmp_pvalue_binom_and_norm(n, mu0, t, add_to_x=0):
    x_axis = np.linspace(0, n, 1000)
    dots_to_show = np.arange(0, n + 1, 1)

    sum_mu = n * mu0 # <1>
    sum_variance = n * mu0 * (1 - mu0) # <1>
    sum_std = np.sqrt(sum_variance) # <1>

    binom_dist = binom(n=n, p=mu0) # <2>
    norm_dist = norm(loc=sum_mu, scale=sum_std) # <2>

    plt.hlines(1 - binom_dist.cdf(x_axis[:-1]), x_axis[:-1], x_axis[1:], color=turquoise, linestyle='-')
    plt.vlines(x_axis[:-1], 1 - binom_dist.cdf(x_axis[:-1]), 1 - binom_dist.cdf(x_axis[1:]), color=turquoise, linestyle=':')
    
    plt.scatter(dots_to_show, 1 - binom_dist.cdf(dots_to_show-1), color=turquoise,
                alpha=1, linewidths=0.5,
                label=f'Binom pvalue = 1-binom.cdf(x-1)') # <3>
    # pvalue через биномиальное распределение
    plt.scatter(t, 1 - binom_dist.cdf(t - 1), color=turquoise, marker='o',
                alpha=1, s=100, label=f'binom p-value({t})') # <4>
    # аппроксимирующее нормальное распределение
    add_str = "" if add_to_x == 0 else f"{add_to_x}"
    plt.plot(x_axis, 1 - norm_dist.cdf(x_axis + add_to_x), color=red_pink, alpha=0.5,
             label=f'Normal pvalue = 1-norm.cdf(x{add_str})') # <5>
    # pvalue через нормальное распределение
    plt.scatter(t, 1 - norm_dist.cdf(t + add_to_x), color=red_pink,
                alpha=1, marker='o', s=100, label=f'norm p-value({t})') # <6>

    plt.legend()
    plt.xlabel('t')
    plt.ylabel('$p$-значення')
    plt.show()

n = 30
mu_0 = 0.5
t = 15

cmp_pvalue_binom_and_norm(n, mu_0, t)
```

1. Параметри нормального розподілу.
2. Створення біноміального та нормального розподілів.
3. $p$-значення біноміального розподілу.
4. $p$-значення біноміального розподілу для конкретного $t$.
5. $p$-значення нормального розподілу.
6. $p$-значення нормального розподілу для конкретного $t$.

Порівняння $p$-значення біноміального і нормального розподілів.
:::